<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[对话框（5]]></title>
    <url>%2F2018%2F05%2F26%2FMFC%E5%9F%BA%E7%A1%80%2FMFC%EF%BC%9A%E5%AF%B9%E8%AF%9D%E6%A1%86%EF%BC%885%2F</url>
    <content type="text"><![CDATA[这是第五章了…话说我第三章还没写完…不过既然今天讲了第五章，而且昨天又为了作业了解了一些对话框的知识，横竖就先写第五章吧。 一、对话框的基本概念对话框是收集信息或提供反馈的窗口，通过控件与用户进行交互。而控件是执行用户动作的窗口，通常需要依附于其父窗口（对话框、边框窗口、视图、控件栏等）所有。但是对话框则可以脱离SDI或MDI单独组成应用程序，若要建立一个对话框应用程序，需要在创建MFC工程文件时勾选“基于对话框“即可。 它建立了一个对话框应用程序。 如果希望谁能够使用自定义的对话框，需要为自定义对话框创建一个类，这个步骤可以使用类向导完成。建立以后，就可以创建这个自定义对话框类的对象了。 以消息对话框为例： 常用的一种对话框是消息对话框即MessageBox(L”information”,L”title”,MB_YESNO|MB_ICONQUESTION); 第三个参数决定了产生的消息对话框的外观：MB_YESNO代表对话框有两个按钮，一个是是（YES）一个是否（NO）；MB_ICONQUESTION代表产生的对话框在information前面有一个问号的icon。除了以上两种，还有许多类似的组合。例如：MB_YESCANCEL、MB_OKRETRY等等，icon也还有多种类型。 对话框有一些返回值，例如IDOK、IDCANCEL、IDNO、IDYES、IDABORT（呐，无意中发现shift加空格可以切换全半角…）、IDIGNORE、IDRETRY等。这些返回值可以告知程序哪个键被按下。 对话框的分类：1.模态对话框 模态对话框是一种在对话框打开时不允许进行父界面操作的对话框，大多数对话框都是模态对话框。建立模态对话框只需要调用函数DoModal()即可。它会完成加载模板与显示对话框的工作。 1234//创建一个自己的对话框对应类名字是CMyDialogCMyDialog dlg;dlg.DoMal();//只要程序执行到这里，一个自定义的对话框就会被弹出来 对话框的分类：2.非模态对话框 非模态对话框允许用户在打开这个对话框时执行其他操作，有少数对话框需要设置成非模态的形式。非模态对话框的创建与显示工作需要自己完成：自己编写构造函数、使用Craete加载模板、使用ShowWindow显示对话框。 123CMyDialog*pDlg=new CMyDialog(this);pDlg-&gt;Craete(IDD_DIALOG1);//与CMyDialog类对应的对话框IDpDlg-&gt;ShowWindow(SW_SHOW); 在对话框程序中，有时需要自己在OnInitDialog函数中添加额外的初始化代码来完成对函数的初始化。也可以写对某些控件产生消息的处理函数。 二、一个简单的静态与编辑控件对话框第一步：在资源视图中添加对话框并设计控件 这里用到了三种控件：静态控件Static Text、编辑控件Edit Control、按钮Button。它们均可以在属性界面修改ID，其中Static Text与Button可以在属性界面的“外观”-&gt;“Caption”一栏中修改显示文本，还可以修改诸如文字显示格式、边框样式等多种属性，不一一叙述。而Edit Control则需要在构造函数中才能设定初值。这里在后面有详述。 将这三种控件添加到对话框并进行调整，得到一个设计好的对话框。控件从工具箱添加。 可多选控件并由toolbar的左对齐等功能快速调整 全部设计完之后，可通过toolbar中的“测试对话框”查看布局，但没有消息函数会被执行。确定无误后，可以双击对话框为其建一个新的类。 如果选择了对话框应用程序，VS会自动为你建立第一个类 第二步：为控件添加相应的成员变量 在”添加”-&gt;“变量”中选择”控件变量“，即可为对应的控件添加变量。 如上图。 控件变量有两种类别，一种是如图的Control，一种是Value。Control类别建立的是这种控件对应类型的一个对象，Value类别建立的是这种控件对应的值。不管选哪种类别，都可以根据自己的需要修改变量类型。但是，控件类型是VS自己判断出的，不允许用户自己修改。 第三步：完成必要的初始化 在第一步中提到，Edit Control在属性视图中没有初始值的设定。对Edit Control初始值的设定需要在对话框的初始化函数OnInitDialog中完成： 1234//设置Edit Control的初始值//在CMyDialog::OnInitDialog()中edits =L&quot;1001&quot;;//Value类型的控件变量UpdateData(false); UpdateData相当于是控件实际Value与Value类别控件变量之间的一个双向开关。当以false调用UpdateData时，把控件变量的值赋给控件；以true调用UpdateData时，把控件的值赋给控件变量；当不调用Updatadata时，两者不进行值的传递。 则在这里以false调用UpdateData，将edits的值给控件。 如果不调用UpdateData，1001无法显示。 第四步：为控件建立消息与对应处理函数 在这里以Button “确定”为例：当点击“确定”时，弹出一个MessageBox，显示现在的Edit Control信息。 为控件添加消息处理函数的方法与以前一样。使用类向导，在“命令”中寻找IDOK（以“确定”按钮为例），在右边的消息中选择一个，添加消息处理函数。 12345//在CMyDialog::OnBnClickedOk中CString str;UpdateData(true);str.Format("this is the value: %s",edits);MessageBox(str); 最终于运行结果： 三、通用对话框通用对话框就是预定义的对话框，他们可以执行各种标准的操作。 今天写作业时，需要在单文档应用程序里加自定义对话框。在视图类里有一个菜单消息处理函数，在里面要弹出对话框。这时，可以通过语句if(dialog.DoModal()==IDOK)Invalidate(true);来进行判断是否按下了OK键。而且在这里没有调用UpdateData函数，控件对应的Value值也发生了改变。？？？？？？？？？？？？？暂存疑。还遇到了一个函数：editctr.GetWindowTextW(editcontent);这个函数具体的作用？以及不能在视图中使用？用了之后两种错误，无论直接视图GetDlgItem(IDC_DIALOG1)-&gt;GetWindowTextW(str);还是用dialog.GetDlgItem(IDC_DIALOG1)-&gt;GetWindowTextW(str);都不行！一个直接停止工作另一个像是assert，不懂。 1.CFontDialog 字体对话框CFontDialog的部分成员函数： GetCurrentFont(LPLOGFONT lplf)：获得字体样式GetColor():获得字体颜色IsBold()/IsItalic()/IsUnderline()：是否粗体、斜体、带下划线 在上一章中我们提到了LOGFONT与COLORREF，在这里不再提。包括自定义字体参数与选择与颜色设置。 创建对话框的方式仍然可以直接使用模态对话框，有个例子5-2，不再赘述。 2.CColorDialog 颜色对话框CColorDialog的部分成员函数： COLORREF GetColor()：获得颜色COLORREF* GetSavedCustomColors()：获得第一个自定义颜色的指针。SetCurrentColor(COLORREF clr)：设置颜色。不要调用。在消息处理函数中系统自动在用户变更选择。否则会出错弹出failure那种。 3.CFileDialog 文件对话框一种构造方式：CFileDialog dlg(true,NULL,NULL,OFN_READONLY,L&quot;C++ source|*.cpp&quot;);//文件后缀与显示方式 这里给出它的两种构造函数的参数形式：不存在默认 (BOOL bOpenFileDialog,LPCTSTR lpszDefExt=(LPCTSTR)0,LPCTSTR lpszFileName=(LPCTSTR)0,DWORD dwFlags=6UL,LPCTSTR lpszFilter=(LPCTSTR)0,CWnd*pParentWnd=(CWnd*)0,DWORD dwSize=0UL,BOOL bVistaStyle=1) 如果第一个参数是true，打开。如果是false，另存为。 (const CFileDialog &amp;) 部分成员函数： CString GetFileName()：获得文件名CString GetPathName()：获得文件路径CString GetFileExt()：获得文件扩展名 4.CPrintDialog 打印对话框有三种构造函数，常用的写出一个：(true)/(false)，（注：这种构造函数有其他缺省参数）这个参数确定了两种不同的文本排列方式，指定打印对话框还是打印设置对话框显示：false: 显示打印对话框 true:显示打印设置对话框。不存在默认。 部分成员函数： BOOL GetDefaults()：获得默认打印机int GetCopies()：获得打印份数int GetFromPage()：获得打印起始页int GetToPage()：获得终止页 5.CFindRepalceDialog 寻找与替换对话框声明并初始化显示一个查找与替换对话框：注意！这里不能使用非指针否则在函数退出时dialog也没有了。由于这是一个无模式对话框，使用new在堆上分配新空间，而不是在栈上。在Create之前使用m_fr进行初始化，它是FINDREPLACE结构类型 ，使用IsTerminating决定对话框是否被终止。 12CFindeReplaceDialog*pDlg=new CFindReplaceDialog();pDlg-&gt;Craete(true,NULL);//查找。false是查找与替换 CFindReplaceDialog是非模态对话框，不用DoModal，否则弹出Debug Failed！ 我都快忘了，CString不是String，想用字符串常量初始化，是要加上L的。 部分成员函数： CString GetFindString()：获得查找的字符串CString getReplaceString()：获得替换的字符串BOOL MathCase()：是否精确匹配字符串 为使父窗口被通知查找/替换请求，必须在框架窗口使用WindowsRegister-WindowMessage函数并使用ON_REGISTERED_MESSAGE消息映射宏处理登记消息。你可以从框架窗口的回调函数中调用CFindReplaceDialog类成员表中列出的任何成员函数。 非模态对话框的消息处理，更多。 四、控件将MFC提供的控件简单罗列如下： 控件类 控件 说明 CStatic 静态控件 表示其他控件的文本 CButton 按钮控件 下压按钮、单按钮、复选框 CEdit 编辑框控件 文本输入 CListBox 列表框控件 字符串列表 CCombBox 组合框控件 编辑框与列表框的结合 CScrollBar 滚动条控件 对话框中的滚动条 CAntimateCtrl 动画控件 显示AVI视频文件 CHeaderCtrl 标题控件 显示在文本列上的按钮 CImageList 图像列表控件 大小相同的图标或位图 CListCtrl 列表控件 图标与文字组成的列表 CProgressCtrl 进展条控件 任务完成进展 CRichEditCtrl 多格式编辑框 多格式的文本输入 CSliderCtrl 滑动条控件 包含滑动条与刻度标记 CPinButtonCtrl 旋转框控件 通过双向箭头增减值 CStatusBarCtrl 状态栏控件 状态信息显示栏 CToolBarCtrl 工具栏控件 工具信息显示栏 CTabCtrl 标签控件 显示多页信息或控件 CTreeCtrl 树状列表控件 树状的层次列表结构 CBitmapButton 位图按钮控件 位图标签的按钮 CDragListBox 拖放列表控件 允许用户拖放的列表项 CDateTimeCtrl 日期时间控件 显示日期与时间 CMonthCalCtrl 月历控件 显示月历 CIPAddressCtrl IP地址控件 显示IP地址 1.静态控件静态控件(CStatic)用于显示文本、图标、位图等，通常不用于输入与输出。控制静态控件的类是CStatic。它可以完成诸如改变静态控件的内容的工作。 想要为静态控件添加变量的话，一定要先修改他们的ID。然后对应空间才会出现在类向导的成员变量的控件名称里面。 为静态控件修改文本有两种方法： 1.在程序中不用修改：可直接在属性-&gt;外观-&gt;Caption进行修改。 在程序中修改：mctrl.SetWindowText(L&quot;ID&quot;); 2.按钮控件按钮控件(CButton)是一种子窗口，通过单击它来执行某种操作。按钮控件又可以分为复选框、单选框、下压按钮。 CButton类的成员函数如下： GetIcon()/SetIcon()GetCheck()/SetCheck()GetButtonStyle()/SetButtonStyle() 对按钮控件的修饰操作： 1.修改位图按钮/文字按扭修改属性-&gt;外观-&gt;Icon。如果这一项是false，按钮上面一定会有文字，即使加了位图也会并存。如果修改为true，纯位图按钮。类似于CStatic，在Caption改文字内容。 载入位图：1234//在CTestDialog::OnInitDialog中HICON icon;icon=AfxGetApp()-&gt;LoadIcon(IDR_MAINFRAME);mbtn.SetIcon(icon); 2.为按钮控件添加成员变量不用非要改名字，就可以添加。 3.增加一个复选框控件IDC_CHECK属于按钮控件。1234CButton*pCheck=(CButton*)GetDlgItem(IDC_CHECK);CSTring str;str.Format(L"复选框状态:%d",pCheck-&gt;GetCheck());MessageBox(str); 3.组合框控件列表框控件(CListBox)： 用于显示列表项，查看与选择列表。 编辑框控件(CEdit)： 用于输入文本信息。 组合框控件(CComboBox)： 由列表框和编辑框组成。 一些CComboBox的成员函数： GetCurSel：获得列表框当前项位置GetLBText：获得列表框指定项内容SetCurSel：设置列表框指定项位置int AddString(LPCTSTR lpszItem)：列表框结尾添加字符串InsertString：列表框插入字符串DeleteString:列表框删除字符串ResetContent：删除列表框中的所有项 组合框像是列表框与编辑框的组合。 它既可以像编辑框一样直接编辑，又可以下拉选择。 对组合框控件，在属性-&gt;行为-&gt;Data中可以设置下拉列表的每一项，每项之间应该用分号分开；在属性-&gt;外观-&gt;Type中有三个选项：Simple-简单的编辑框、DropDown-组合框功能、DropList-列表框功能。 对列表框控件，属性中没有提供添加选项的功能，只能在代码中通过自己写int AddString(LPCTSTR lpszItem);来添加。 一个小例子：哦你们的markdown有bug。不能把冒号放后面 组控件(Group Box)：组控件属于静态控件。它可以在Rect区域显示文本。 静态文本(Static Text)：属于静态控件。 希望实现这样的功能：当用户在组合框里输入文本或者选择选项之后，在Rect区域显示该选项的预览。 在资源视图中添加Static Text、Combo Box、Group Box，为他们更改标识，为Combo Box添加初始列； 为Combo Box添加Value与Control类别的变量分别：m_number,m_ctrlNumber，为Group Box添加Control类别的变量m_ctrlDisplay； 在CTestDialog的.h文件中： 12private: CRect rect;//为了表示Group Box的显示区域 在CTestDialog的.cpp文件的OnInitDialog()中:OnInitDialog()是虚函数 1234m_ctrlDisplay.GetWindowRect(&amp;rect);//那块显示区域在电脑屏幕上的坐标ScreenToClient(&amp;rect);//把电脑屏幕的坐标转化为客户区的坐标m_ctrlNumber.SetCurSel(0);//设置0位的串为默认串m_ctrlNumber.GetLBText(0,m_number);//获取0位的串 在CTestDialog的.cpp文件的OnPaint()的else中：OnPaint是消息-&gt;WM_PAINT-&gt;添加函数 1234CPaintDC dc(this);dc.SetBkMode(TRANSPARENT);//字体的背景模式透明dc.SetTextColor(RGB(0,0,255));dc.TextOutW(rect.left+20,rect.top+20,m_number); 在CTestDialog的.cpp文件的OnSelchangeNumber()中：是命令IDC_NUMBER-&gt;CBN_SELCHANGE函数 123//改变选择时更新Rectm_ctrlNumber.GetLBText(m_ctrlNumber.GetCurSel(),m_number);//获取现在显示的那个串InvalidateRect(&amp;rect); 在CTestDialog的.cpp文件的OnEditchangeNumber()中：是命令IDC_NUMBER-&gt;CBN_EDITCHANGE函数 123//在输入字符串时更新Rectm_ctrlNumber.GetWindowText(m_number);//获取写在上面的字符串InvalidateRect(&amp;rect);//更新m_number中的内容 Q：为什么Invalidate知道更新什么 废话 刚开始一直error。后来发现是一个已经删掉的控件没有删ID，导致一直藏在代码中。 标准模版库STL：是一种基于模板的容器类库，包括常用的数据结构与常用的算法。 4.列表框控件定义类模板：CtypedPtrList &lt;CObList,CStudent*&gt; m_pDataList m_pDataList的成员函数： GetHeadPosition 与 GetTailPosition GetAt and GetPrev and GetNext AddTail and RemoveHead InsertAfter and InsertBefore RemoveAt and RemoveAll IsEmpty 一个小例子：希望实现在一个列表框中，各条信息的添加、删除 1.在资源视图中添加对话框，并在对话框上添加下列控件：(Edit Box,IDC_ID),(Edit Box,IDC_NAME),(List Box,IDC_LIST),(Button,IDC_PREVIOUS),(Button,IDC_NEXT),(Button,IDC_ADD),(Button,IDC_CLOSE) 2.为控件IDC_ID添加Value类别空间变量m_id，IDC_NAME添加Value类别的m_name，IDC_LIST添加control的m_ctrlList。 3.在类向导中，点’添加类’按钮添加CStudent类，其基类是CObject 1234567public: CString m_id; CString m_name; CStudent(CString id,CString name)&#123; m_id=id; m_name=name; &#125;; 4.在CTestDialog的.h文件中： 123private: POSITION m_pos; CTypedPtrList&lt;CObList,CStudent*&gt; m_pDataList;//链表 5.在CTestDialog的OnAdd()中：是命令-&gt;IDC_ADD-&gt;BN_CLICKED 12345678910111213141516171819UpdateData(true);if(m_id.GetLength()==0)&#123; MessageBox(L"ID cannot empty!"); (CEdit*)GetDlgItem(IDC_ID)-&gt;SetFocus(); return; &#125;if(m_name.GetLength()==0)&#123; MessageBox(L"Name cannot empty!"); (CEdit*)GetDlgItem(IDC_NAME)-&gt;SetFocus(); return;&#125;CStudent *pStudent; //向链表追加结点pStudent=new CStudent(m_id,m_name);m_pDataList.AddTail(pStudent);m_pos=m_pDataList.GetTailPosition();CString str; //向ListBox追加字符串str = m_id+" "+m_name; m_ctrlList.AddString(str);m_ctrlList.SetCurSel(m_ctrlList.GetCount()-1); 6.在CTestDialog的OnPrevious中：是命令-&gt;IDC_PREVIOUS-&gt;BN_CLICKED 12345678910111213141516if(m_pos!=NULL)&#123; //计算上一条记录在链表中位置 if(m_pos==m_pDataList.GetHeadPosition())m_pos=m_pDataList.GetTailPosition(); else m_pDataList.GetPrev(m_pos); //从链表中取出上一条记录 CStudent *pStudent=m_pDataList.GetAt(m_pos); m_id=pStudent-&gt;m_id; m_name=pStudent-&gt;m_name; UpdateData(false); //计算上一条记录在ListBox中位置并选中 int pos=m_ctrlList.GetCurSel(); if(pos==0) pos=m_ctrlList.GetCount()-1; else pos--; m_ctrlList.SetCurSel(pos); &#125;else MessageBox(L"No Item!"); 7.在CTestDialog的OnNext中：是命令-&gt;IDC_NEXT-&gt;BN_CLICKED 12345678910111213141516if(m_pos!=NULL)&#123; //计算下一条记录在链表中位置 if(m_pos==m_pDataList.GetTailPosition())m_pos=m_pDataList.GetHeadPosition(); else m_pDataList.GetNext(m_pos); //从链表中取出下一条记录 CStudent *pStudent=m_pDataList.GetAt(m_pos); m_id=pStudent-&gt;m_id; m_name=pStudent-&gt;m_name; UpdateData(false); //计算下一条记录在ListBox中位置并选中 int pos=m_ctrlList.GetCurSel(); if(pos==m_ctrlList.GetCount()-1) pos=0; else pos++; m_ctrlList.SetCurSel(pos); &#125;else MessageBox(L"No Item!"); 8.在CTestDialog的OnClose中：是命令-&gt;IDC_CLOSE-&gt;BN_CLICKED 12if(MessageBox(L"CloseDialog?",L"Close",MB_OKCANCEL|MB_ICONQUESTION)==IDOK) CDialog::OnCancel(); 9.在CTestDialog的OnDestory中：是消息-&gt;WM_DESTORY 12if(!m_pDataList.IsEmpty()) delete m_pDataList.RemoveHead(); 10.在CTestDialog的OnInitDialog中：是类向导-&gt;虚函数-&gt;OnInitDialog 1m_pos=NULL; 最终我们得到的效果如图：（这个排序似乎不是很对啊… :-$ 对上面的例子考虑做一下补充： 以状态图来控制按钮状态：1234567enum STATE&#123; STARTSTATE, BROWSESTATE, ADDSTATE, MODIFYSTATE, FINALSTATE,&#125;； 设置SwitchState函数，并在函数中以&lt;Control&gt;*p×=&lt;Control*&gt;GetDlgItem(ID)来获取对象指针，并用p×-&gt;EnableWindow(false/true)来设置按钮是否可用。 最终可以： 番外：绘图程序的例子 要求：带对话框的单文档应用程序： 1.add 画笔对话框，改变画笔样式与宽度 2.add 颜色对话框，改变画笔颜色 3.add 增加菜单栏与工具栏按钮，打开两种对话框 4.用画笔在视图窗口画一个矩形 1.在资源视图中添加两个菜单项：ID_VIEW_PEN，ID_VIEW_COLOR；添加两个工具栏按钮ID同上，在快捷键列表添加快捷键：Ctrl+E与Ctrl+L。（快捷键列表：资源视图-&gt;Accelerator-&gt;IDR_AMINFRAME） 2.在资源视图中添加画笔的对话框，并添加控件：（颜色对话框使用内置对话框|控件|标识|说明||:-:|:-:|:-:||Static Text|IDC_STATIC|Width||Edit Box|IDC_WIDTH|||Group Box|IDC_STATIC|Style display||Radio Button|IDC_SOLID|Solid||Radio Button|IDC_DASH|dash||Radio Button|IDC_DOT|dot||Group Box|IDC_DISPLAY|display| 3.为控件添加成员变量：(IDC_WIDTH,Val,m_width),(IDC_SOLID,Val,m_style),(IDC_DISPLAY,Ctrl,m_ctrlDisplay)；添加普通变量CRect rect 4.在CPenDialog的定义前：1enum&#123;PEN_STYLE_SOLID,PEN_STYLE_DASH,PEN_STYLE_DOT&#125; 5.在CPenDialog的OnInitDialog中：12m_ctrlDisplay.GetWindowRect(&amp;rect);ScreenToClient(&amp;rect); 6.在CPenDialog的OnChangeWidth中：12UpdateData(true);if(m_width&gt;1&amp;&amp;m_width&lt;7)InvalidateRect(&amp;rect); 7.在CPenDialog的OnSolid/OnDash/OnDot中：12m_style=PEN_STYLE_SOLID;(DASH/DOT)InvalidateRcet(&amp;rect); 8.在CPenDialog的OnPaint中：123456789101112131415161718CPen newPen;switch(m_style)&#123; case PEN_STYLE_SOLID: newPen.CreatePen(PS_SOLID,m_width,RGB(0,0,0)); break; case PEN_STYLE_DASH: newPen.CreatePen(PS_DASH,m_width,RGB(0,0,0)); break; case PEN_STYLE_DOT: newPen.CreatePen(PS_DOT,m_width,RGB(0,0,0)); break; default: newPen.CraetePen(PS_SOLID,m_width,RGB(0,0,0)); break; &#125;dc.SelectObject(newPen);dc.MoveTo(rect.left+10,rect.top+10);dc.LineTo(rect.right-10,rect.top+40); CTestView 9.在CTestView的.h中：1234private: int m_width; int m_style; COLORREF m_color; 10.在CTestView构造函数中：123m_width=1;m_style=PEN_STYLE_SOLID;m_color=RGB(0,0,0); 11.在CTestView的OnViewPen中：1234567CPenDialog penDlg;penDlg.m_width=m_width;penDlg.m_style=m_style;if(penDlg.DoModal()==IDOK)&#123; m_width=penDlg.m_width; m_style=penDlg.m_style; &#125; 12.在CTestView的OnViewColor中：12CColorDialog colorDlg;if(colorDlg.DoModal()==IDOK)m_color=colorDlg.GetColor(); 13.在CTestView的OnLButtonDown中：123456789101112131415Pen newPen;switch(m_style)&#123; case PEN_STYLE_SOLID: newPen.CraetePen(PS_SOLID,m_width,M_color); break; case PEN_STYLE_DASH: newPen.CreatePen(PS_DASH,m_width,m_color); break; case PEN_STYLE_DOT: newPen.CraetePen(PS_DOT,m_width,m_color); braek; &#125;CDC*pDC=GetDC();pDC-&gt;SelectObject(newPen);pDC-&gt;Rectangle(20,20,200,200); 注：当画笔宽度大时，DOT与DASH都会像是SOLID风格。 5.旋转框控件(Spin)旋转框控件与编辑框控件一起使用，通常用于双向计数器。 添加编辑框控件与旋转框控件，使编辑框控件的Tab次序位于旋转框控件之前； Alignment属性设置为Right；（外观-&gt;Alignment） 选中Auto Buddy与Set Buddy Integer；（行为-&gt;Auto Buddy/Set Buddy Integer） 上述的意义： Alignment：Unattached-取消附加；Left-左对齐；Right Align-右对齐 Auto Buddy：自动按照Z顺序选择上一个控件作为数值调节按钮控件的合作窗口。 Set Buddy Integer：指定数值调节钮控件在它的位置改变时设置合作者窗口的文本。 对于Alignment： Left: Unattached: !!!!!!记得在View.h里面加#include&quot;CTestDialog.h&quot;!!!! Spin控件Ctrl类型是CSpinButtonCtrl，添加ctrl的Spin控件成员变量m_ctrlSpin。(Spin只有Control类别的变量) SetRange() 改变取值范围 SetPos()设置当前取值 GetPos 在CTestDialog的OnInitDialog中：12m_ctrlSpin.SetRange(0,50);m_ctrlSpin.SetPos(25); 当按动Spin的按钮时，EditBox中的值会一个一个地变化。 6.滑动条控件(Slider)Slider又称游标控件，通常用于刻度显示与选择。 选中Auto Ticks和Tick Marks Orientation属性设置为Horizontal Point属性设置为Both Auto Ticks：指定滑块在其取值范围内对于每一个增量都有一个刻度线 Tick Marks：指定滑块显示刻度线 Orientation：Horizontal-水平；Vertical-垂直 Point：Both-两端；Top/Left-顶/左；Bottom/Right-底/右 CSliderCtrl用于管理Slider控件，添加成员变量m_ctrlSlider。 SetRange 改变取值范围 SetTicFreq 改变取值幅度 在CTestDialog的OnInitDialog中： 12m_ctrlSlider.SetRange(0,100);m_ctrlSlider.SetTicFreq(10); 7.进展条控件(Progress)Progress常用于显示应用程序的执行进展，属性有Border、Vertical、Smooth CProgressCtrl类用于管理Progress控件，添加成员变量m_ctrlProgress。 SetRange 改变取值范围 SetStep 改编取值幅度 在CTestDialog的OnInitDialog中： 12m_ctrlProgress.SetRange(0,100);m_ctrlProgress.SetStep(5); 在CTestDialog的OnTest中： 12345for(int i=0;i&lt;20;i++)&#123; m_ctrlProgress.StepIt(); Sleep(100); &#125;if(m_ctrlProgress.GetPos()==100)MessageBox(L"Progress to 100!"); 可以将滑动条控件与进展条控件联系起来，当滑动条控件移动时，发送WM_VSCROLL或WM_HSCROLL给父窗口。 在CTestDialog的OnInitDialog中： 12m_ctrlSlider.SetRange(0,100);m_ctrlSlider.SetTicFreq(10); 在CTestDialog的OnHScroll中： 1m_ctrlProgress.SetPos(m_ctrlSlider.GetPos()); 8.动画控件(Animate)动画控件用于播放无声的.avi文件，属性有Auto Play、Center、Border CAnimateCtrl类用于管理Animate控件 做一个播放动画的对话框： 在资源视图中添加一个对话框，并向上面添加一个动画控件，四个按钮。分别为：IDC_ANIMATE、IDC_OPEN、IDC_PLAY、IDC_STOP、IDC_DISPLAY。 对四个按钮进行消息处理： 在CTestDialog的OnOpen中： 1234567CFileDialog dlg(true,NULL,NULL,OFN_READONLY,L&quot;Animation(*.avi)|*.avi&quot;);//true:以打开文件的方式打开if(dlg.DoModal()==IDOK)&#123; CString filename=dlg.GetPathName();//获得被打开的文件名 m_ctrlAnimate.Stop();//停止播放当前打开的动画 m_ctrlAnimate.Close();//关闭当前打开的动画 m_ctrlAnimate.Open(filename);//打开新动画&#125; 在CTestDialog的OnPlay中m_ctrlAnimate.Play(0,11,1);//从0秒播放到11秒，播放1次 在CTestDialog的OnStop中m_ctrlAnimate.Stop();//停止播放 在CTestDialog的OnDisplay中m_ctrlAnimate.Seek(5);//显示第5秒的静态图片 9.树状控件树状控件据说不考。先不写了，到时候印出来。 五、直接创建控件1.滑动条控件与进展条控件（单文档应用程序 在CTestView的.h文件中： 123private: CSliderCtrl m_ctrlSlider; CProgress m_ctrlProgress; 在CTestView的.h文件的#program once;之后： 12#define IDC_SLIDER 101;#define IDC_PROGRESS 102; 3.在CTestView的.h文件中： 1234567protected: DECLARE_MESSAGE_MAP();public: afx_msg int OnCreate(LPCREATESTRUCT lpCreateStruct); afx_msg void OnHScroll(UINT nSBCode, UINT nPos, CScrollBar* pScrollBar); afx_msg void OnLButtonDown(UINT nFlags, CPoint point);//声明函数，如果使用类向导，类向导会做这些。但是话说回来，既然不用资源视图，就纯代码吧 在CTestView的.cpp文件的BEGIN_MESSAGE_MAP(—-)之后： 12345ON_WM_CREATE()ON_WM_HSCROLL()ON_WM_LBUTTONDOWN()//在END_MESSAGE_MAP之前//WM表示这是个消息，如果是命令，则是ON_COMMAND 在CTestView的OnCreate中： 12345678m_ctrlSlider.Create(WS_CHILD|WS_VISIBLE|WS_BORDER|TBS_AUTOYICKS|TBS_BOTH|TBS_HORZ,CRect(40,40,300,80),this,IDC_SLIDER);m_ctrlSlider.SetRange(0,100);m_ctrlSlider.SetTicFreq(10);m_ctrlProgress.Create(WS_CHILD|WS_VISIBLE|WS_BORDER,CRect(400,40,700,80),this,IDC_PROGRESS);m_ctrlProgress.SetRange(0,100);m_ctrlProgress.SetStep(10);m_ctrlProgress.SetPos(50); 在CTestView的OnHScroll中： 123CSliderCtrl*pSlider=(CSliderCtrl*)pScrollBar;m_str.Format(L&quot;%d&quot;,pSlider-&gt;GetPos());Invalidate(true); 在CTestView的OnDraw中： 1pDC-&gt;TextOutW(40,20,m_str); 在CTestView的OnLButtonDown中： 1234for(int i=0;i&lt;5;i++)&#123; m_ctrlProgress.StepIt(); Sleep(100);&#125; 2.图像列表与位图(Image List)图像列表类似于位图数组，每个位图都有一个索引，用于查找特定的图像。CImageList用于创建、显示和管理图像列表。 例： 从资源视图中加载位图：IDB_CLASS , IDB_STUREC , IDB_COMPUTERDEPT , IDB_SELECTEDCLASS , IDB_SELECTEDSTUREC 在CTestDialog的.h文件中： 123private: CImageList*m_pImageList; void AddBitmapToImageList(int num); 在CTestDialog的构造函数中： 123456p_ImageList=new CImageList();m_pImageList-&gt;Create(16,16,true,0,0);AddBitmapToImageList(IDB_COMPUTERDEPT);...//这是其他的要被Add的Bitmap 在CTestDialog的AddBitmapToImageList中 1234CBitmap bmp;bmp.LoadBitmap(num);//要加载的位图数目m_pImageList-&gt;Add(&amp;bmp,RGB(255,255,255));bmp.DeleteObject(); 在CTestDialg的OnDestory中： 1delete m_pImageList; 在CTestDialog的OnPaint的else中： 12345678CPaintDC dc(this);CPoint pt1(10,10),pt2(10,60);int count=m_ImageList-&gt;GetImageCount();for(int i=0;i&lt;count;i++)&#123; m_pImageList-&gt;Draw(&amp;dc,i,pt1,ILD_NORMAL); m_pImageList-&gt;Draw(&amp;dc,i,pt2,ILD_MASK); pt1.x+=50;pt2.x+=50;&#125;]]></content>
      <tags>
        <tag>MFC</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim命令]]></title>
    <url>%2F2018%2F05%2F23%2FLINUX%E5%9F%BA%E7%A1%80%2FVim%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[vim编辑器用法命令 首先确保linux下安装有vim。可以使用上述命令sudo apt-get install vim来确定。如果已经安装了vim，会显示没有变化，否则会帮你安装vim。 然后就可以开始使用vim啦！ 你使用 vim 或vim filename.suffix 进入了vim的命令模式。 在命令模式下，不能进行文本编辑操作，需要按下A/a/I/i进入插入模式，在这个模式下可以像notepad一样进行文本编辑。 如果使用第二种命令进入vim，vim将会自动帮你确定文件类型。这样说吧，比如你创建了一个yayicpp.cpp文件进入编辑，vim将会使代码高亮、进行括号匹配等操作。 好的！进入文本编辑模式之后，你迫不及待地写了一段helloworld。代码完成之后，你觉得只打印一行helloworld不太够，你想知道有没有类似于VS环境中那种Ctrl+C和Ctrl+V的操作。 其实是有的。这个时候需要按下Esc重新进入命令模式。在命令模式下有很多功能组合，上述的复制粘贴就是其中一种，但是这里并不想以复制粘贴作为第一个被介绍的命令，让我们先从光标的移动开始。 按下h键，光标左移；j光标下移；k光标上移；l光标右移。 按下d键进入删除模式，这时按下h可删除光标左侧的一个字符，按下j可删除光标所在行以及下面一行；按下k可删除光标所在行与其上面一行；按下l可删除光标所在的字符。双击d键删除光标所在行。 按下u键可以撤销前一步所做的改变。 按下V（Shift+v）或是v可以进入到一个选择的可视化界面，同样可以使用hjkl控制选择范围，v按照字符选择，V按照行数选择。选择完成之后按下y就可以复制选定内容。按下p就可以将复制内容粘贴到选定的位置。 按两下y可以复制光标所在行。 写到这里，你觉得可以了，可以从vim里面退出来了。 在命令模式下输入冒号，进入最后行模式。在最低端出现了光标。 在光标位置输入w，保存文件。 输入q，退出。 这些命令可以进行组合wq。wq可以用x替代。 你进入了最后行模式，又不想退出了，想继续编辑。 按下Esc或者Backspace可以回到命令模式。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[标准日本语初级(上)第一课]]></title>
    <url>%2F2018%2F05%2F17%2F%E6%97%A5%E8%AF%AD%E7%99%BD%E7%99%BD%2F%E6%A0%87%E5%87%86%E6%97%A5%E6%9C%AC%E8%AF%AD%E4%B8%8A1%2F</url>
    <content type="text"><![CDATA[单词日语中的汉字全部是多音字，至少会有两个读音。 じん 人：ちゅうごくじん にほんじん せい 生：がくせい せんせい りゅうがくせい 关于“先生”这个词，在日本一般只用于对教课的老师、政治议员、医生、律师的称呼。其次是在某一个领域比较厉害的人物，会被称为”先生“。 がく 学 いん 員：しゃいん 教授 きょうじゅ：读音前长后短。 かい 会 しゃ 社 いん 員 通过这些组合我们可以认识到一些新词，比如：かいいん 会員、しゃいん 社員、かいしゃ 会社、しゃかい 社会 区分：会社員 社員会社員 指的是一种职业，意思是“公司职员”。 社員 指的是具体属于某一个公司的人，一般在指出公司的句子里面使用。 日本会有鼻浊音，比如：企業 きぎょ，如果考虑正式的发音，应该是：kinyo，但是实际上，尤其年轻一辈，不考虑鼻浊音，就只读成普通的浊音：kigyo。]]></content>
      <categories>
        <category>日本語</category>
      </categories>
      <tags>
        <tag>日本語</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu-windows 共享文件夹]]></title>
    <url>%2F2018%2F05%2F17%2FLINUX%E5%9F%BA%E7%A1%80%2Fubuntu-windows%E5%85%B1%E4%BA%AB%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[实际写的时间应该是2017年9-26。最初写在了CSDN。因为要放弃CSDN了，就挪过来。 在windows下 创建一个文件夹 右击文件夹-&gt;属性-&gt;共享-&gt;添加用户-&gt;everyone-&gt;设置权限-&gt;添加-&gt;共享。 查看本机IP。 在Linux下 安装samba包 File System中输入：smb://[ip] OK。 如果linux提示：failed to mount windows share:connection timed out，但是无论从虚拟机ping主机还是主机ping虚拟机都能ping通，说明是因为win10里面默认关闭了SMB服务。询问Cortana“启用或关闭windows功能”（或者打开控制面板自己找这一项），找到 SMB 1.0/CIFS 文件共享支持，打开，之后会被要求重启。电脑重启之后，就可以连接啦！解决方法来源:SMB/Windows 连接的时候会要求用户名与密码，这是因为直接连接了机器，这个密码是要求Windows机器的账户密码。其实我觉得有点奇怪…因为上述设置的时候明明“everyone”可以读写。不过无伤大雅，就没有再管。 目前存在的问题：无法传输2M的pdf文件。但是6K的txt可以很快传输。 #519再次更新： 前面说到无法传输pdf，实际上是超过了1M甚至几百K的文件不能传输，会有提示Connection timed out。昨天看了些解决方案，都需要修改smb源码至少也需要修改conf文件。改了之后重启仍然不能传输。 具体修改方式点这里 今天忽然就好了….而且传输速度很快…]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次linux server版本的get桌面]]></title>
    <url>%2F2018%2F04%2F27%2FLINUX%E5%9F%BA%E7%A1%80%2F%E8%AE%B0%E4%B8%80%E6%AC%A1linux-server%E7%89%88%E6%9C%AC%E7%9A%84get%E6%A1%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[流水账，顺便带一点操作方法。 首先板子是UP2，之前其实已经预装了Ubuntu16.04的server版本，但是我们以为这只是一个简版而果断重新装了Ubuntu的desktop版。后来被告知这个server版预装有关于UP2开发的一系列包…于是又刷回了server版。 如何刷回server版（for UP2），click here。 里面给出的image下载链接可能是因为源在国外的关系，下载速度emm，我放进了我的百度网盘，虽然速度也慢，但不至于超时失败。 除了server版的image，还需要一个制作PE启动盘的工具。仍然是官方给出的工具tuxboot，省心的下载链接选Files on SourceForge，速度也慢，但好在不大。我也上传到了网盘。 使用TuxBoot而不是其他UltraISO之类的软件的原因是：这里下载出来的image是.zip的格式，UltraISO并不能直接处理这个文件，如果使用UltraISO将这个.zip添加到.ISO，得到的镜像属于不可引导文件，无法为U盘建立引导分区。 打开TuxBoot，选择 Pre Dowloaded -&gt; 7zs(for zip) -&gt; 选择文件所在位置 -&gt; USB Drive -&gt; 选择drive(U盘)。 如果想要可引导的ISO文件，可以勾选Save ISO File。MD5 check为预勾选，不要动。 下面是TuxBoot的一个截图： 选完之后点OK等待完成，然后就得到了一个可以用来装Ubuntuserver版的U盘。 然后直接把U盘插到UP2的USB接口，重启UP2，就可以直接进入引导界面。等待它装完之后，板子自动关机。拔掉U盘，防止进行再次安装。开机。初始的用户名与密码都是upsquared。 至此，系统重装完成。 上一次装系统还是自己装win10，这个比较简单，因为windows官方有傻瓜式的PE U盘制作引导，这里也给出网站click here。跟着指示走就行了。 然后开始奋战在get桌面。其实这本来是一件很简单的事，但是由于校园网需要登陆+pppoeconfig文件找不到+命令行下登陆困难，这件事困扰了我一下午…其实最终这个问题也不是我解决的…使它自己好的… 首先新装的系统需要更新一下：sudo apt-get update 具体命令看这里。 注意：中文包可能会出出现“not avaliable”，这是因为需要指明安装简体还是繁体。hans是简体，hant是繁体。 首先，目前的情况是： up2没有wifi模块不能无线连接 一台不支持ipv6的路由器，好处是路由器一次登陆各设备都能上网。目前大多数路由器应该都是这样（那应该叫做AP 两根网线，一个给路由器WLAN，一个从路由器的LAN接到UP2的网口。 显示屏鼠标键盘都是必备的 按理来说，我用PC连wifi登陆，然后UP2这边就应该能上网了，怪事是这样的：我登陆了wifi，发现欸怎么还不能从板子那边上网，但是很奇怪有的时候又可以get到，但是过了一会儿就会说无法从[web]得到数据，这个web就是我们学校登陆界面的网址。于是我就ping一下，ping不通，curl一个网址，也是传回登陆界面得html。emmm… 1curl www.bing.com 这个问题其实我也没有解决，因为是可以上一段时间网的，就是不断地重新apt-get install，直到某次的进度达到100%（因为每次运行都会从上次失败的地方重新开始）。总之，最后还是get到了桌面。但是应该是一直可以连接网络才对想知道校园网网关的原理 这时，get到的桌面就只有一个壁纸，其他什么都没有，可以这样安装unity桌面上面的网页仅供参考，因为这里是新装的，就是因为没有装unity桌面，这样：sudo apt-get install unity应该就行。 啊这么久以后了，今天脑子一抽卸载了python3，许多包都卸载了，决定重刷，这次试一试自己装桌面，不直接整包了。 正好了解一些python3的问题吧。 之后中文输入法什么的就在设置里面找就行了。 至此，终于把板子恢复了~]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ModuleNotFoundError:No module named 'numpy' in pyCharm]]></title>
    <url>%2F2018%2F04%2F08%2FPython%2Fnumpy_not_found%2F</url>
    <content type="text"><![CDATA[这个错误折磨了我三天….各种折磨….终于在今天给解决了。 为什么会出现这个问题？ 有两种原因： 没有装NumPy 已经装了NumPy但是运行的脚本使用的解释器不是装了NumPy的解释器。 1如果你现在已经自己从Python官网下载安装了Python环境，建议现在卸载掉，方法很简单，Win10直接去中的设置-&gt;应用中卸载就行。因为如果不卸载掉，你的电脑中可能在下列操作之后存在多个python.exe，打开不同的python.exe，安装的东西就不一样，能用的模块也不一样。如果什么应用默认使用了你不想使用的那个python，就很麻烦。 好了，现在可以装NumPy了。其实可以直接再cmd里面pip3 insatll numpy（用于python3）或pip install python（用于python2），但是我看网上各博客论坛上的大佬都不推荐这么做，最好是直接使用Anaconda，这样可以避免一些版本不兼容带来的幺蛾子。 如果你已经装了NumPy，同样，建议卸载。只需要在cmd里面pip3 unintsall numpy（py3）或是pip unintall numpy（py2）。 去下载Anaconda的安装包，不推荐官网，因为在国内官网奇慢。推荐去清华大学镜像网站下载，没有特殊需求的话看清平台与32/64，选择最新版似乎就行（因为我是全新的环境，pycharm2018.1community。 然后安装anaconda，自己选一个安装路径，不用必须安装到C盘，也不用觉得安装到C盘比较方便（反正都逃不过环境变量。 到这里python环境就没有问题了，接下来如果还是会有notfound的问题，就是pycharm的配置问题了。 2如果你是在pyCharm中新建的项目，这里一定要提示：新建项目的时候一定自己选择python解释器！！！，因为，如果你不自己去选，默认是“新的解释器”，这个新的解释器不仅会在项目下建一些不必要的东西，还有可能需要为之安装jupyter note。总之，不推荐。推荐使用已经存在的解释器，也就是你刚刚安装anaconda选择的那个目录下的python.exe： 这样进去之后基本没什么问题了。 插一句，如果出现这种找不到module的问题，去看一看这个运行的程序使用的是哪个解释器，这个信息会出现在底部的输出窗口。我就是因为发现jupyter的解释器一直是原来的那个新建的解释器才决定每次创建项目都使用已经存在的anaconda解释器。 关于运行配置，可以自己配置，只需要注意选择解释器的时候选择anaconda下的解释器就好。推荐直接在file-&gt;default setting中设置项目的默认解释器，或是在file-&gt;setting中为这个项目设置自己的默认解释器。 最后提一下，jupyter book需要在server上运行，第一次运行随便给一个token，然后底部给出一个链接，这就是可以运行了，随后使用shift+enter就可以运行一段代码了。运行方式感觉像是IDLE的改良。如果jupyter运行的时候提示error需要安装jupyter，就安装一下就好。也不用自己去搜索，就按旁边的fix就好。 python file和jupyter note都可以使用：]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[matlab notes]]></title>
    <url>%2F2018%2F02%2F26%2FMATLAB%2Fmatlab_notes%2F</url>
    <content type="text"><![CDATA[nkes113@nankai.edu.cn 哈佛 mit matlab ixl.com 公邮nkmatlab2018@126.comcode:besidenk 第一节 变量脚本与op 脚本 Scripts 变量 variables 标量 数组 Array 矩阵 数据文件操作 Exercise：得到并存储当前时间 操作变量 基本plot 可视化编程 用户函数 解方程 微分积分 4画图 CELL Struct 5符号与模拟 双变量分析 相关系数计算 Pearson Spearman jackknife 经典线性回归分析与预测 线性回归扩展 交互式多线性回归分析： 岭回归：针对多重共线问题 零碎的 第一节经典统计学 三个基本假设：同一总体、相互独立、特定分布 不同的数据采集方式有着不同的统计方法（平均数计算 数据是否符合经典统计学的分布规律 ftp://202.113.29.4 采样 基于设计的采样 基于模型的采样 Q2：癌症高发与污染是不是有关系。 变量脚本与op set path customization:preferences 帮助：help sin doc sin docsearch sin 脚本 Scripts编辑文件：edit filename.m;注释:%zhushi输出字符串：disp(&#39;string&#39;)，不要试图像使用printf那样使用disp，如果一定要输出数据，考虑下面两种方式： disp(strcat(&#39;the number is:&#39;,num2str(num)));或是：str=sprintf(&#39;the number is:%f&#39;,num)disp(str) 变量 variables matlab是一个weakly typed语言，不需要初始化。 matlab大小写敏感 尽量不要使用这些变量： i 与 j 用于声明复数：123456&gt; &gt;&gt; a=1+2i&gt;&gt;a =&gt;&gt; 1.0000 + 2.0000i&gt; pi是$\pi$ ans是最后一个未赋值的算式的值 Inf与-Inf是正无穷与负无穷 NaN相当于null 标量清除command window：clc 数组 Array注意：千万不要使用A=(1,2,3)或是A=(1 2 3)或是A=(1;2;3)这种！（是不是第二遍强调这个了！ 矩阵：A=[1 2 3;4 5 6;7 8 9]空格也可以是逗号，scripts里面建议使用逗号。 size与length：知道“matlab对于数组是先列后行（不同于C++ java等有助于理解这个”123456789&gt;&gt; A=[1 2 3;4 5 6];&gt;&gt; hangshu=size(A,1);&gt;&gt; lieshu=size(A,2);&gt;&gt; lengtha=length(A);&gt;&gt; [hangshu,lieshu,lengtha]ans = 2 3 3 length函数其实是max(size(A))，也就是行长度与列长度之中，更大的那一个。 矩阵 但是我试了一下，似乎是最终形成的那个矩阵也应该是一个整齐的二维矩阵，而且使用length也是相当于一些数据（number）来算的。所以似乎也没有特别说的必要… 数据文件操作将变量存进文件：save filename v1 v2 ...或者是save filename，后面的这个是将当前的workspace中的所有变量存入文件。 清除当前工作区中的变量：clear v1 v2...或是clear，后面的这个将清除当前workspace中的所有的变量。 加载文件中的变量：load filename v1 v2...或是load filename，后面这个将会将该文件中的所有变量load进工作区。 Exercise：得到并存储当前时间有用的函数：clock：使用方式是直接clock。得到的是[year month day hour minute seconds]datestr：将上述的结果转化为时间的字符串。 12345&gt;&gt; datestr(clock)ans = &apos;19-Mar-2018 21:43:44&apos; 操作变量 加减乘除+-*/ 次方^ element wise运算前面加. 内置的函数：sqrt开平方、log自然对数、log10以10为底的对数、sin cos atan等三角函数、round四舍五入、floor全取整数、ceil天花板、fix向0舍取整、abs绝对值、angle相角、factor得到指定数据的素数因数。 矩阵转置’(单引号) sum函数优先上下行相加，如果只有一行就全加上去 prod函数优先上下行相乘，如果只有一行就所有相乘 \运算右除，对于标量来说就是相反的事，但是对于矩阵来说A\B是：12A*x=b;x=A\b; 目前主要用于求解方程。 ones(hangshu,lieshu) zeros(hangshu,lieshu) rand(hangshu,lieshu)，默认情况下产生的数据在(0,1)之间——rand(n)默认生成nxn的随机矩阵 nan(hangshu,lieshu) linspace(shi,zhong,geshu)，不是linespace喔~ b=0:1:10、b=0:10 不写中间的间隔默认是1 寻址：A(1)，先列后行 特殊寻址：A(2,:)等你知道 特殊寻址find：index=find(A(:)&gt;=10)，使用help ind2sub sub2ind min \ max参考sum 基本plotplot最好使用help。 打开新图：figure 可视化编程用户函数function [avg,sd,range]=scriptname(p1,p2) load进来之后是一个1x1的struct？ function nargin：matlab中的函数调用可以允许更少的参数，该内置参数即为实参个数。 流的控制flow control 图像相关： help imread：matlab自带的图像函数相关说明 surface analysis quiver画图函数mesh doc specgraph # 解方程 使用以下code： 1234A=[1,4;-3,1];b=[34;2];y=A\b;disp(y); 使用函数roots解方程 使用函数polyfit/polyval进行多项式的拟合： 1234567x=[-1 0 2];y=[0 -1 3];p2=polyfit(x,y,2);%求解出系数plot(x,y,'o','MarkerSize',10);hold on;x=-3:.01:3;%对x进行排序hum（？）.01=0.01plot(x,polyval(p2,x),'r--'); 使用fzero(funhandle,xvalue)求解func=0时在xvalue附近的解。其中funchandle也可以使用匿名函数。 使用函数fminbnd(funchandle,xmv,xMv)寻找在区间[xmv,xMv]之间的解。 微分积分diff：diff实际上并不是专门用于“求微分”的函数，更确切地说，diff函数求解出的是差分，其实也就是一组数据或一组向量或一组二维数组…的后一项减前一项： 12345&gt;&gt; diff(1:5)ans = 1 1 1 1 说diff可以用来求微分是因为在定义上，如果某一函数的微分在某一可微点$x_0$为：$dy$，则在该点，对于增量$\delta y=f(x_0+\delta x)-f(x_0)$，则应该有：$\delta y=dy+o(\delta x)$。因此，实际上在x取值间隔足够小的时候，x的取值间隔就是这里的$\delta x$，可以用来近似微分。 如果使用diff来求导数，需要注意是$\frac{dy}{dx}$，因此需要对求出的数据进行除以$\delta x$的操作。 比如： 123456&gt;&gt; x=-pi:0.1:pi;&gt;&gt; f=@(x)(sin(x));&gt;&gt; y_ori=f(x);&gt;&gt; y_diff=diff(y_ori);&gt;&gt; y_div=y_diff/0.1;&gt;&gt; figure;plot(y_ori,'r-');hold on;plot(y_diff,'b-');hold on;plot(y_div,'k-');legend('ori','diff','div'); 4画图hist:画直方图 hist(x)：默认10个等宽bin，将给的数据分入这十个bin，显示每个bin中的数目。 hist(x,scaler)：scaler个等宽bin，将给的数据分入这几个bin。 hist(x,vector)：vector指定的bin，将给的数据分入这些bin。 [counts,centers]=hist(x)：每个bin中的个数以及bin的中心 histc：hist衍生 hist(x,vector)：不会像hist那样plot出来，只得要对应数据，可以自己去plot。 bar：hist类似 bar(x,y,option)：x是bin，y是hist中对应的x，画直方图，不同的是这里是累加过程。option可选style，具体可help。 randn：随机数——更多用法请查看官方randn文档 randn(n)：有正态分布的随机数组成的nxn矩阵。 randn([a b …])：随机的x维矩阵 randn：一个随机数 $\mu+\sigma*randn(n)$：一个nxn的矩阵是$\mu$方差是$\sigma^2$的正态分布 s=rng;rng(s);保存/重置随机生成数状态 mu=[1 2];sigma=[1 0.5;0.5 2];R=chol(sigma);z=repmat(mu,10,1)+randn(10,2)*R;其中：repmat是将已有矩阵复制成给定个数：nxn or mxn cumsum：累加 cumsum(A)：将从左至右累加A中元素并得出一个新的APLUS CELL cell可以定义但不必须：A=cell(2,3); A={&#39;hello&#39;,&#39;world&#39;;[1 2 3 ;4 5 6],17}; cell寻址使用大括号A{1}=[1 2 3]; A{1,2}=18; Struct 结构可以定义但不必须：s=struct s=struct(&#39;name&#39;,&#39;yayi&#39;,&#39;age&#39;,19) 结构访问同对象：s.name=&#39;yang&#39; 使用类似指针的东西：s=struct(&#39;name&#39;,{&#39;yayi&#39;,&#39;yuki&#39;},&#39;age&#39;,{19,13});p1=s(1);p2=s(2); 使用函数getfield获取结构体的各个field或是使用函数fieldnames。 对图像进行网格插值 5符号与模拟 - 1234a=sym('1/3');b=sym('2/3');c=a+b;%好像哪个语言里面也有这种功能....具体忘记是哪个了... - 12pretty('x+x+3*x^2+2*x^2');%就是合并同类项 - 123%对矩阵：a=sym('[a b;c d]');%这样出来的矩阵，可以进行诸如* inv det的各种矩阵运算 双变量分析相关系数计算PearsonSpearman适用于：有序变量之间关联强度与方向测量。适合于偏斜分布数据。 $$\rho=1-\frac{6\sum_{i=1}^{n}{(x_i-y_i)^2}}{n(n^2-1)}$$ 其中x，y都应该是有序变量。 可以用来检测排序总体之间是不是存在相关性：零假设是两个变量之间不存在相关关系，即$\rhos=0$，检验的统计量$t\gamma=\rho_s\sqrt{n-1}$。当n&gt;=30，采用z检验。 jackknife经典线性回归分析与预测线性回归扩展验证正态分布：chizgof matlab使用反斜线算子\解线性方程组。 help regress help robustfit：识别数据中的异常值 leverage：计算X的QR分解之后的杠杆值：这个值接近1，则预测值接近于实际值。 aoctool函数： MATLAB应用 交互式多线性回归分析：###逐步回归分析：** stepwise 岭回归：针对多重共线问题ridge ### polyconf polydemo nlparci nlinfit nlintool nlmefit glmfit glmval treedisp treeval 零碎的 tic toc binocdf mnpdf mnrnp? poiss-poisspdf（泊松分布的概率密度函数）-poissoncdf]]></content>
      <categories>
        <category>matlab</category>
      </categories>
      <tags>
        <tag>matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译复习课]]></title>
    <url>%2F2018%2F01%2F17%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%2F%E7%BC%96%E8%AF%91%E5%A4%8D%E4%B9%A0%E8%AF%BE%2F</url>
    <content type="text"><![CDATA[词法分析语法分析语义分析：分析阶段中间…综合阶段 使用算法构造对应模块程序 各个阶段做什么事？通常倒过来问：某个事情在哪个阶段做？ 词法：将字符流切成单词流语法：将单词流构建语法树语义：类型检查、变量定义与使用规则中间代码生成：语法树-&gt;中间代码代码优化：基本块、流图、基本块内数据流分析、跨基本快数据流分析代码生成：三地址吗转化汇编代码 预处理器：文本替换（宏、包含文件 汇编器、链接器：加载器：将程序load到内存中-》修改程序中的地址（啊啊啊啊我又想到os了😭 符号表管理：词法、语法、以后错误处理：语法阶段 几个阶段如何组织？ 前四个阶段包括中间代码，之前，主要面向高级语言后面的包括优化都是后端 词法分析基本概念单词：类别、符号串分组模式：单词词素词素是具体字符串 单词是一种类型(NUMBER)模式是对一种单词的描述 不可能用自然语言描述组织： 正则表达式——模式符号串集合。有穷集、无穷集-》处理无穷集 使用简单语言（符号串集合）的运算描述复杂语言 定义： 1. 符号表中的符号（表示长度为一的符号串集合 2. $\epsilon$ 3. A|B 4. AB 5. A* 6.(A) lex支持更多形式，但是这四种运算已经是完备的了。 字母表、符号串、语言 运算法则：服从集合与符号串 等价：运算出的符号串集合相同 正则定义：类似于上下文无关文法 符号简写：+：正则闭包？：有或没有、0或1次连接[]：或 基本概念正则表达式的设计 有限自动机非确定有限自动机NFA五元组{状态集合，字母表，又想变（迁移函数），顶点（初态），终态集合} DFA无epsilon边，NFA发出相同符号边转到不同状态===NFA不确定但是DFA确定 epsilon体现在状态迁移函数的定义域，多条边体现在值域 确定有限自动机DFA 一个状态一个符号唯一确定下一个状态 五元组状态转换图状态转换矩阵：行是状态，列是字符表中符号==》计算机容易存储 判断等价===》相同正则 等价的nfa与dfa，dfa时间复杂性一定是更优的。 正则式-》NFA 汤姆森构造法：正则-&gt;NFA 是语法制导翻译的方法 NFA-&gt;DFA——子集构造法 目标是构造与NFA等价的DFA。等价：识别的字符串集合是一样的动态描述：二者对相同的字符串结果相同。在NFA里面停下的一堆状态与DFA中的某个状态等价。 障碍：无穷。 最小化DFA：概念——区分 摸个符号串区分两个状态：停下的状态一个是acc一个是其他。若分散在两个现有集合——分开。加死状态：状态迁移矩阵不能有项是空：非终态 语法分析概念 上下文无关文法：CFG：四元式（终结符、非终结符、开始符号、产生式集合） 形式化地描述：A-&gt;α 推导、语言、句型、句子最走推到、最右推导语法树、二义性文法CFG等价 CFG与正则式 自顶向下语法分析 算符文法：没有连续的非终结符、不能有ε产生式 优先级计算： 句柄确定&lt;=&gt; 活前缀：前缀末端不超过最右句柄的末端 构造识别活前缀的DFA。closure goto 概念、分析表 预测分析 SLR、LR 语法制导翻译S属性、L属性 设计 结合：自顶向下 继承；自底向上 综合 结构等价：表达式树等价名字等价：虎太郎披上羊皮就不是灰太狼 类型表达式的上下文无关文法 中间代码生成：临时名字的重用三地址码生成：按照算法构造 表达式-&gt;三地址码 代码优化 基本块、流图、从基本快口循环 下次引用 优化方法 目标代码生成基本块内局部最优]]></content>
      <categories>
        <category>编译</category>
      </categories>
      <tags>
        <tag>编译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chap5-设备]]></title>
    <url>%2F2018%2F01%2F16%2FOS%2Fchap5-%E8%AE%BE%E5%A4%87%2F</url>
    <content type="text"><![CDATA[设备基础设备类型 按功能分类 存储设备：暂时或永久 I / O设备：人机交互 通信设备：数据交换和传输按数据管理方式分类 块流：使用不同大小的块作为数据管理的基本单位 字节流：使用字节作为DM的基本单位 按设备分配进行分类 独占设备：低速I / O设备 共享设备：高速I / O设备 虚拟设备：通过软件模拟硬件 按工作模式分类 逻辑设备：由OS维护的数据结构 物理设备：不同种类的硬件 设备管理讨论 设备的复杂性：不同的设备有不同的工作模式不同设备使用不同的数据格式不同的设备支持不同的接口 有关设备的重要问题：速度：电脑的瓶颈HCI：用户造成的操作错误兼容性：独立于设备，独立于操作系统 设备管理的关键策略：高效合理：协调CPU，RAM和设备之间的速度差异。 以更高效的方式控制和管理设备。方便：兼容，安全，稳定标准化：IT行业的基础 设备管理目的 独立于设备的编程接口： 隐藏硬件组件之间的差异 为用户提供简单而通用的控制方法 保持用户进程的安全性和稳定性 高效的管理策略 分配和释放：像进程调度一样 性能增强：提高数据传输速度，使设备更适应CPU和RAM 保护：内部和外部保护，死锁 设备管理的困难 端口地址管理 控制模式设计 死锁：不合理的设备请求或分配 硬件介绍建构： 物理组件：由模拟信号驱动的设备 电子部件：可以响应和执行数字指令的控制器或适配器 控制器/适配器 主板扩展插槽 适配器中的寄存器和数据缓冲区 适配器的责任 地址转换：将逻辑地址映射到设备端口 数据传输：接收或发送所需的数据 命令执行：将数字指令转换为模拟信号来驱动物理组件 性能增强：应用缓存和其他方法来提高设备的性能 电阻式触摸屏工作原理：p7 设备的工作流程硬件工作周期的步骤：启动，自检，运行，结果检查和错误处理 设备端口 状态寄存器：存储设备的当前状态 指令寄存器：存储收到的指令 数据缓冲区：存储所需的数据 CPU和设备之间的通信机制 设置状态和指令寄存器的内容 设备执行指令，或完成数据通信 工作完成后，设备通过中断通知CPU 示例：IBM软盘驱动器 指令集：读取，写入，查找，格式化等 参数：由CPU设置，存储在设备寄存器中 位流：CPU逐位发送数据，软驱将数据缓冲区中的位排列成字节，并进行必要的检查 CPU与设备之间的通信：参见接口 如何访问设备？ I / O端口 设备的寄存器的ID 计算机维护I / O通信的I / O端口列表 缺点：分离内存空间和设备的寄存器其实还有，用于端口的指令不如用于内存访问的指令多 内存映射I / O 所有器件的寄存器都映射到内存空间 每个寄存器都分配一个唯一的内存地址 内存IO映射优点 将I / O地址视为内存地址的一部分，会生成全局地址空间 I / O和内存的区别是隐藏的，程序员可以设计复杂的I / O程序 I / O地址可以被有效地保护(?)坏处硬件很难区分内存和I / O设备的地址管理成本较高，在双公交或多母线架构下更为复杂 实际上存在混合编址方案：设备的数据缓存被map到内存，寄存器由io端口指定。 总线：与前面的并不是并列关系 设备工作模式忙等待 特殊内核进程将数据发送到设备端口;进程重复检查端口，直到端口可用并发送其余数据;内核进程完成后，用户进程继续运行;缺点：CPU浪费太多——接口中的查询方式 中断 特殊内核进程将数据发送到设备端口;进程进入休眠状态，CPU将运行其他进程;数据缓冲区为空后，设备向CPU发送中断;内核进程被唤醒并发送其余的数据缺点：频繁的中断是耗时的——接口中的中断输出方式 DMA 用户进程导致CPU陷阱，特殊内核进程设置设备中的寄存器并退出trap;设备直接从内存中读取数据;工作完成后，设备向CPU发送中断;用户进程被唤醒并继续运行——只需一次中断就可以 DMA实现细节：请参考书上p187 DMA的内部结构： 单路径：只有一套寄存器，只能控制一个I / O设备 多路径：多套寄存器，可同时控制多个I / O设备 DMA调度：在多个通道之间切换 DMA的工作模式： 1. 数据传输模式：一次一个字VS块模式 周期窃取：DMA请求一个字的总线并得到它 突发模式：DMA获取总线并启动一系列的数据传输 Fly-by模式：DMA告诉设备控制器直接将数据发送到内存 设备到设备和存储器到存储器：DMA从设备/存储器获取字并将其发送到目标地址 DMA中使用的地址： 物理地址：MMU位于CPU中，CPU将对应内存的虚拟地址转换以后给DMA地址寄存器 虚拟地址：MMU位于内存中，这种情况很少 缓冲：消除设备之间的速度差异 为了避免DMA过于复杂，磁盘读入数据之后将数据存在自己的缓冲区，一是为了检验校验和，二是为了减少总线使用减少DMA复杂度。 DMA请求CPU对DMA控制器初始化，并向I/O接口发出操作命令，I/O接口提出DMA请求。DMA响应DMA控制器对DMA请求判别优先级及屏蔽，向总线裁决逻辑提出总线请求。当CPU执行完当前总线周期即可释放总线控制权。此时，总线裁决逻辑输出总线应答，表示DMA已经响应，通过DMA控制器通知I/O接口开始DMA传输。DMA传输DMA控制器获得总线控制权后，CPU即刻挂起或只执行内部操作，由DMA控制器输出读写命令，直接控制RAM与I/O接口进行DMA传输。在DMA控制器的控制下，在存储器和外部设备之间直接进行数据传送，在传送过程中不需要中央处理器的参与。开始时需提供要传送的数据的起始位置和数据长度。DMA结束当完成规定的成批数据传送后，DMA控制器即释放总线控制权，并向I/O接口发出结束信号。当I/O接口收到结束信号后，一方面停 止I/O设备的工作，另一方面向CPU提出中断请求，使CPU从不介入的状态解脱，并执行一段检查本次DMA传输操作正确性的代码。最后，带着本次操作结果及状态继续执行原来的程序。 DMA是必需的吗？ IO通道DMA的缺点 缓慢而简单，不能支持复杂的I / O编程I / O通道简介 特殊芯片（PU）用于管理I / O设备 字符复用信道，选择复用信道，组复用信道 I / O通道与CPU共享内存，并与CPU分别工作I / O通道的结构 CAW：地址寄存器，将I / O通道程序的地址存储在内存中 CCW：命令寄存器，存储当前的I / O命令 CSW：状态寄存器，用于存储I / O操作结果的状态 CDW：数据寄存器，数据缓冲区 ![](http://oysmkdi7t.bkt.clouddn.com/18-1-17/67957883.jpg) IO软件同步阻塞VS异步传输 阻塞：用户程序将暂停（挂起），直到I / O操作完成 数据传输：中断到来之前，CPU正在异步工作（对程序来说是阻塞）错误处理 硬件级错误处理：由设备执行（尽量在底层执行） 高级错误处理：将状态返回到更高级别并由内核/用户程序处理统一命名：一个文件或一个设备的名字应该是一个简单的字符串或是一个整数，不应依赖于设备： 设备独立的概念：访问任意IO设备而无须事先制定设备 使用I / O设备地址映射名称缓冲 如何根据缓冲区维护数据缓冲区和控制数据传输：数据离开设备通常不会直接到达目的地。（实时约束）设备的分配和释放 如何实现I / O设备共享？ 如何避免死锁？ IO软件层次 中断如何由用户控制I / O设备？ 用户进程请求I / O并被阻止 设备驱动程序启动I / O操作并被阻止 I / O设备完成操作并发送中断 设备驱动程序完成并且用户进程被唤醒中断的工作流程 硬件级错误处理：由设备执行 高级错误处理：将状态返回到更高级别并由内核/用户程序处理 在终端形成之后，在软中断中：保存没被硬件保存的所有寄存器为中断服务程序设置上下文（运行环境）为中断服务程序设置栈应答中断控制器, 再次开放中断寄存器从被保存的地方复制到进程表中运行中断服务程序为下次要运行进程设置ＭＭＵ上下文装载新的进程寄存器开始运行新进程 设备驱动程序 对设备执行操作进行控制的代码是设备驱动程序 设备驱动程序的逻辑位置被指明驱动程序与设备控制器之间通过总线完成通信 设备驱动程序介绍 控制设备控制器的说明：更上层，忽视了设备之间的区别 设备驱动程序始终视为内核进程：这样才能访问设备控制的寄存器（可以作为用户进程，需要系统调用，消除系统崩溃的一个源头） OS为抽象驱动程序提供统一的接口：如上图 设备驱动程序：静态库或动态库（目前主流是动态）设备驱动程序的工作流程 接收并检查高级进程发送的参数 检查设备并启动设备（当前是不是在使用？初始化设备，电源需求，日志等） 配置设备的寄存器（将向设备发送的指令存进设备控制器的控制寄存器，检查控制器是不是已经接收命令并准备接受下一个命令，直到所有命令都送出） 接收I / O操作的状态设备驱动程序的重要问题 同步阻塞VS无延迟运行（需要长时间处理，设备驱动程序进程阻塞自己，直到中断到来唤醒；不需要长时间，完成后应检查错误。随后可能会将数据发给某个设备无关软件，返回一个信息。如果还有命令就执行，没有的话就阻塞自己） 可重入：驱动程序的复杂性（第一次调用完成之前第二次到来 可热插拔的系统和内存请求：传送必须被终止，请求应该被抹去。有时候新设备的到来可能夺走旧设备的资源 设备驱动程序以阿布年不允许系统调用，但是可以调用内核的某些过程。比如DMA、定时器、分配释放硬接线的内存页面等。 与设备无关的io软件 设备驱动程序的统一接口 引入缓冲的方式 (a) 无缓冲输入(b) 缓冲区放在用户空间(c) 缓冲区在核心空间，然后被复制到用户空间(d) 在内核空间有双缓冲区 适当的使用缓冲 缓冲技术在io中很普遍，但是数据传递中太多的缓冲会影响系统性能 IO中错误报告： 建立io的错误处理机制，尽量在底层处理错误 分别处理不同错误：如编程/io 分配与释放专用设备 根据设备使用特性建立分配与释放原则（独享设备／共享设备），直接释放或队列管理． 建立与设备无关的数据传递格式 不同设备数据传递格式不同，但须用软件隔离此特性，使上层软件不必考虑设备访问中的这一特性，如访问块大小的转换。 用户空间的IO SDK / DDK或编程库 隐藏设备驱动程序的细节，使用户访问I / O设备变得简单 如“cout”，“print”……后台程序和守护进程 用户的虚拟设备 设备共享的缓冲和调度 spooling 预输入模块：将作业输入到输入井中；缓输出模块：将作业结果缓冲式输出到独享设备上；作业调度模块：控制作业从输入井中取数，向输出井中送数；输入、输出井：在磁盘上开辟的两个 “井”区域。 磁盘管理磁盘是一种外设，CPU和内存访问速度比磁盘快若干个数量级，磁盘系统的性能对整个系统性能有重要影响，磁盘设备管理的目标就是提高磁盘的访问速度和安全性。从以下几方面讲： 1. 磁盘硬件及访问性能 2.RAID 3.CD-ROM 4.可刻录／可重写ＣＤ 5.ＤＶＤ 6. 磁盘格式化问题 7.磁盘访问调度策略 柱面定位时间：磁头移动到指定柱面的机械运动时间；旋转延迟时间：磁盘旋转到指定扇区的机械运动时间；它与磁盘转速相关，如：软盘转速可为600r/m(每分钟转速)，硬盘可为10000r/m。数据传送时间：从指定扇区读写数据的时间。 柱面定位（寻道）时间在访问时间中是主项，合理组织磁盘数据的存储位置可提高磁盘I/O性能。 例：读一个128KB大小的文件：(1)文件若由8个连续磁道(每磁道32个扇区)上的256个扇区构成： 20ms+(8.3ms+16.7ms)8=220ms;其中，柱面定位时间为20ms，旋转延迟时间为8.3ms，32扇区数据传送时间为16.7ms；(2)文件若由256个随机分布的扇区构成： (20ms+8.3ms+0.5ms)256=7373ms;其中，1扇区数据传送时间为0.5ms；随机分布时的访问时间为连续分布时的33.5倍。 算法短查找时间优先算法（SSTF）：按磁头臂移动最小距离优先分配磁盘。磁盘使用率高，分配快。 扫描(SCAN)算法：磁头沿一个方向移动，并为请求进程分配磁盘，然后反方向移动再进行分配。保证队列中不出现饿死情况。（或称电梯法） 循环扫描(C-SCAN)算法：磁头沿一个方向移动，并为请求进程分配磁盘，到头后返回重新移动。可减少等待时间。 N步扫描(N-step-SCAN)算法：把磁盘I/O请求队列分成长度为N的段，每次使用扫描算法处理这N个请求。当N=1时，该算法退化为FIFO算法。 双队列扫描(FSCAN)算法：请求队列分成两个，一个用做处理，一个用做存放新到请求。]]></content>
      <categories>
        <category>OS</category>
        <category>课</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chap6-死锁]]></title>
    <url>%2F2018%2F01%2F16%2FOS%2Fchap6-%E6%AD%BB%E9%94%81%2F</url>
    <content type="text"><![CDATA[死锁概念死锁：如果一个进程集合中的每个进程都在等待只能由该进程集合中的其他进程才能引发的事件，该进程集合是死锁的。 大多数情况下，都是在等另外的进程放弃所占的资源，但是由于所有的进程都不能运行，他们永远也等不到自己需要的资源 死锁产生条件： 互斥条件：每个资源要么已经分配了一个进程，要么就是可用的 占有和等待条件：已经得到了某个资源的进程可以请求新的资源 不可抢占条件：已经分配给一个进程的资源不能强制性被抢占，只能被占有它的进程显式释放 环路等待条件：死锁发生时，系统中一定有两个或者两个以上的进程组成的一条环路，该换路中的每一个进程都在等待下一个进程占有的资源。 死锁的危害：死锁进程永远不能活动，被持有的资源永远不可以访问-&gt;不合理的资源获取可能会产生死锁（闭环，像数据库一样） 解决 破坏4个条件，阻碍死锁发生 避免死锁发生 死锁检测与恢复 鸵鸟 prevention破坏四个条件 互斥条件：虚拟共享资源 避免分配那些不是绝对必须的资源，尽量做到尽可能少的进程可以真正请求资源 eg：使用打印机守护进程以及假脱打印机技术 占有和等待条件：禁止已持有资源的进程等待其他资源 在一次分配中满足一个进程的所有资源需求，否则进程将被阻塞，直到所有需要的资源都可用 不可抢占条件：夺取死锁进程的资源并给其他进程 避免引发混乱，使用虚拟化技术 环路等待条件：为每种资源分配类型标识，进程必须按照升序/降序来请求资源。 一种变体是不需要一定升序，但是需要不允许进程请求比当前所占有资源编号低的资源。 死锁避免preventation不合理。 系统必须判断这次请求资源是不是安全的，并且只能在安全的情况下得到资源。 安全状态：存在一个合理的资源分配序列不安全状态：不存在可以避免死锁的资源分配序列 避免死锁的机制：os只在安全的情况下分配资源。 阴影部分不能进。 银行家算法单资源 查看是否有进程还需要的资源数小于系统剩余的资源数，如果有，就分给他，如果没有，会产生死锁。 也可以这样说：如果一个进程请求资源，检查是不是可以给他。 多资源与单资源差不多，但是需要每一个还需要的资源数都是小于剩余的资源数，如果存在，就给，然后收回这个已经完成的资源，如果没有，就不可能成功了。 安全状态与死锁系统安全-&gt;没有死锁没有死锁不一定是系统安全。但是只要确保系统是安全的，就一定不会死锁。 死锁检测与恢复守护进程判断运行状态，长时间不运行则认为进入思索。 可以使用图、集合、向量、矩阵等记录资源分配状态，试图找到环路。 请求矩阵中的向量定义成qij，表示进程i请求类型j的资源量，代表当前进程产生的资源请求初始态所有进程无标记，通过算法标记进程最后查看：若有无标记的进程，则说明有死锁现 象存在 算法：1）在分配矩阵中标记一行全为0的进程2）向量W初始化成可用向量Available3）按下标i查找，进程i未标记并且该进程的请求向量小于等于W，就进行标记；若找不到这样的行，算法终止。4）若找到这样的行，标记进程i后，再把分配矩阵中的相应行加到W中，返回步骤3。 其实就是银行家算法 恢复： 抢占 Backdating：设置检查点在进程中，当检测到死锁时，进程将返回到检查点。 进程查杀：直接杀死进程。 非资源死锁 两阶段加锁对需要修改的数据：先请求加锁，再修改数据；若有一个数据已加锁，进程则释放所有加锁的记录。（像csmaca一样 通信死锁通信中多个进程发送信息，但需要阻塞当前进程等待对方回复。若发送信息丢失，则死锁。解决办法：超时中断； 活锁所谓活锁既是：进程没有死锁，但却无法运行下去，只是在不断的重复尝试，如冲突检测。 进程饿死由于条件限制使有些进程请求永远无法得到服务，进程被饿死。从饿死进程角度看，像是发生了死锁。]]></content>
      <categories>
        <category>OS</category>
        <category>课</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[流光]]></title>
    <url>%2F2017%2F12%2F16%2F%E6%9C%88%E5%8D%8E%2F%E6%B5%81%E5%85%89%2F</url>
    <content type="text"><![CDATA[生死桥怀玉心想，怎的每个人都要听他的心里话呢？到底心里有没有话？简简单单的一桩事儿，自家的事儿，哪有什么？世上各人都爱小事化大。]]></content>
      <categories>
        <category>因寄所托</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Lab4_Document]]></title>
    <url>%2F2017%2F12%2F12%2FOS%2FLab4_Document%2F</url>
    <content type="text"><![CDATA[Lab4-DocumentPart A: Multiprocessor Support and Cooperative MultitaskingMultiprocessor Support在本实验的开始部分，首先将为jos添加多核支持。在多核模式下，所有CPU地位平等，有相同的系统资源与IO总线访问权。但是，在系统启动时，多CPU可以被分为两类：BSP与AP。BSP在系统上电时接管机器，完成系统的初始化，随后，出于某种需要，BSP将会唤醒AP，AP也可以作为独立的CPU执行指令。 在这种系统之中，每个CPU都有一个模块是LAPIC，它负责系统的中断传递，为每个CPU提供一个独特的编号。 LAPIC是Local Advanced Programmable Interrupt Controller，local高级可编程中断控制器。LAPIC一般由中断信号、PRT、一组寄存器与其他一些部件组成，可以处理硬件的中断请求信息，并通知CPU进行处理。 在本次实验中，我们将会用到LAPIC模块的如下功能函数： cpunum()： 该函数中，通过访问lapic[ID]对应字段获得当前的cpu编号。 lapic_startap(): 这个函数中，BSP负责对尚未工作的AP进行初始化与唤醒操作。首先设置向量，然后发送INIT中断来重置其他CPU，最终发送STRARTUP信号与开始执行的位置，使一个CPU正式开始工作。 lapic_init(): 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273voidlapic_init(void)&#123; if (!lapicaddr) return; // lapicaddr is the physical address of the LAPIC's 4K MMIO // region. Map it in to virtual memory so we can access it. //lapiaddr是LAPIC的4K的MIMO区域的物理地址 //把他映射到虚拟地址空间，就可以访问了 lapic = mmio_map_region(lapicaddr, 4096); //enable LAPIC；设置伪中断向量 // Enable local APIC; set spurious interrupt vector. //#define SVR (0x00F0/4) // Spurious Interrupt Vector //#define ENABLE 0x00000100 // Unit Enable //in inc/trap.c //#define IRQ_OFFSET 32 // IRQ 0 corresponds to int IRQ_OFFSET //// Hardware IRQ numbers. We receive these as (IRQ_OFFSET+IRQ_WHATEVER) //#define IRQ_SPURIOUS 7 lapicw(SVR, ENABLE | (IRQ_OFFSET + IRQ_SPURIOUS)); // The timer repeatedly counts down at bus frequency // from lapic[TICR] and then issues an interrupt. //定时器重复从lapic [TICR]的总线频率倒计数，然后发出中断。 // If we cared more about precise timekeeping, // TICR would be calibrated using an external time source. //如果我们更关心精确的计时，TICR将使用外部时间源进行校准。 lapicw(TDCR, X1);//in this:向lapic数组写入东西lapic[TDCR]=X1; lapicw(TIMER, PERIODIC | (IRQ_OFFSET + IRQ_TIMER)); lapicw(TICR, 10000000); // Leave LINT0 of the BSP enabled so that it can get // interrupts from the 8259A chip. //吧BSP的LINT0（向量表0）enable，这样就可以从8259A芯片得到中断 // According to Intel MP Specification, the BIOS should initialize // BSP's local APIC in Virtual Wire Mode, in which 8259A's // INTR is virtually connected to BSP's LINTIN0. In this mode, // we do not need to program the IOAPIC. //根据英特尔MP规范，BIOS应在虚拟线路模式下初始化BSP的本地APIC， //其中8259A的INTR虚拟连接到BSP的LINTIN0。 //在这种模式下，我们不需要编程IOAPIC。 //如果当前cpu不是启动cpu，它的中断表0 被mask if (thiscpu != bootcpu) lapicw(LINT0, MASKED); // Disable NMI (LINT1) on all CPUs //中断表1都被mask lapicw(LINT1, MASKED); // Disable performance counter overflow interrupts // on machines that provide that interrupt entry. //在一些特定的版本（提供了中断入口）的机器上， //disable PCINT（性能计数器溢出？？？） if (((lapic[VER]&gt;&gt;16) &amp; 0xFF) &gt;= 4) lapicw(PCINT, MASKED); // Map error interrupt to IRQ_ERROR. lapicw(ERROR, IRQ_OFFSET + IRQ_ERROR); // Clear error status register (requires back-to-back writes). lapicw(ESR, 0); lapicw(ESR, 0); // Ack any outstanding interrupts. lapicw(EOI, 0); // Send an Init Level De-Assert to synchronize arbitration ID's. //#define ICRHI (0x0310/4) // Interrupt Command [63:32] //#define INIT 0x00000500 // INIT/RESET //#define DELIVS 0x00001000 // Delivery status //#define LEVEL 0x00008000 // Level triggered //#define BCAST 0x00080000 // Send to all APICs, including self. lapicw(ICRHI, 0); lapicw(ICRLO, BCAST | INIT | LEVEL); while(lapic[ICRLO] &amp; DELIVS) ; // Enable interrupts on the APIC (but not on the processor). //TPR 任务优先级 lapicw(TPR, 0);&#125; 该函数初始化LAPIC。像其他结构一样，lapic被映射到固定的物理地址，随后进行各种中断向量的设置以及向量表的mask操作，设置错误状态寄存器的值，最后设置任务优先级。 像VGA设备一样，物理地址空间上也为LAPIC设备留了一个洞，它将会被map到虚拟地址的MMIOBASE。这种访问方式使得CPU可以像访问内存一样访问设备。 Exercise 1 完成mmio_map_region函数，它将会完成把LAPIC设备所占据的物理地址map到预留的虚拟地址部分。 1234567891011121314151617181920212223242526272829303132333435363738394041424344void *mmio_map_region(physaddr_t pa, size_t size)&#123; // Where to start the next region. Initially, this is the // beginning of the MMIO region. Because this is static, its // value will be preserved between calls to mmio_map_region // (just like nextfree in boot_alloc). //这是mmio开始的地方 static uintptr_t base = MMIOBASE; // Reserve size bytes of virtual memory starting at base and // map physical pages [pa,pa+size) to virtual addresses // [base,base+size). Since this is device memory and not // regular DRAM, you'll have to tell the CPU that it isn't // safe to cache access to this memory. Luckily, the page // tables provide bits for this purpose; simply create the // mapping with PTE_PCD|PTE_PWT (cache-disable and // write-through) in addition to PTE_W. (If you're interested // in more details on this, see section 10.5 of IA32 volume // 3A.) //保留虚拟内存的的size字节，并把物理地址pa，pa+size给map到base,base+size， //由于这是设备的内存，并不是dram，需要告诉cpu缓存到这里的access是不安全的， //幸运的是，页表提供了这样的位 //只需要使用PTE_PCD|PTE_PWT|PTE_W即可 //如果你对这个很有兴趣，可以去看10.5节，IA32 卷3A // Be sure to round size up to a multiple of PGSIZE and to // handle if this reservation would overflow MMIOLIM (it's // okay to simply panic if this happens). //确保你roundsizeup //确保你检测是不是会超过MMIOLIM，如果超过了，panic // Hint: The staff solution uses boot_map_region. //使用boot_map_region // Your code here: //Note:pa=5 size=7 pgsize=10 //actually endsp shall be 20 uint32_t endsp=ROUNDUP(size+pa,PGSIZE); pa=ROUNDDOWN(pa,PGSIZE); size=endsp-pa; if(base+size&gt;MMIOLIM)panic("the reservation would overflow MMIOLIM"); boot_map_region(kern_pgdir,base,size,pa,PTE_PCD|PTE_PWT|PTE_W); //panic("mmio_map_region not implemented"); // base+=size; return (void*)(base-size);&#125; &gt; 这里需要注意的是size与paddr的关系。由于最终覆盖到的地址应该在size+paddr，因此不能使用ROUNDDOWN(paddr)与ROUNDUP(size)直接做运算，否则可能会产生缺页的情况。 Application Processor Bootstrap在i386_init函数中，本实验又增加了新的初始化过程： 在启动AP之前，BSP将会首先去获知多处理器的信息，比如CPU总数，他们各自的APIC编号以及LAPIC的MMIO地址。kern/mpconfig.c中的mp_init函数通过访问MP配置表来获知这些信息。随后，lapic_init初始化LAPIC设备，pic_init在更底层的部分初始化8259A的中断控制器。最后boot_aps函数(kern/init.c)将会启动各个AP，使他们从MPENTRY_PADDR开始运行。 boot_aps函数如下： 可以看到，BSP首先将AP启动后执行的代码搬到AP的启动位置code，随后逐个唤醒AP。对每一个AP，将会告诉它它的内核栈的位置，随后调用lapic_statrap(kern/lapic.c)。lapic_startap的代码在上方已经贴出，它为CPU设置各种中断信息并最终给出STRATUP信号表明AP已经设置完成，随后AP开始从给定地址开始运行。进入mpentry.S的运行，设置initial页表并转入自己的内核栈，随后调用mp_main函数，设置页表，初始化LAPIC、GDT以及trap，随后告诉boot_aps这个CPU设置完毕，boot_aps接收到AP的信息之后，进入下一个AP的初始化。 随后就像在Lab3中的那样，调用用户程序。 Exercise 2 修改page_init函数，不再将从MPENTRY_PADDR开始的虚拟地址添加到可用页上，给出更新后的函数： Question Compare kern/mpentry.S side by side with boot/boot.S. Bearing in mind that kern/mpentry.S is compiled and linked to run above KERNBASE just like everything else in the kernel, what is the purpose of macro MPBOOTPHYS? Why is it necessary in kern/mpentry.S but not in boot/boot.S? In other words, what could go wrong if it were omitted in kern/mpentry.S? Hint: recall the differences between the link address and the load address that we have discussed in Lab 1. MPBOOTYPHYS的目的是计算应该访问的地址。与boot.S不同，在mpentry.S中启动的AP，其load进的地址并不是像boot一样与假设自己被加载进来的地址相同，而是被BSP加载到MPENTRY_PADDR。为了访问到正确的物理地址，应该换算成希望加载进来的地址再进行对地址的操作。 Per-CPU State and Initialization在多CPU的系统中，需要明确每个CPU私有的状态以及共有的资源划分。在kern/cpu.h中定义的CpuInfo结构存储有大部分的私有信息。thiscpu指向当前cpu的CpuInfo结构。 Exercise 3修改mem_init_mp函数，为每个CPU map一个内核栈。 像在memlayout.h中定义的那样，补充后的代码是： Exercise 4 修改trap_init_percpu使得在多CPU环境下可以运行 代码： 这段代码中一共有四个需要修改的地方，一是所有的ts应该修改为thiscpu-&gt;ts，而是栈顶应该由KSTACKTOP-(KSTKSIZE + KSTKGAP)变为KSTACKTOP-i*(KSTKSIZE + KSTKGAP)，三是gdt中tss表项位置应该由[(GD_TSS0 &gt;&gt; 3)变为[(GD_TSS0 &gt;&gt; 3)+i，四是load选择子的时候应该修改为对应cpu的选择子ltr(GD_TSS0+i*8);。 这样就完成了不同CPU的trap初始化。 完成这里的操作之后，make qemu CPUS=4，可以看到所有函数检查通过，CPU信息输出。 Locking上述完成之后，代码将会停在原地。为了使得AP能够进一步运行，需要首先解决多个CPU同时运行内核代码的竞争状况。为了解决这个问题，采用内核锁机制。当有进程在内核空间时，内核将会上一个锁，回到用户空间后，锁被释放。 在kern/spinlock.h中定义了一个kernel_lock，提供了lock_kernel与unlock_kernel函数。需要我们自己来决定加锁解锁的位置。 Exercise 5加锁与解锁 在i386_init中，在BSP唤醒其他CPU之前加锁： 在mp_main中，在AP初始化之后加锁，然后调用sched_yield来开始调度。 在trap中，如果是从用户模式来的trap，就获得锁。 在env_run中，在进入用户模式的时候释放锁 Question It seems that using the big kernel lock guarantees that only one CPU can run the kernel code at a time. Why do we still need separate kernel stacks for each CPU? Describe a scenario in which using a shared kernel stack will go wrong, even with the protection of the big kernel lock. 这是因为在lab3中已经写过，当用户进程发生中断的时候，执行的代码中有：这段代码是产生中断之后硬件自己就会执行的，在这个时候仍未调用trap，自然还没有为内核加锁。也就是说，如果使用同一个栈，当两个cpu同时发生中断的时候，这段代码很可能会被打断执行顺序，从而导致内核栈的混乱。 Round-Robin Scheduling接下来，将会修改调度过程的代码，来为jos添加调度的功能。 在这里，这个功能会被描述为： 函数shced_yield负责选择一个新进程运行，它从当前运行进程的编号开始寻找，找第一个有着ENV_RUNNABLE的进程把运行权交付给它。如果没有其他进程是ENV_RUNNABLE状态而且现在的进程还可以运行，那就还让现在的进程运行。 Exercise 6 修改该sched_yield函数： 需要注意的是，这时syscall函数仍未被完成，需要在此后陆续添加更多的SYS_*来允许用户空间的系统调用。 随后可以测试，修改i386_init函数，创建3个进程： 使用make qemu CPUS=2，可以得到结果： Question In your implementation of env_run() you should have called lcr3(). Before and after the call to lcr3(), your code makes references (at least it should) to the variable e, the argument to env_run. Upon loading the %cr3 register, the addressing context used by the MMU is instantly changed. But a virtual address (namely e) has meaning relative to a given address context–the address context specifies the physical address to which the virtual address maps. Why can the pointer e be dereferenced both before and after the addressing switch? e所指示的空间是在mem_init中被申请的物理空间，它并不会存在于每个进程的可用页表里供进程自己决定map的虚拟地址，而是对每个进程而言都是一样的。 Whenever the kernel switches from one environment to another, it must ensure the old environment’s registers are saved so they can be restored properly later. Why? Where does this happen? 只有这样做，才能保存上一个进程的运行状态信息，恢复进程运行时才不会出错。这个操作发生在trap函数中，代码是这样的：它保存了发生trap的进程的tf。然而，进程之间切换由kernel决定。每次发生进程调度，都会发生trap（这里将syscall主动放弃cpu也通过trap完成） System Calls for Environment Creation下面将允许用户进程创建子进程并执行。 在Unix中，fork函数可以用来创建子进程。这个子进程完全copy了父进程的地址空间，二者唯一不同的是在父进程中fork返回子进程的编号而在子进程中返回的是0。 我们将实现一个更加原始的fork，首先需要完成一些系统调用函数。在这些个函数之中，需要频繁用到函数envid2env来检查进程操作是否合法，首先来分析这个envid2env函数： 如果envid是0，说明是当前进程希望获得自己的env结构，直接允许获得，返回curenv，函数成功。如果给的envid不合法或者指定进程是free进程，无法得到进程结构，返回bad environment。否则如果指定需要检查权限，那么给定的envid必须是当前进程的子进程，如果满足要求返回成功，否则返回失败：bad environment。 Exercise 7： 只需要按照要求完成代码： sys_exofork：创建一个新进程，其中，用户地址空间没有任何map，不可以运行。子进程将会拥有和父进程一样的寄存器状态值，该函数在子进程中返回0，在父进程中返回子进程的id。（由于子进程刚刚被创建的时候是没有执行能力的，因此实际上，在子进程中是无法返回的，直到其父进程用下面的函数将子进程标记为可运行）代码： sys_env_set_status：设置一个进程的状态为ENV_RUNNABLE或者是ENV_NOT_RUNNABLE。代码： sys_page_alloc：申请一个物理页并把它map在给定进程的给定地址。代码： sys_page_map：把给定进程的某一个页的映射同样映射到另一个进程的给定地址，这样，这两个进程享有了共享的一个物理页。代码： sys_page_unmap：把某一个页从某一个进程的对应地址上unmap。代码： 完成这些之后，partA的dumbfork测试就可以通过了。 Part B: Copy-on-Write Fork像在前面提到的一样，Unix提供了fork函数，这个函数将会复制整个父进程的地址空间。xv6 Unix的fork将会复制父进程的所有页到新的页，这也是在dumbfork里面做的。但是，这样的操作耗时而且通常都是无用功：创建出的子进程可能很快就会被父进程委派去做其他的工作，子进程的地址空间很快会被新的数据取代。 出于这种考虑，现在来实现一种新的特性，子进程与父进程将享有同一套地址空间，直到有进程真的要去修改这块空间。这样的技术叫做copy-on-write。 在这种特性之下，当创建子进程的时候，父进程仅仅将自己的映射关系给子进程，同时把自己共享出去的页都标记为只读。当有一方想要修改该虚拟地址空间时触发一个page fault，这时，内核才真正意识到需要一个新的页，这时才会去为发生错误的进程申请一个自己的页。这样的设计使得子进程在执行之前花费的代价很少，一般只会有一个栈的页。 User-level page fault handling用户层面的缺页异常有很多种引起的可能，cow只是其中的一种。内核必须能够决定为不同程序空间引起的缺页异常提供不一样的解决方式，比如，在栈中发生的缺页异常需要申请并map一个物理页，在bss区域引起的缺页中断会申请一个全0的物理页然后映射。 对内核来说，有很多信息都可以作为判断依据，接下来，将完成我们的pgfault处理函数。 Setting the Page Fault Handler为了处理缺页中断，用户进程需要向内核注册并存储自己的缺页中断处理函数的入口点。为了实现这个功能，在Env结构中新加了成员env_pgfault_upcall。 Exercise 8：完成函数sys_env_set_pgfault_upcall，确保进行了权限检查。 根据提示，该函数为特定进程设置一个缺页中断处理函数。这个进程必须是自己或者是自己的子进程。写出代码： Normal and Exception Stacks in User Environments在正常的执行中，用户进程将会在用户栈中执行，esp指向栈顶，当一个缺页中断发生的时候，内核将会使用户进程重新在另一个栈中运行缺页中断的处理函数。也就是，我们需要使内核能够自动换栈。 异常栈有一个page大小，最顶端是UXSTACKTOP。因此，第一个中断发生后将会空间UXSTACKTOP-PGSIZE到UXSTACKTOP之间作为异常栈。在处理函数中可以通过各种调用恢复原进程的正确执行，随后该函数返回，回到上次发生中断的地方，重新执行出错代码。每一个希望有用户层次的缺页中断处理函数的进程都必须支持申请新页来作为他自己的异常栈。 Invoking the User Page Fault Handler接下来我们要修改trap中的代码，使它有以下的功能。 如果这个用户进程并没有自己的缺页中断处理函数，当他有缺页中断发生的时候，就销毁这个进程然后退出，否则。 异常栈中的情况是这样的： UXSTTACKTOP是栈底，依次push进了许多变量，他们与结构UTrapframe吻合。函数执行结束后，需要从异常栈返回原本的用户栈。 实际情况中可能更加复杂：缺页中断额处理函数本身还可能会发生中断，这时，继续往栈顶push数据，但是需要注意，由于一些原因，需要先push一个32bit的空位。这个将会在后面进行解释。如果tf-&gt;tf_esp在上述区域之中，那么就是在异常栈中发生的缺页中断，否则就是在原本的用户进程中发生的中断。 Exercise 9 完成函数page_fault_handler。他需要将用户空间的缺页中断给用户的处理函数。 首先，只有有处理函数才能进行下一步的操作，否则将会free掉这个进程。随后确定将要push的结构的首地址。如果当前进程可以访问这个地址，那么就把对应的地址写为对应的值，保存好之前执行状态的信息。保存完之后，将程序的下一个执行地址设置为函数的入口地址，将该进程的栈顶设置为异常栈的栈顶，运行。 User-mode Page Fault Entrypoint接下来，需要我们完成执行C程序并且返回到原执行状态的汇编指令，该汇编指令是sys_env_set_pgfault_upcall的处理过程。 Exercise 10：完成lib/pfentry.S中的_pgfault_upcall过程。 只需要根据提示，结合上述的异常栈动作： 最后，完成C程序库部分的缺页异常处理机制： Exercise 11：完成lib/pgfault.c中的set_pgfault_handler函数： Implementing Copy-on-Write Forkfork函数是一个cow的子进程创建函数，它的控制流程是这样的： 使用set_pgfault_handler来确定中断处理函数C程序层面的入口 调用sys_exofork创建一个新进程 对每一个可写的或是cow的在UTOP之下的页，父进程为之调用duppage函数，这个函数将会把cow的页map到子进程地址空间，然后重新在自己的地址空间map这些页。 父进程为子进程设置缺页中断处理函数入口点 子进程可以运行了，父进程将其标志为RUNNABLE 之后，每次想要修改cow页面都会触发缺页中断，触发之后过程如下： kernel把pagefault告诉_pgfault_upcall，执行入口调用pgfault函数 pgfault检查错误是写错误而且页面是cow，否则panic pgfault申请新的页，map到一个临时地址，把出错的页面信息copy到新的页面，随后把新页map到一个合适的地址。 kernle会把进程的页表都map到UVPT页目录map到UVPD，方便根据虚拟地址获取对应页的权限信息。首先我们先来看一看这个小技巧。 在内核中可以使用函数pgdir_walk获得权限信息，但是在用户空间，虚拟地址的翻译决定了自身的页表与页目录是不可见的。为了方便的获取权限信息，我们向用户进程的页目录中插入一个特殊的entry。这个entry指向页目录的首部。 这样，当我们访问一个PDX与PTX均是特定数值V的虚拟地址时，我们访问到了页目录。这个地址作为指针数组的开头，使用某虚拟地址的PDX作为索引，使我们可以访问到页目录的各项。 当我们访问一个PDX是V但是PTX不是V的虚拟地址时，我们访问到了页表。同样地我们可以访问到各个页表项。 上述提到的两个虚拟地址分别是UVPD与UVPT。在memlayout.h中定义。 Exercise 12：完成frok，duppage以及pgfault。 partB到这里就结束了，在进入partC之前，首先来梳理一下从fork开始的整个运行过程。 当一个用户进程调用fork函数创建子进程，在fork中将申请一个新的进程，复制父进程的地址空间映射给子进程并把二者空间中的对应页都标记为cow，随后父进程为子进程申请用户栈，设置缺页处理过程入口点，最终将子进程的状态标记为可运行。fork退出后将得到两个可运行的进程，在子进程中fork函数返回的是0，在父进程中返回的是子进程的进程id，随后二者可以区分开开始运行。 子进程开始运行其他东西或是父进程需要写数据的时候，其中一个必然会触发一个cow的缺页中断。这个进程的缺页中断经过内核dispatch，将会执行我们在trap中完成的处理函数，假设它已经设置了自己的处理函数，那么就会创建一个异常栈，开始执行在pfentry.S中的汇编代码，执行完毕之后返回原来发生错误的执行位置，继续执行。 Part C: Preemptive Multitasking and Inter-Process communication (IPC)Clock Interrupts and Preemption在此之前，我们不同进程之间的调度都是自愿的。下面将通过引入时钟中断来强制进行调度。 Interrupt discipline外部中断在本实验中一共有16个，标号是32-47。在本实验中，内核中的外部中断被忽略，在用户空间中通过设置FL_IF来设置允许外部中断。 Exercise 13：修改trapentry.S以及trap.c来初始化上述的中断，然后修改该env_alloc允许用户空间的外部中断 像上一个实验一样即可： 只需在指定的位置将新建的env的tf_eflags修改为FL_IF允许即可。 Handling Clock Interrupts在lapic_init以及pic_init中，已经设置好了产生时钟中断，下面需要处理时钟中断。 Exercise 14：修改trap_dispatch，它调用sched_yield。直接给出代码： Inter-Process communication (IPC)进程间的通信有很多种模型，这里只实现简单的一种。 IPC in JOS这里进程可以相互发送或接收的信息有：一个32bit的数据或是一整个页。整个页的发送是通过共享内存来实现的，这在下面将具体说明。 Sending and Receiving Messages为了接收数据，进程将调用sys_ipc_recv。这个系统调用使这个进程不可运行，直到收到数据。当进程等待接收消息时，任何其他进程都可以向其发送消息不会检查权限。 为了尝试发送一个值，一个环境调用sys_ipc_try_send与接收者的环境ID和要发送的值。如果指定的环境实际上正在接收（它已经调用sys_ipc_recv并且还没有获得值），则发送递送消息并返回0.否则发送返回-E_IPC_NOT_RECV以指示目标环境当前不期望接收值。 Transferring Pages当进程使用小于UTOP的dstva调用sys_ipc_recv时，表明它愿意接收页面映射。如果发送者发送一个页面，那么该页面应该被映射到接收者地址空间中的dstva。如果接收者已经有了一个映射到dstva的页面，那么这个页面被unmap。 当环境使用小于UTOP的srcva调用sys_ipc_try_send时，说明发送者想要发送当前映射到srcva（发送者）的页面到接收者，具有权限perm。在一个成功的IPC之后，发送者在srcva的地址空间保留其原始的映射，但是接收者也在接收者的地址空间中获得了原来由接收者指定的dstva的同一物理页面的映射。结果这个页面在发送者和接收者之间被共享。 如果发送者或接收者不指示应该传送页面，则不传送页面。在任何IPC之后，内核将接收方的Env结构中的新字段env_ipc_perm设置为所接收页面的权限，如果没有收到页面，则为零。 Implementing IPC Exercise 15：根据说明补充syscall与ipc中的函数： 本实验结束。]]></content>
      <categories>
        <category>OS</category>
        <category>MIT Lab</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的编译器]]></title>
    <url>%2F2017%2F12%2F02%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%2F%E6%88%91%E7%9A%84%E7%BC%96%E8%AF%91%E5%99%A8%2F</url>
    <content type="text"><![CDATA[我的编译器password: password 环境配置PG的配置VS属性的配置好了，这时在PG中的任务已经完成了，接下来想要使用VS来执行PG生成的程序，还需要进行一些属性的配置。多种组合可行。这里只说明了我自己用的一种组合，路径也以我的电脑为准。我的机器VS2015，win10。 在属性页面添加： 配置属性 -&gt; VC++目录 -&gt; 包含目录：D:/Program Files（x86）/Parser Generator 2/Cpp/Include 配置属性 -&gt; VC++目录 -&gt; 库目录：D:/Program Files（x86）/Parser Generator 2/Cpp/Lib C/C++ -&gt; 预处理器 -&gt; 预处理器定义：YYDEBUG,_MBCS; C/C++ -&gt; 代码生成 -&gt;运行库：多线程调试(/MTd) 链接器 -&gt; 输入 -&gt; 附加依赖项：ylmtd.lib; 是YYDEBUG,_MBCS;中间是逗号。 $$\color{red}{注意！上述除了“多线程调试”，其他均是在原有的基础上添加。}$$ 语法分析部分lex与yacc的结合lipeng的结合参考算了。没什么特别大的参考价值，他的着重点与我的不同。 oracle的文档：lex IBM的文档：lex–最终问题在这里面解决。查看其“结合”部分。 在lex中没有main函数，yylval是在lex中定义的一个变量，使用extern YYSTYPE yylval在yacc中使用。 “default”标签跳过“ ”的初始化操作编译器错误C2361:“default”标签跳过“ ”的初始化操作&amp;rd=true)“default”标签跳过“ ”的初始化操作解决 出现“default”标签跳过yylval的初始化操作的原因是：在lex中，我把rule section的正则语义动作定义段写在了对yylval的extract之前。只要挪到后面，这个错误就不见了。（这个看一看在cpp中的错误代码就能发现异常。） yylval：无法解析的外部符号写错地方了。yylval是在yacc里面的，写extern应该在lex里面写。 在yacc中无需用到yylval，这是因为在语义动作上，比如NUMBER，如果不写他的语义动作，他将会自动把产生式左部的值赋为与NUMBER一起给yacc的yylval的值。 成功！现在来总结一下叭！ 现在拥有：一个yacc文件名叫myparser.y，一个lex文件名叫mylexer.l。创建了一个新的既有lex又有yacc的项目。把原来lex中的除了main函数之外的东西拷贝到新程序的对应位置（不建议直接全部复制，因为可能会有细小问题出现。特别注意你在生成project的时候定义的lexer的名字！）注意上面提到过的那个rule section的问题。在lexer的include句之后定义extern string yylval（我这里使用string只是因为我的YYSTYPE是string，我的不能直接使用宏YYSTYPE）在lex的匹配语义动作中加上对yylval的赋值（yylval=yytext;这句将匹配对应的字符串给yylval。同样因为我的yylval是string，不是string可以自己转换一下。在lex的语义动作最后加上return NUBER;（NUBER只是一个例子，应该返回这个匹配对应的token。把原来yacc中的代码拷到新程序的对应位置（同样不建议直接全部复制。如果原来不懂yylavl的意义，在单token行也写了语义动作赋值，把这个语义动作删掉，或者使用\$1对这个值做你想要的处理之后赋给\$\$。好了！生成之后，在VS项目中运行就好啦！ 符号表的设计由于支持函数类等操作，所以要增加多个生存期作用域，需要多个符号表。这些符号表将动态生成，压进栈中。这也是考虑到作用域的特性。另一方面，由于作用域与语法相关，符号表的创建（除了全局符号表）在yacc中完成。yacc获取栈，lex获取栈，共同操作。 C++标准库栈上述链接其实没什么特别多的东西，记住两点三函数： 使用stack需要包括头文件#include&lt;stack&gt; 这是个模板类，使用时指定类型：stack&lt;CHash*&gt; mystack; 函数们： 函数名 作用 top() 返回栈顶元素，不弹出 pop() 弹出栈顶元素，不返回 push(member) 将member压栈 size() 返回栈中元素个数 empty() 检查栈是不是空 简直是救星！string CString int char等互转 语法树的生成C++的文件操作 这次的作业我走了很多弯路，主要一点就是没有搞清楚自己究竟要干什么。这次作业的重点在于“语法树生成”。 编译器对函数的处理YACC部分注意：yacc中的文法定义顺序是非常有关系的。不一样的顺序将会带来不一样的结果。越靠上的文法，越会先被匹配。在添加产生式的过程中出现了”rules are never reduced”。在第一次写作业时也出现了，但是那时没有好好积累。shift在这里是”移入“，reduce是”归约“。这是LR算法中的语言。 理解”rules are never reduced”-stackoverflow not getting reduced rules are never reduced 总结上述的一些： 可能是因为指出的那个没有在右边出现过。 可能是在前面的某个产生式包括了这个产生式的情况，所以不能被匹配。 你的递归没有办法被终止。 yacc似乎会将第一个产生式左部作为开始符号。 In general, you want to use the -v option to get yacc to prodcue a y.output file with detailed information about your grammar. This file will tell you specifically about all the conflicts and unused rules – what they are and how they come about – while the messages just give you a summary of the problems.(使用-v选项来获取更详细的输出信息。) 有时即使没有错误或者警告，程序也运行不出来，大概是匹配了不是本意的文法，自己看吧。我心情不好。一直感觉文法是对的，一直运行不出来。我的lex没有返回一些token给yacc。能运行就怪了。 没有好好理解VS里面.h与.cpp，不要随便在里面写一些函数，然后包括去使用。 LEX部分]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[琐碎]]></title>
    <url>%2F2017%2F12%2F02%2F%E7%90%90%E7%A2%8E%2F</url>
    <content type="text"><![CDATA[git的beanch原来真的可以在本地也切换啊！当我用git checkout lab3的时候，文件夹里的东西也会跟着变。这也就解释了，为什么我明明从写好的lab3复制文件到lab4的lab3却没反应，因为我根本就没有复制到la4文件夹的lab3分支！首先进入lab3再复制，最后进入lab4分支，指定merge lab3分支，成功！。 GIT分支 干什么 句子 删除本地的一个分支 git branch -d 新增加一个分支 git checkout -b 删除远程分支 git push -delete 我见过的错误解决方法 在 git merge lab3之后产生冲突，人为解决之后再次merge无法merge：只需根据提示： 123git add .git commit -m &quot;mesage&quot;git merge lab3 VScmd运行完之后闪退可以通过更改属性的方式解决。什么system(“pause”)啊也行吧，但是我觉得没有属性来的方便永久。 “配置属性”–&gt;“链接器”–&gt;“系统”，然后在右侧的列表中，在第一项”子系统“的值中选择”控制台（/SUBSUSTEM:CONSOLE）“。]]></content>
      <categories>
        <category>琐碎</category>
      </categories>
      <tags>
        <tag>all</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译原理——语法分析]]></title>
    <url>%2F2017%2F11%2F29%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%2F%E8%AF%AD%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[语法分析终于开始语法分析的复习了！ 上下文无关文法：1. 便于扩充语言特性 2. 语法容易被理解 3. 检错机制加入（其他就不行？） 语法分析器的位置（等待加图） 通用的语法分析器几乎是不可能保证效率的（目前有通用的语法分析器，Cocke-Younger-Kasami），目前有两种算法，自底向上（对应最左推导LL），自顶向下（对应最右推导LR）。 语法错误处理在编程中可能会发生不同的错误，在词法（拼写错误）、语法（单词漏写、顺序错误）、语义、逻辑上都可能会发生错误，其中，语法错误相对较多，成为检查重点。 对语法错误的分析相对简单：它具有可行前缀/活前缀特性，在使用给定词法串前缀加上一些字符不能构成该语法的正确语言串时，就会发生错误。 处理错误有三个目标：清楚报告出现的错误、快速从错误中恢复、不能对正确程序的编译处理造成太大的影响。 给出一个报告错误的方法：打印出有问题的那行 -&gt; 给出一个错误所在地的指针 错误处理一般在于自圆其说。很难清晰的预测程序员原本的意图，只需要报告最一般的错误可能。 错误恢复策略Panic模式：遇到错误之后，不断丢弃输入中的符号。直到发现$\color{red}{同步词法单元}$集合中的符号。 $\color{red}{同步词法单元}$：通常是界限符，比如分号、右大括号。他们的意图清晰，没有二义性。编译器的设计这必须为自己的编译器定义合适的同步词法单元。 panic模式可能会丢掉很多正常输入（这些失去的分析有可能会影响接下来的分析），但是这种模式很简单，能够保证不会进入无限循环。接下来的几个方法都不能保证。 短语级：局部修正，继续分析。比如，可能会做一些逗号换分号，加减分号的操作。已经在一些修复型编译器中使用。 需要避免进入无限循环。比如设定是”在有错误的串前面加一个分号“，就可能会一直循环下去。 可以与panic结合，避免丢弃太多单词。 错误产生式：描述错误模式。 可以更好的进行修正，检测错误信息。 全局修正：x 上下文无关文法正式定义一个上下文无关文法由终结符、非终结符、一个开始符号、一组产生式组成。使用符号描述是：$(V{T} , V{N} , S , p)$ 在文法中有一些约定的命名方式（待补充） 推导实际上是语法等价的一个替换过程。使用右部替换左部。 形式化定义：$$\alphaA\beta \Rightarrow \alpha\gama\beta 当且仅当存在 A \rightarrow \gama$$ $$ $$ 推导与语言最左推导：总是替换最左边的非终结符 最右推导：总是替换最右边的非终结符 形式化定义： 推导与语法分析树一颗语法树可能会对应多个推导过程。如果限制了最左或者最右，那么一个语法树就只能对应一个推导。 CFG设计正则表达式可描述符号串$\in$GFG可描述字符串 NFA-&gt;CFG在CFG，与正则不同的是：CFG的开始符号是所有，正则的终态是空串；CFG的终态是空串，正则的终态是所有。 因此： 终态：$A_i \rightarrow \epsilon$ 形如xy(x!=y)的01串：（不能用正则） 奇数串：S-&gt;B|BSB B-&gt;0|1 偶数串：拆成两个穿拼接形式。只要两个奇数串中心位置不同，拼出的偶数串就符合上述描述。给出证明： 证明： CFG验证证明CFG G生成语言L：互相包含。 一个例子（略） CFG修改 去错 重写：满足特殊要求 $$不合要求的问题\begin{cases}二义性 \\epsilon-moves \回路 \左递归 \提取左公因子\end{cases}$$ 消除二义性]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译原理——语法分析]]></title>
    <url>%2F2017%2F11%2F29%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%2F%E8%AF%AD%E6%B3%95%E5%88%B6%E5%AF%BC%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[Tiny C中的语法树：节点分为两类 语句 表达式 语句还可以细分，表达式还可以细分。 注意，有些叶节点是不需要保存的。比如说if statement，if ( ) else都可以不需要保存。 具体创建树有两种，一种是递归下降的形式，另一种是yacc的形式，与语法制导定义相似。 （哇那我很多都写错了…这两天是白干了吗…）]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lab3_Document]]></title>
    <url>%2F2017%2F11%2F27%2FOS%2FLab3_Document%2F</url>
    <content type="text"><![CDATA[Lab3 DocumentPart A：User Enviornments and Exception Handling在这一部分，首先需要了解关于在本实验中env（进程）的相关定义： 12345678//in inc/env.henum &#123; ENV_FREE = 0, ENV_DYING, ENV_RUNNABLE, ENV_RUNNING, ENV_NOT_RUNNABLE&#125;; 这是在本实验中定义的进程状态，在实验中，仅用到了ENV_FREE、ENV_RUNNABLE、以及ENV_RUNNING。 类似于课上讲的pcb，在本实验中对一个进程的描述定义如下： //in inc/env.c 第一个变量env_tf是当中断或异常或系统调用发生的时候，该进程需要保存的寄存器的值；最后一个变量指明了该进程的地址空间。 在kern/env.c中可以看到，关于进程，有三个全局的变量： 123struct Env *envs = NULL;// All environmentsstruct Env *curenv = NULL;// The current envstatic struct Env *env_free_list;// Free environment list 在马上进行的初始化之后，在envs所标识的物理地址开始，一直到NENV\*(struct Env)结束，是所有可以被使用的进程描述结构占用的空间，每一个(struct Env)大小都是一个可用的Env描述。curenv被指示为是当前正在运行的进程。env_free_list指向第一个可以使用的进程描述结构，这样的设计使得进程描述结构的申请与销毁都变得很容易，而且由于该链表中存储的是处于ENV_FREE状态的进程，很少需要有添加删除的过程。 Allocating the Environments Array就像在实验二中那样，在这里需要修改pmap.c中的代码，为envs映射空间。仿照在lab2中的写法，修改程序如下： 12//in kern/pmap.c the first LAB3: Your code hereenvs=(struct Env\*)(boot\_alloc(NENV\*sizeof(struct Env)));//为Env结构申请空间 1234//in kern/pmap.c the second LAB3: Your code herefor(int i=0;i&lt;ROUNDUP(NENV\*sizeof(struct Env),PGSIZE);i+=PGSIZE)&#123; page_insert(kern_pgdir,(struct PageInfo\*)pa2page(PADDR(envs)+i),(void\*)(UENVS+i),PTE_U); &#125; 像在lab2中做过的那样，boot\_map\_region使得从PADDR(envs)开始，连续PTSIZE的物理空间映射到从UENVS开始的虚拟地址空间上。 做到这里尝试make qemu的时候，发现失败了。 注意：回想在lab2中所做的工作，在page_init函数中曾经为没有用的页面加入freelist。查看当时的代码发现，那时计算剩余空间的时候，是从为npages分配空间呢的后一页开始计算的。在mem_init中修改了之后的映射之后，这时的freelist应该从envs占用所有空间之后的第一页进行添加，于是修改代码如下： 1234567int begin=(int)ROUNDUP(((char*)envs) + (sizeof(struct Env) * NENV) - 0xf0000000, PGSIZE);for (i=begin/PGSIZE;i&lt;npages;i++)&#123; pages[i].pp_ref=0; pages[i].pp_link=page_free_list; page_free_list=&amp;pages[i];&#125; 再次make qemu，得到结果如下： Creating and Running Environments在这一部分，将会完善kern/env.c中的内容，来建立起一个进程操作的雏形。 由于还没有文件系统，这时我们用一个技巧来骗过boot loader，使得bootloader加载kernel的时候也把我们需要的用户程序加载进来。这些用户程序在user文件夹下。 首先， -b binary option告诉编译器只需要将程序编译成二进制文件，而不需要生成.o文件，随后把这个文件作为一个较大的数组放在最后，同时在真正应该被搬进内存的文件中声明extern变量，告诉编译器在链接之前先不要管这个。随后，在链接阶段，大数组已经被load进来，与其他代码一同进行地址映射。最终这里的代码可以被执行。 查看kern/init.c文件，发现在所有初始化之后有这样的语句： 1234567#if defined(TEST) // Don't touch -- used by grading script! ENV_CREATE(TEST, ENV_TYPE_USER);#else // Touch all you want. ENV_CREATE(user_testbss, ENV_TYPE_USER);#endif 这是告诉编译器：如果用户采用make qemu的方式运行，那么就创建一个user_testbss这样的用户进程，实际上就是执行testbss.c文件生成的那个binary。 在env完成之后对这里进行更深一步的讨论。 接下来需要写出下面几个函数的代码： env_init env_setup_vm region_alloc load_icode env_create env_run 12345678910111213141516171819202122232425262728293031// Mark all environments in 'envs' as free, set their env_ids to 0,// and insert them into the env_free_list.//把所有的envs设置成free的，他们的id都是0，然后插入freelist// Make sure the environments are in the free list in the same order// they are in the envs array (i.e., so that the first call to// env_alloc() returns envs[0]).//需要保证所有在freelist里面的env的顺序与在数组中的env相同？？？////本函数：初始化所有在env数组中的的env结构，把它们加到freelist里面，要求如上。//在meminit之后执行。//env数组：*envs，当前：*curenv，freelist：*env_free_listvoidenv_init(void)&#123; struct Env*current=NULL; int i=NENV-1; //一共NENV个env while(i&gt;=0)&#123; //NENV is defined in inc/env.h //current-&gt;env_tf=3; envs[i].env_id=0; envs[i].env_runs=0;// current-&gt;env_pgdir=NULL; envs[i].env_link=env_free_list; env_free_list=&amp;envs[i]; i--;&#125; // Per-CPU part of the initialization env_init_percpu(); cprintf("envinit done!\n");&#125; 这个函数比较简单，需要注意的一点是要求倒着添加到链表里面。其他只是按照要求写的代码。 这个函数在最后执行了一个已经完成的函数：env_init_percpu，如下图： 该函数完成对各个段寄存器的设置。 1234567891011121314151617181920212223242526272829303132333435363738//为进程e初始化内核虚拟空间static intenv_setup_vm(struct Env *e)&#123; int i; struct PageInfo *p = NULL; // Allocate a page for the page directory if (!(p = page_alloc(ALLOC_ZERO))) return -E_NO_MEM; // Now, set e-&gt;env_pgdir and initialize the page directory. //初始化pagedir？ // Hint: // - The VA space of all envs is identical above UTOP // (except at UVPT, which we've set below). // See inc/memlayout.h for permissions and layout. // Can you use kern_pgdir as a template? Hint: Yes. // (Make sure you got the permissions right in Lab 2.) //所有envs的虚拟地址空间都在UTOP之上 //查看inc/memlayout.h看许可以及布局 //可以使用kern_pgdir作为一个模板 // - The initial VA below UTOP is empty. // - You do not need to make any more calls to page_alloc. // - Note: In general, pp_ref is not maintained for // physical pages mapped only above UTOP, but env_pgdir // is an exception -- you need to increment env_pgdir's // pp_ref for env_free to work correctly. // - The functions in kern/pmap.h are handy. // LAB 3: Your code here. e-&gt;env_pgdir=(pde_t*)page2kva(p);//page2kva in pmap.c p-&gt;pp_ref++; memcpy(e-&gt;env_pgdir,kern_pgdir,PGSIZE);//kernel's e is the kernel's e //permission:RR //p[PDX(UTOP)] = PADDR(p) | PTE_U | PTE_P; // UVPT maps the env's own page table read-only. // Permissions: kernel R, user R e-&gt;env_pgdir[PDX(UVPT)] = PADDR(e-&gt;env_pgdir) | PTE_P | PTE_U; return 0;&#125; 123456789101112131415161718192021//为进程申请len字节的物理地址空间，然后把它map到vastatic voidregion_alloc(struct Env *e, void *va, size_t len)&#123; // LAB 3: Your code here. // (But only if you need it for load_icode.) // // Hint: It is easier to use region_alloc if the caller can pass // 'va' and 'len' values that are not page-aligned. //如果允许传入不是页对齐的va（虚拟地址）和len（长度）的话会更好一些 // You should round va down, and round (va + len) up. // (Watch out for corner-cases!) //什么叫corner-cases //获取首地址 //只是申请了页面，其实没有真正的物理空间 for(int i=(uint32_t)ROUNDDOWN(va,PGSIZE);i&lt;(uint32_t)ROUNDUP(va+len,PGSIZE);i+=PGSIZE)&#123; struct PageInfo*pa=page_alloc(0); if(pa==NULL)panic("fail to alloc !in region_alloc!"); page_insert(e-&gt;env_pgdir,pa,(void*)i,PTE_U|PTE_W); &#125;&#125; 该函数指定进程申请从指定虚拟地址开始的len字节空间。由于vs与va+len可能不是页面对齐的，因此真正在分配页面的时候，需要做操作ROUNDOWN与ROUNDUP来进行页面的对齐。当申请页面失败时，panic，否则就将页面插入到当前进程的pgdir中。 1234567891011121314151617181920212223242526272829303132333435363738static voidload_icode(struct Env *e, uint8_t *binary)//binary：ELF&#123;//注意，对应的用户数据已经在内存中了 struct Elf*elf=(struct Elf*)binary;//给定的ELF文件头结构（更详细的，查看inc/elf.h） struct Proghdr *ph, *eph;//ELF文件指定程序段的程序头 // is this a valid ELF? if (elf-&gt;e_magic != ELF_MAGIC) panic("not a elf!"); ph = (struct Proghdr *) ((uint8_t *) elf + elf-&gt;e_phoff);//第一个程序头开始 eph = ph + elf-&gt;e_phnum;//最后一个不是程序头结构开始的位置 lcr3(PADDR(e-&gt;env_pgdir));//将CR3中装载进去这次的页目录 for (; ph &lt; eph; ph++)&#123; if(ph-&gt;p_type==ELF_PROG_LOAD)&#123; region_alloc(e,(void*)ph-&gt;p_va,ph-&gt;p_memsz); //申请从ph-&gt;p_va程序假设自己所在的虚拟地址开始，到va+memsz结束的空间 memmove((void*)ph-&gt;p_va,binary+ph-&gt;p_offset,ph-&gt;p_filesz); // The ph-&gt;p_filesz bytes from the ELF binary, starting at // 'binary + ph-&gt;p_offset', should be copied to virtual address // ph-&gt;p_va. Any remaining memory bytes should be cleared to zero. // (The ELF header should have ph-&gt;p_filesz &lt;= ph-&gt;p_memsz.) // Use functions from the previous lab to allocate and map pages. //在ELF中的ph-&gt;p_filesz字节的，从binary+ph-&gt;p_offset都应该被copy到虚拟地址空间ph-&gt;p_va //任何剩余的空间被清零 memset((void*)(ph-&gt;p_va+ph-&gt;p_filesz),0,ph-&gt;p_memsz-ph-&gt;p_filesz);//eme2file //memcpy((void*)ph-&gt;p_va,binary+ph-&gt;p_offset,ph-&gt;p_filesz); &#125; &#125;//after modification , everything is OK! // call the entry point from the ELF header // note: does not return! //((void (*)(void)) (ELFHDR-&gt;e_entry))(); e-&gt;env_tf.tf_eip=elf-&gt;e_entry; // Now map one page for the program's initial stack // at virtual address USTACKTOP - PGSIZE. // LAB 3: Your code here. region_alloc(e,(void*)(USTACKTOP-PGSIZE),PGSIZE); lcr3(PADDR(kern_pgdir));&#125; 该函数负责把已经装入内存的binary文件重新装载到ELF文件头中指定的位置，并为用户进程创建一个栈。 123456789101112voidenv_create(uint8_t *binary, enum EnvType type)&#123; // LAB 3: Your code here. struct Env *newenv_store; int result=env_alloc(&amp;newenv_store,0); if(result&lt;0)panic("env_alloc: %e", result); ; if(result==0)&#123; newenv_store-&gt;env_type=type; load_icode(newenv_store,binary); &#125;&#125; 这里使用到了已经定义好的函数：env_alloc。env_create本身比较简单，我们来看一下env_alloc： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647intenv_alloc(struct Env **newenv_store, envid_t parent_id)&#123; int32_t generation; int r; struct Env *e; //没有新的可以用了 if (!(e = env_free_list)) return -E_NO_FREE_ENV; // Allocate and set up the page directory for this environment. if ((r = env_setup_vm(e)) &lt; 0) return r; // Generate an env_id for this environment. generation = (e-&gt;env_id + (1 &lt;&lt; ENVGENSHIFT)) &amp; ~(NENV - 1); if (generation &lt;= 0) // Don't create a negative env_id. generation = 1 &lt;&lt; ENVGENSHIFT; e-&gt;env_id = generation | (e - envs); // Set the basic status variables. e-&gt;env_parent_id = parent_id; e-&gt;env_type = ENV_TYPE_USER; e-&gt;env_status = ENV_RUNNABLE; e-&gt;env_runs = 0; // Clear out all the saved register state, // to prevent the register values // of a prior environment inhabiting this Env structure // from "leaking" into our new environment. memset(&amp;e-&gt;env_tf, 0, sizeof(e-&gt;env_tf)); // Set up appropriate initial values for the segment registers. // GD_UD is the user data segment selector in the GDT, and // GD_UT is the user text segment selector (see inc/memlayout.h). // The low 2 bits of each segment register contains the // Requestor Privilege Level (RPL); 3 means user mode. When // we switch privilege levels, the hardware does various // checks involving the RPL and the Descriptor Privilege Level // (DPL) stored in the descriptors themselves. e-&gt;env_tf.tf_ds = GD_UD | 3; e-&gt;env_tf.tf_es = GD_UD | 3; e-&gt;env_tf.tf_ss = GD_UD | 3; e-&gt;env_tf.tf_esp = USTACKTOP; e-&gt;env_tf.tf_cs = GD_UT | 3; // You will set e-&gt;env_tf.tf_eip later. // commit the allocation env_free_list = e-&gt;env_link; *newenv_store = e; cprintf("[%08x] new env %08x\n", curenv ? curenv-&gt;env_id : 0, e-&gt;env_id); return 0;&#125; 该函数完成一系列的初始化操作，申请新进程，地址空间申请，一些属性的设置（这也是在env_init中不是做设置的原因），寄存器值的清理与设置等等。 123456789101112131415voidenv_run(struct Env *e)&#123; if (curenv != e) &#123; // if (curenv-&gt;env_status == ENV_RUNNING) // curenv-&gt;env_status = ENV_RUNNABLE; curenv = e; e-&gt;env_status = ENV_RUNNING; e-&gt;env_runs++; lcr3(PADDR(e-&gt;env_pgdir));//将当前的地址空间设置为当前进程的地址空间 &#125; env_pop_tf(&amp;e-&gt;env_tf); //panic("env_run not yet implemented");&#125; 该函数只需要根据提示即可写出，看一下env_pop_tf的代码： 1234567891011121314151617181920212223voidenv_pop_tf(struct Trapframe *tf)&#123; __asm __volatile("movl %0,%%esp\n" "\tpopal\n" "\tpopl %%es\n" "\tpopl %%ds\n" "\taddl $0x8,%%esp\n" /* skip tf_trapno and tf_errcode */ "\tiret" : : "g" (tf) : "memory"); //对应的汇编代码： /* mov tf,eax movl eax,esp popal popl es popl ds addl $0x8,esp iret */ //从这里开始，真正退出了内核态，进入用户态 panic("iret failed"); /* mostly to placate the compiler */&#125; 真正开始运行时，是需要trap伪装栈内容之后才能调用该函数，进入用户态的。trap的内容将在PartB讨论。届时还会需要用到该函数的内容。 按照文档的说明，使用b env_pop_tf打断点，查看内容，在经过若干次执行之后： iret将进行退栈操作，此处暂未涉及。 这里写完之后，就可以梳理一下在进入用户态之前都发生了什么：(in kern/init.c) 首先，清理bss。这将保证所有未初始化的都是0，在testbss中将会有体现。然后初始化控制台，进行内存的初始化，进程初始化，trap的初始化。随后创建一个env，开始执行。 现在，我们可以讨论在上面提到过的ENV_CREATE。 ENV_CREATE在kern/env.c中被定义： 首先可以看到本文件对那些骗boot loader装载进来的用户程序的外部定义，随后调用env_create函数，以ENV_PASTE3(_binary_obj_, x, _start)作为传入的ELF文件头结构，以type作为类型被创建。 随后，在create之后，执行load_icode，将对应内存的文件搬运到指定内存，并设置进程的入口点为函数的入口点，为用户进程初始化map一个页空间的栈，准备开始执行。 随后，调用了env_run函数，执行这个已经准备好的用户程序。但是在这个阶段，这个程序实际上还不能被真正执行。 Handling Interrupts and Exceptions中断与异常都将会打断原有程序的执行，转而执行其他程序。他们的区别就在于，中断用于处理那些处理器外部的异步事件，而异常处理被处理器在执行指令时发现的错误情况。 中断会被INTR引起，异常会被INT引起。这也确定了breakpoint应该是一个异常而不是中断。 Basics of Protected Control Transfer中断和异常都可能完成这个转化，完成特权级的转化需要两个东西：IDT与TSS。 IDT：IDT确保了用户程序切换到内核态的情况只有已经由kernel定义的几种，保证切换过程中的安全性。 x86允许256个不同的中断或异常，他们有着不一样的中断向量，CPU利用中断向量来确定这个中断的中断向量表，进而找到处理中断的入口，执行处理程序。找到中断向量的描述符之后，EIP中装载的将会是中断处理程序的入口地址，CS中装载的是运行优先级。不一样的运行优先级设置带来不一样的结果，在接下来的实验中将会被讨论到。 一个IDT Gate是这样的： segment selector与offset用来描述在段机制下自己的中断响应函数的位置。segment selector负责在GDT里面找到对应的段，offset负责找对应的偏移量。找到函数之后，保存现场并执行响应函数。 TSS：处理器需要空间来存储旧的寄存器中的值，这样从中断或异常中返回的时候，用户程序才能够接着执行。因此，在从用户态切换到内核态的时候，需要换一个栈进行操作。这时就需要TSS来确定段寄存器来确定这个栈到底在哪里。从用户态切换到内核态时，首先在栈中push一些寄存器值： 然后加载中断描述符中的值，然后把ESP和SS置为指向新栈的值。 尽管TSS可能会很复杂，但是在这个实验中只是用到了指向内核栈的部分。 在中断发生的时候，系统将会看一下产生中断的程序的特权级，决定应该怎样保护现场。如果在特权状态，不用换栈，只需要保存更少的东西，而处于用户状态下的程序在执行完中断响应函数之后还要从内核栈退回到自己的用户栈，保存了更多的东西。 iret：系统指令，从中断中返回。ret：从函数中返回retf：与ret基本一样，从函数中返回。（弹出栈，拿出返回地址（就是下一条语句）返回值，丢掉压栈参数） Types of Exceptions and Interrupts当一个进程在User Environment运行时，忽然遇到了一个中断： 进程切换到被TSS定义的那个栈，在JOS中SS0是GD_KD（GDT中的kernel code），ESP0是KSTACKTOP。 进程把一些值push到这个kernel栈里面。 找到IDT entry，开始执行函数 需要注意的是，就像上面已经讨论过的，有些中断/异常会push error code，而有的不会。 如果是在内核态发生了中断，就不需要进行换栈操作，这时旧的SS与ESP不会被保存。 怎么从内核态切换到用户态呢，其实方法是相似的。新开一个用户栈，存上中断以为的数据，随后iret，这样就降到了用户模式。 Setting Up the IDT现在来查看本实验中关于中断/trap的内容。 在inc/trap.h中定义了许多中断号，PushRegs结构以及TrapFrame结构。 TrapFrame结构中定义了trapnumer、es、ds等在值，这些值在特权级发生改变的时候会被压栈出栈保存，在后面还会用到。 为了完成Exercise4，首先分析trap.c以及trapentry.S中的代码： 这两个macro将会帮我们进行trapno的压栈操作，函数名的定义。第一个用于自动压栈errorcode的，后一个处理不自动压栈errorcode的。找到每个中断类型的压栈方式： 这时应该明确，这时仍处于原来的特权级。 于是，使用上述两个macro来为trap添加一个入口点，这部分的代码： 然后考虑/kern/trap.c中的内容，在这之前，首先查看macro SETGATE的作用： 1234567891011121314//in inc\mmu.h#define SETGATE(gate, istrap, sel, off, dpl) \&#123; \ (gate).gd_off_15_0 = (uint32_t) (off) &amp; 0xffff; \ (gate).gd_sel = (sel); \ (gate).gd_args = 0; \ (gate).gd_rsv1 = 0; \ (gate).gd_type = (istrap) ? STS_TG32 : STS_IG32; \ (gate).gd_s = 0; \ (gate).gd_dpl = (dpl); \ (gate).gd_p = 1; \ (gate).gd_off_31_16 = (uint32_t) (off) &gt;&gt; 16; \&#125; 这个macro帮我们设置了IDT的Gate。 于是，根据前面对TRAPHANDLER_NOEC与TRAPHANDLER的描述以及SETGATE，写trap_init如下： 接下来考虑_alltraps。根据提示，写出如下代码： 提示信息： Your _alltraps should: 1. push values to make the stack look like a struct Trapframe 2. load GD_KD into %ds and %es 3. pushl %esp to pass a pointer to the Trapframe as an argument to trap() 4. call trap (can trap ever return?) Consider using the pushal instruction; it fits nicely with the layout of the struct Trapframe. 代码： 进行makegrade检测： Answer the following questions in your answers-lab3.txt: 1. What is the purpose of having an individual handler function for each exception/interrupt? (i.e., if all exceptions/interrupts were delivered to the same handler, what feature that exists in the current implementation could not be provided?) 2. Did you have to do anything to make the user/softint program behave correctly? The grade script expects it to produce a general protection fault (trap 13), but softint&apos;s code says int $14. Why should this produce interrupt vector 13? What happens if the kernel actually allows softint&apos;s int $14 instruction to invoke the kernel&apos;s page fault handler (which is interrupt vector 14)? 回答： 如果所有的中断都是一个响应函数，那么首先需要统一是不是要自动压栈errorcode，其次在SETGATE时就无法指定特权级，就不能为内核中断提供不同的保护。比如syscall允许用户程序产生，但是诸如divideerror等只可以由硬件产生，如果所有都是用同一个优先级，很容易被别有用心的用户程序取得内核权限。 pagefault14不允许用户程序直接发起，必须经由硬件产生。这种机制可以更好地保护内存。假如允许用户程序自己产生int14，则每引发一个缺页中断系统就需要分配一个虚拟页，可能会被恶意程序利用，使得内存崩溃。而int13则是general protection interrupt，保护自己不去管那些不允许用户自己产生的中断。如果希望int14可以正常被用户程序直接产生，应该将其特权级设置为3. Page Faults, Breakpoints Exceptions, and System CallsHandling Page Faultspage fault是14号中断。当处理器捕获到14号中断的时候，它会在CR2中存储一个引起pagefault的线性地址。下面来处理这个中断。 在上一步分析到，在把es与ds分别都设置为GD_KD之后，这时调用trap函数，我们先来分析trap函数。 FL_IF是在inc/mmu.h中定义的中断标志。如果寄存器eflage中中断标志没有被置位，则不是一个中断。 在tf结构tf_cs的低位存储着优先级，假如优先级是3，则是在用户态。这时是无权处理中断函数的，应该首先升级成为内核态，然后再处理。然后调用trap_diapatch，来分发处理各种不同的trap，处理完毕回来之后，如果没有什么异常就可以接着运行。 在trap_dispatch中添加下面的代码： 1234if(tf-&gt;tf_trapno==T_PGFLT)&#123; page_fault_handler(tf);//此时该函数尚未完成 return;&#125; 这时去查看page_fault_handle，此函数尚未完成，但是对于用户态的trap已经给出了解决，可以看到一句代码fault_va = rcr2();。这就是前面提到的在CR2中储存引起pagefault的线性地址，随后的打印操作即可以打印出这事的信息。 The Breakpoint Exception其实，breakpoint也只是一个异常，函数入口点的相关代码在前面都已经写出来了。需要说的是，在我最早使用breakpoint作为该函数的名字时，运行make run-breakpoint一直不成功。如果breakpoint还有其他用处，希望可以发现。目前暂时搁置这个问题。 这里需要做的只是补充trap_dipatch，代码如下： 1234if (tf-&gt;tf_trapno == T_BRKPT) &#123; monitor(tf); return;&#125; Questions 1. The break point test case will either generate a break point exception or a general protection fault depending on how you initialized the break point entry in the IDT (i.e., your call to SETGATE from trap_init). Why? How do you need to set it up in order to get the breakpoint exception to work as specified above and what incorrect setup would cause it to trigger a general protection fault? 2. What do you think is the point of these mechanisms, particularly in light of what the user/softint test program does? 回答： 这个问题的答案与上一个相似。当特权级设置为0的时候，只允许硬件产生中断而不会允许用户自己去调用。 更好的保护机制。 makegrade信息将在最后一同贴出。 System calls在JOS中，系统调用定义的中断号是48号，系统调用不能由硬件产生，因此需要允许用户程序来生成系统调用。这也是在SETGATE中最后一个参数是3的原因。system call在初步判断时与trap处理相同，但是处理过程更加复杂。应用程序将会把系统调用的号码以及参数放在寄存器里面，这样内核将不需要在用户环境的堆栈或指令流中找数据。sysno将会在寄存器eax之中，其他参数将会在edx , ecx , ebx , edi , esi之中。返回时的返回值将会存在eax之中。 首先查看lib/syscall.c，syscall的代码以及对应的汇编代码如下： 补充kern/syscall.c以及kern/trap.c，代码如下： 这里需要提出的是，在kern/syscall.c中有另一个未完成的函数sys_cput，这个函数要求检查内存是否可以被访问，而在后面的练习中有相关函数的补充，在这里先不贴出代码。 User-mode startup用户程序开始运行时是在lib/entry.S，随后在lib/libmain.c中call libmain()。在lib/entry.S中可以看到： envs已经被定义了，因此下面进入lib/libmain.c来初始化thisenv。根据提示，查看inc/env.h中的ENVX，其定义如下： 1#define ENVX(envid) ((envid) &amp; (NENV - 1)) 为了得到当前的进程号，可以调用在kern/syscall.c中的sys_getenvid函数，该函数如下： 12345static envid_tsys_getenvid(void)&#123; return curenv-&gt;env_id;&#125; 但是，根据inc/env.h，env_id并不是一个完全的envs中的序号， 根据注释，ENVX(eid)才是真正在envs中的偏移，于是，在libmain中的代码如下： 1thisenv = envs+ENVX(sys_getenvid()); 其实，只有在这部分完成之后，才能正确的调用用户函数。这是因为在退出时需要访问thisenv-&gt;env_id，而先前这个变量并没有值。 在用户程序执行完成之后，就会调用sys_env_destory来退出自己。 Page faults and memory protection内存保护是操作系统的一个重要特性，确保一个程序中的错误不会破坏其他程序或破坏OS本身。OS通常依赖于硬件来保护自己，他知道哪块虚拟地址可用，哪块不可用，如果一个程序想要访问他没有权限访问的地址，会引发错误。如果这个错误可以被解决，OS会试图解决，如果不能解决，犯错的进程就不可以再运行了。 系统调用为内存保护提出了一个有趣的问题。大多数系统调用接口让用户程序将指针传递给内核。这些指针指向要读取或写入的用户缓冲区。内核然后在执行系统调用的时候去引用这些指针。这有两个问题： 1.内核中的页面错误可能比用户程序中的页面错误严重得多。如果内核页面在处理自己的数据结构的时候出错，这是一个内核错误，而且错误处理程序应该让内核（也就是整个系统）崩溃。但是当内核解引用用户程序给它的指针时，它需要一种方法来记住任何页面错误，这些解除引用实际上是代表用户程序。 2.内核通常拥有比用户程序更多的内存权限。用户程序可能会传递一个指向系统调用的指针，指向内核可以读或写的内存，但是程序不能。内核必须小心，不要被欺骗引用这样一个指针，因为这可能会泄露私有信息或破坏内核的完整性。 下面将处理对用户读写指针的访问权限处理，如果用户想要读写的地方表示允许，就允许，否则不允许。而内核，如果出现了page fault，立即崩溃。 在kern/trap.c中添加对内核发生了pagefault的处理，这也是上面提到的尚未完成的操作。根据提示，由于tf_cs中的低位代表特权级，直接查看特权级：如果不是在用户态发生的，就直接panic。代码如下： 12if ((tf-&gt;tf_cs&amp;3) == 0) panic("Kernel page fault!"); 接下来对kern/pmap.c中的user_mem_check以及user_mem_assert进行操作： 只需要按照说明检查内存中位置以及PTE_P和PTE_U等即可，直接贴出代码： 下面是user_mem_assert的代码。 12345678910111213//检查进程env是不是允许访问这个区域//如果可以就return//不行的话env就死了，如果env是当前运行进程，就不返回了//user_mem_checkvoiduser_mem_assert(struct Env *env, const void *va, size_t len, int perm)&#123; if (user_mem_check(env, va, len, perm | PTE_U) &lt; 0) &#123; cprintf("[%08x] user_mem_check assertion failure for " "va %08x\n", env-&gt;env_id, user_mem_check_addr); env_destroy(env); // may not return &#125;&#125; 最后，对在实验1中写过的debuginfo_eip进行更改，使得backtrace可以使用。将代码贴出： 本实验的基础部分到这里结束。 最终的makegrade： CHALLENGE： 完成了单步执行的challenge。 根据提示，查找EFLAGS信息，得到这样的信息： 于是为了能够单步执行，z在monitor中修改如下部分： 添加指令si 写函数mon_si并在.h中声明（声明略去） 修改kern/trap.c，使得能够处理debug的中断信息 运行： 类似的，就可以加上c指令使继续运行到下一个breakpoint。 添加指令c 写函数mon_c 只是，这时需要将TF位置为0。 结果： 为了更好地查看si与c的结果，我将breakpoint.c修改为下： 最后，再次运行make grade： 本实验完成。代码已经提交到git.mobisys.cc。 点击链接预览lab3工程代码~ 如果想要直接下载的话就点这个（这是百度的网盘） yayi2456 &lt;(￣︶￣)↗[GO!]&gt; 最后，列出那些给过我帮助的网站！谢谢！（也便于我以后找到！ 一个学霸的自我修养 clann24 clann的实际代码与README代码不一样啊，而且明明clann的自己可以运行，加到我的代码上却不能运行了。对clann的load_icode存疑。 朴实中透露着惊喜 mick_seu 可以说是很厉害了。代码简单易懂，正确率超高，超适用。 学习并快乐着 飞龙 飞龙的代码也很简单易懂！而且一看就是自己写的，与网上主流的都不一样。 X86 CPU的EFLAGS寄存器各个标识位 伊凡 How to read and write x86 flags registers directly? stackoverflow 我需要BB一句。到了OS课的该是大三了。stackoverflow这个社区真的是强推，无数问题都是在这个社区找到的回答。嗯，强推。 markdown to html md转html在线 emm其实效果一般…很不好….但是，毕竟在线，不想用的话，自己安装pandoc，费劲费空间。 另外一个html与md markdown的chrome插件]]></content>
      <categories>
        <category>OS</category>
        <category>MIT Lab</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[串讲复习]]></title>
    <url>%2F2017%2F11%2F27%2FOS%2F%E4%B8%B2%E8%AE%B2%E5%A4%8D%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[系统调用例：STL的实现printf：对屏幕： 在每一个像素有一种颜色 文本模式 系统调用与函数调用系统调用是中断，相当于在用户程序执行的过程中嵌入一段由OS完成的代码，完成后再返回用户程序。其中，包括特权级的升降。在进行系统调用的过程中，进入之后首先会检查用户传参是否有危险，随后再执行系统调用。这将在一个新的页完成，存在于内核态独立地址空间，将会带来包括TLB，Cache等的一系列问题。因此，系统调用的代价比函数调用的代价大得多。 进程间的通信直接通信与间接通信1send(A,) 阻塞通信与非阻塞通信像网络中那样，阻塞通信就是// 通信链路缓冲0容量：发送方需要等待接收方有限容量：无限容量： 信号信号类似于中段， 是最原始、最简单的一个进程间交互的模式。在关机时，系统将会用这种方式通知各各进程。 管道父子之间传递信息 消息队列类似于电子邮件系统。 得到一个队列，使用队列号来标识。此后消息的send与recv都通过这个队列。 共享内存创建共享段shmget(key,size,flags)。其中key是其他人希望与你共享内存的话必须知道的值。shmat(shmid,*shmaddr,flags)把共享段映射到进程地址空间。 在这里，将又会遇到在“哲学家就餐”那部分的问题。另外，还将会有在cache还是内存的问题。cache作为在读写操作时第一个碰到的硬件，是否可以保证进程A写的时候吧东西写进了共享区的物理内存？在B不能使用的时候它的Cache的正确性哈能不能保证？—？ 由一个“可否使用cache”的位. 文件写入时发生了什么？在内存中创建一个新的inode节点或者索引节点，如果存在，在文件系统中找到对应的inode。 修改文件夹对应的数据节点。最初只在内存中修改并标记这块数据已经被修改了，你记得帮我写回去。 close并不能使数据立即回到硬盘上。pagebuffer可以被禁用。fsync可以强制立即写回磁盘。 //sqlite将收到文件系统缓存影响。 先写数据还是先写索引？更偏向于先写数据，这样顶多修改内容存不上，如果先写索引，可能导致文件系统将无效数据误认为是文件数据。 文件删除时发生了什么找到对应的inode：这时在cache内存（pagecache）以及文件系统上都存有该文件的数据。 在内存中删除inode，清除页面。把硬盘中的inode清除，对应数据块清除，硬盘中的块标记为未使用，文件夹中的项删除。 一个文件（夹）怎样叫做存在？1.在某一个文件夹下有她的树根的索引 2.在占用未占用位图中存在数据块占用标志。 如何恢复一个被误删的文件？寻找树根。而树根是有特点的。一个文件恢复需要扫描位图中显示的未使用的数据块，找到树根，然后顺着树根找到所有文件。所以，一旦误删，就不能再动硬盘了，再动硬盘可能会破坏原来的数据，导致文件直接找不到或者缺失或者？（不会乱码咩） 怎样快速删除文件并且不可恢复？删除与覆盖、与文件系统相关、把我的空lab5给他复制过去hhh。 关机时发生了什么？init在接收到特定信号时发起关机 使用SIGSTOP提示关机，使用SIGKILL强制关机 各种内存数据回写。 意外断电？1.可能数据在内存中没有被回写 2.磁头正在飞行（可能会有保护机制） 3.磁头正在写入如果搞坏了磁介质可能只是这个地方不能读写，但是RAID1多地机房。 意外断电防护：使用重力传感器，（磁头）失重时将会尽快写入数据。 开机时发生了什么跳转到指定地址取指令（0xfffff0或0x00000000（手机））：bios中存在一些基本指令：兼容机的标准化使得BIOS可以适配大量硬件 硬盘数据载入内存 这是因为硬盘的读取模式也兼容给bios的读写。 格式化C盘再复制回去：NTLDR missing：NTFS系统自身的代码。VBR：ntfs文件系统的加载器，包含文件系统的读取方式与操作系统。使用vbr把文件load进来。 操作系统接管运行，为进程准备环境。 init进程创建用户交互进程。winlogon。init不做任何操作只等关机，其他任务都是init的子进程的工作。 为什么不拷贝一份新的而是使用父进程的？子进程直接自己调用exec，直接调用（freertos）。拷贝执行？？？子进程在出来之后就已经是一个完整的pcb了。 父进程可以接收子进程的main函数的返回值。父进程等待子进程退出，由父进程替子进程收拾残局：找到他分配的页面，转为可用页面。SIGCHILD。如果一个进程的父进程先自己退出了，这个子进程的父进程就变成init。 exec时发生了什么？在文件系统中找到文件，读取文件目录树 将文件映射入内存 程序执行]]></content>
      <categories>
        <category>OS</category>
        <category>MIT Lab</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络概述]]></title>
    <url>%2F2017%2F11%2F21%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A6%82%E8%BF%B0%2F</url>
    <content type="text"><![CDATA[这是第一次课！时隔许久，也算是复习啦~ # 网络边缘网络核心分组交换在各种网络之中，端对端之间互相传送报文。为了从源系统项目地端系统发送报文，源端系统将报文分成若干的小数据块，成为分组。每个分组都通过源端系统与目的端系统之间的分组交换机（主要是路由器以及链路交换机）传送。分组以等于链路最大传输速率的速度通过通信链路，因此如果传输速度是R比特/s，那么传输L比特分组的时间是L/R比特/s。 存储转发传输多数分组交换机在链路的输入端使用存储转发传输机制，它是指在交换机开始发送第一个比特之前，必须接收到整个分组。 我们看一个例子： 如果发送方要传送长是L的报文，两条链路传输速率都是Rbit/s，那么到达路由器之前不能转发，首先浪费了L/R s，这时全部到达了，然后转发出去，一共花费了2L/R。（没有考虑线路长度） 而如果数据一旦到达路由器就转发而不用等到全部到达，只需要L/R的时间。 现在计算发送三个分组，从源发送第一个分组到达目的地接收到全部三个分组的时间：在L/R，第一个分组被转发出去，这时源也开始发出第二个分组，2L/R，第一个已经被路由器转发完毕，目的端收到，路由器开始接收第三个分组，源开始发送第三个分组，3L/R，路由器接收第三个分组完成，第二个分组已经送出去被目的接收到，源端发送完毕，4L/R第三个分组完全传送出去，目的端接收到第三个分组。一共4L/R时间。 考虑N条速率均为R的链路（所以一共有N-1个路由器），发送一个分组所需时间是$t=N*\frac{L}{R}$。 如果像上面一样分组发送： 一个长度L的包一次发出去，时间是$t=N*\frac{L}{R}$，如果分成c组，时间为：$t`=(c+N-1)*\frac{L}{c*R}$！！]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>网络课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络编程一：UDP,CMD,TCP,WebServer]]></title>
    <url>%2F2017%2F11%2F15%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E7%AE%80%E5%8D%95udp%E9%80%9A%E4%BF%A1%E5%AE%9E%E7%8E%B0-java%2F</url>
    <content type="text"><![CDATA[今天写webserver的时候发现需要用到以前写的一些程序的知识。所以觉得最好总结一下。 UDP CMDwoaibianyi,bianyibangwojiejueledaiamdewenti.xieixeni. 感觉像是…识别不出\n…行吧，myplace myrule，//必须以;结尾！ UDP介绍UDP通信使用两个类：DatagramPacket与DatagramSocket。前者是对UDP包的一个封装，后者是完成两端之间的交流。在UDP里面Server与Client地位同等，彼此没有区分。 1234DatagramPacket packet=new DatagramPacket(buff,buff.length,addr,port);//发送包;DatagramPacket packet=new DatagramPacket(buff,buff.length);//接收包;DatagramSocket socket=new DatagramSocket(port);//指定端口号的socket;DatagramSocket socket=new DatagramSocket();//自动分配一个可用端口号; 不得不说端口号与进程、socket之间的关系：端口号与进程毛关系没有。一个udp socket只能绑一个端口，一个port只能被一个socket绑。这个原因是在多路复用与多路分解讲到的。否则不知道pck究竟该给谁。 ServerServer的ip获取；获取client的ip与portServer端获取Server的ip与port： 12InetAddress.getLocalHost();//ip获取;socket.getLocalPort();//socket绑定的port获取; Server端获取Client的ip与port： 123//pck是从client接收到的包;pck.getAddress();//;pck.getPort();//; 时间获取 定义：Calendar cal; 每次获取时间前都应执行：cal= Calendar.getInstance(); 获取常用的数据： 1234567int year = cal.get(Calendar.YEAR);int month=cal.get(Calendar.MONTH)+1;int day=cal.get(Calendar.DATE);int week = cal.get(Calendar.DAY_OF_WEEK)-1;int hour=cal.get(Calendar.HOUR_OF_DAY);int minute=cal.get(Calendar.MINUTE);int second=cal.get(Calendar.SECOND); 使用其他类访问同一可视化界面以本程序为例，在主类中创建了一个可视化界面，希望在Time类访问可视化界面的一个label： 在Time类创建一个label，使用主类的label初始化这个label。 主方法：监听client请求1234567891011121314151617DatagramSocket socket=new DatagramSocket(4444);//固定的一个socket，绑定固定的port;while(true)&#123; byte[]buff=new byte[256];//输入缓冲区; DatagramPacket pck=new DatagramPacket(buff,buff.length);//每次都新建一个包，否则会产生缓冲区不干净发送数据错误的问题; try &#123; server.log.setText(server.log.getText()+"\ni'm at "+InetAddress.getLocalHost()+" "+socket.getLocalPort()+" and listenning~\n"); server.log.setCaretPosition(server.log.getText().length());//设置目前的光标位置，在可视化界面具体讲; socket.receive(pck);//接收数据包：阻塞方法; server.log.setText(server.log.getText()+"i've get a request from "+pck.getAddress()+" "+pck.getPort()+" "+new String(pck.getData())+"\n");//; server.log.setCaretPosition(server.log.getText().length()); Server newserver=new Server(new String(pck.getData()),pck,server);//新开一个线程，专门负责与这个client的通信; new Thread(newserver).start();//新线程开始运行; &#125; catch (IOException e) &#123; // TODO Auto-generated catch block; e.printStackTrace(); &#125;&#125; pck.getData();:获取pck包的data信息;pck.getAddress();获取包的源地址pck.getPort();获取包的源端口 InetAddress.getLocalHost();:获取本地ip，可能抛出异常，需要处理socket.getLocalPort();获取socket绑定的端口号 socket.receive(pck);:等待接收一个包socket.send(pck);:发送一个包 String与Unix时间戳之间的转换format函数之中是一个Date对象，这个Date对象由一个long构造：list[i]是File类型。也许会说“过时”，没关系，这一整句代码打上去就不会提示了。 1String dates=new java.text.SimpleDateFormat("yyyy-MM-dd HH:mm:ss").format(new java.util.Date(list[i].lastModified())); 多说一句SimpleDateFormat： G 年代标志符 y 年 M 月 d 日 h 时 在上午或下午 (1~12) H 时 在一天中 (0~23) m 分 s 秒 S 毫秒 E 星期 D 一年中的第几天 F 一月中第几个星期几 w 一年中第几个星期 W 一月中第几个星期 a 上午 / 下午 标记符 k 时 在一天中 (1~24) K 时 在上午或下午 (0~11) z 时区 可以说是十分实用了。 具体信息可以访问这里：SimpleDateFormat使用详解 获取本地文件信息注意：没有解决的一个问题：包最后一定会用ASCII为0的char填充满255个，注意！ 12345File f=new File(dirpath);File[] list=null;if(f.isDirectory())&#123; list=f.listFiles();&#125; 获取文件名信息：list[0].getName();是否文件？是否目录？:list[0].isFile();list[0].isDirectory();还有一系列方法：自己发现吧！ Server的java代码看这里 Clientclient的ip获取InetAddress.getLocalHost();与Server差不多 设置最大时延送出一个包： 123DatagramSocket socket=new DatagramSocket();socket.setSoTimeout(10000);socket.send(pck); 新开一个线程中：等待接收一旦超时触发异常： 12345678try&#123; socket.receive(pck);&#125;catch(SocketTimeoutException e)&#123; e.printStackTrace(); ori=ori+"timeout!:"+socket.getInetAddress()+" for "+pck.getData().toString()+" has no response . try again!\n"; clientthis.tf.setText(ori);&#125; 使用String设置指定IP12345678910111213141516171819202122232425262728293031323334try&#123; int[]ipaddr=new int[4]; String[] ipsplit=new String[4]; data=data.replace('.', '-'); ipsplit=data.split("-");//这两步是当时不懂正则，使的一个小手段; for(int i=0;i&lt;4;i++)&#123; if(ipsplit[i]!=null &amp;&amp; ipsplit[i].isEmpty())&#123; cmd.setText(cmd.getText()+"format of ip addr wrong!split by .\n&gt;"); rows++; break; &#125; ipaddr[i]=Integer.parseInt(ipsplit[i]); &#125;//前面是为了验证给定的string是符合要求的int.int.int.int形式; //得到正确的ip; //转化为byte流; byte[]byteaddr=new byte[4]; byteaddr[0]=(byte)ipaddr[0]; byteaddr[1]=(byte)ipaddr[1]; byteaddr[2]=(byte)ipaddr[2]; byteaddr[3]=(byte)ipaddr[3]; //设置新ip; addr=InetAddress.getByAddress(byteaddr); System.out.println(data); cmd.setText(cmd.getText()+"&gt;");//先忽略就好;&#125;catch(NumberFormatException e)&#123;//根本不符合格式; e.printStackTrace(); cmd.setText(cmd.getText()+" wrong:"+command.substring(7)+"wrong format of ip addr! split by . and only numbers are accept\n&gt;"); rows++;&#125;catch(UnknownHostException he)&#123;//; he.printStackTrace(); cmd.setText(cmd.getText()+"unknown host\n&gt;"); rows++;&#125; client代码看这里 可视化可视化部分也在上面的client代码里面。 TCP WebServer这是第二次作业，使用TCP，利用http1.1，实现一个可以与浏览器进行交互的小型的WebServer。 附加：tcp部分编码设置 String code=”utf-8”; try { InputStream instream= new java.io.FileInputStream(file); byte[] b = new byte[3]; instream.read(b); instream.close(); if (b[0] == -17 &amp;&amp; b[1] == -69 &amp;&amp; b[2] == -65)code=”utf-8”; else code=”GBK”; } catch (IOException e) { // TODO Auto-generated catch block e.printStackTrace(); } return code;]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>网络课</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实验串讲]]></title>
    <url>%2F2017%2F11%2F14%2FOS%2F%E5%AE%9E%E9%AA%8C%E4%B8%B2%E8%AE%B2%2F</url>
    <content type="text"><![CDATA[Lab3：User EnvironmentPre：实验准备知识GCC内联汇编特权降级基础知识准备切换到保护模式之后就会有不同的特权等级，这时默认在最高的特权等级上。这个时候为内核建立了页表结构，接下来将会跳转到用户程序。进行跳转的时候，应该注意：不可以再留着这个高级的运行权限了，因此需要进行特权级的降级。 系统在以上电时，各个资源管理都还没有建立，这个时候处于特权管理模式，在特权模式建立完毕所有的资源映射之后，再降级到通用模式，运行。 因此，一上电运行的指令一旦被不安全的程序接管，将不会降级，保护措施将形同虚设。因此，在智能手机等终端上都有一个叫做trustdo(?)的硬件，它是一个加密的模块，这个模块是系统上电之后运行的第一段代码，作用是验证将要运行的这段代码是不是被授权的，数字签名是否通过，若通过才会运行。trustdo会被做到CPU的芯片中，保证了即使上电后处于特权模式的代码是安全可靠的。 iret：系统指令，从中断中返回。ret：从函数中返回retf：与ret基本一样，从函数中返回。（弹出栈，拿出返回地址（就是下一条语句）返回值，丢掉压栈参数） 中断是一个硬件的事件，中断返回与函数返回不同。当一个中断来了，不管你当时在干嘛，就乖乖地保存一下现场去响应中断。这个保存现场，包括了硬件将会自动帮你保存的一些现场，比如CS、SS、Flag等等，这些是自动存下的，iret的作用就是自动地将这些东西都弹出。但是这些现场保存并不够，通用寄存器是不会帮你保存的。 ret、iret等等在汇编之中可以随意调用，并不需要其他约束。如果当你在汇编中不是函数（中断）的里面调用了这些，它会干些什么呢？他会把自己认为的自己保存进去的那些东西弹出来，一个是返回地址给PC，一个是返回值给保存返回值的东西。即使没有调用函数，ret的行为也是固定的：从栈顶弹出两个值，一个给PC，一个给存储返回值的东西，iret的行为也是固定的，就是从栈顶弹出东西给那些变量。这就是保护现场之后的栈。ret是弹出到eip，retf弹出到CS，iret弹出到CS（代码段）、EFLAGS，根据是否改变特权等级，iret会连下面的SS以及esp一起弹出来。 这样，如果一个程序在栈中事先在栈中存了一些数据，然后调用了iret，iret不管栈中究竟是什么，就会弹出5（3）个元素，给对应的寄存器。ret和retf也类似。因此，在汇编中ret们与高级语言的return们的作用不同，汇编中的ret们只是提供了一个批量修改寄存器的方法。 系统中有两种中断。中断可能在任意时间发生。在用户模式下与在特权模式下中断发生后系统的动作是不相同的。 在用户模式下，系统会保存这些东西：还记得在“内存管理”的lab里面讲过的段选择子，其中有两个bit标识自己处在什么特权模式下的特权位。这里面有两个段选择子，一个是栈的，一个是代码段的，由于在用户模式下，可以看到CS代码段选择子与SS栈选择子的特权位RPL都是3。 在特权模式下，一旦发生中断：这时保存的东西比较少。 无论在哪种模式下一旦调用iret，就把这些东西（其实不一定是这些东西，只是对应栈顶的几个数据）弹出去给对应的寄存器。 正题：特权降级考虑做完lab2，系统在特权级是0的模式下，这是需要现将自己降级成为特权3的模式，再去运行用户程序。怎么降？ 要伪造一个场景：刚刚一个用户程序产生了一个中断所以我升级了，现在我要中断返回。于是我去伪造了一个栈，在栈里头存上了iret希望的那5个数据，每一个是32位。然后调用iret，这些就会从栈中弹出来到达对应的寄存器，然后我就回到了用户模式，那两个段选择子的特权级值就被改为了3。这里需要注意的是，系统原来使用的特权级是0的栈，iret之后这个栈空掉了，但是系统不再使用这个栈，而是重新为用户态开避了一个新的栈，这个栈不再是以前的那个栈了，这个栈放在用户空间的数据段里，它的权限也是3。 为什么要这样设计呢？在特权模式下，系统并不想和特权级更低的用户态共用一个特权级更高的栈。另一个方面从安全考虑，为了防止用户态随意弹出数据随意插入数据破坏内核运行。 从特权模式到达用户模式，新创建了一个栈给用户程序使用，这是在刚上电的时候，还没有用户程序运行。用户程序运行过程中可能会有系统调用回到特权模式下，这是将会使用前面提到的系统用的那个栈，系统调用完成之后，不会再为用户程序创建新的栈了，一是占空间，一是以前的运行态不能就这样丢掉。就还让它回到自己原来的栈。 特权级提升中断、异常、系统调用：我需要更高特权的东西帮帮我。 在80386中，系统调用就是一个中断。异常是需要紧急处理的中断。 中断在32位机器上的中断是一个很复杂的机制，因为那时保护模式已经建立了起来，整个运行在虚拟地址空间上。所以当中段发生的时候，系统使用中断描述符表，写着自己所有的中断号。中断描述符寄存器（IDTR）中存的就是中断描述符表（IDT）在内存中的位置以及大小。表按照中断号排序，每一个中断描述符在80386中被叫做一个门，中断门（中断），陷阱门（异常）。会根z中断发生的编号从表中取出对应的描述符（门），取回的描述符是这样的：segment selector与offset用来描述在段机制下自己的中断响应函数的位置。segment selector负责在GDT里面找到对应的段，offset负责找对应的偏移量。找到函数之后，保存现场并执行响应函数。 在终端发生的时候，系统将会看一下产生中断的程序的特权级，决定应该怎样保护现场。如果在特权状态，不用换栈，只需要保存更少的东西，而处于用户状态下的程序在执行完中断响应函数之后还要从（？）退回到自己的用户栈，保存了更多的东西。 正题：特权级提升从特权模式3切换到特权模式0，实际上就是响应一个中断，这就是上面图中的trap。 对于用户程序，os并不信任。当trap发生时，当前用户程序的运行状态会被存入到内核栈中，而用户栈并没有变化。这也是中断与普通函数调用的不同。现在已经进入了特权模式，如果不作任何操作，只是调用一个iret，前面讲到的CS，SS特权级3又会被写入到寄存器里面，就又回到了用户态。为了能留在特权模式下，对栈进行伪造，假装在进入终端之前就是一个特权模式：也就是把上面提到的用户态发生中断的栈信息修改成特权模式发生中断的栈信息。这时iret，就可以留在特权模式下。 但是：在伪造的时候，SS被扔掉了。怎么回去呢？80386提供了一个TSS任务状态段，它几乎可以存下CPU上所有的寄存器的不止一份拷贝。TSS每个进程一个，会存下一个进程在切换特权状态的时候原特权状态下的SS的值。系统将会自己对TSS进行维护，以确保切换模式时栈的跳转。 TSS存在于哪里呢？在GDT里面有一个TSS的描述符： 80386中有4个特权模式，目前在虚拟化技术下只是用了3个。 有一个叫做TSR的寄存器，存着selector、base addr以及segment limit。便于直接找到TSS。 如果想要回到用户模式，进入trap，伪造一个从用户态过来的栈，iret即可。 系统调用用户程序可以通过系统调用访问内核服务，这个过程需要指定中断号，使用tarp或者特殊指令（SYSENTER/SYSEXIT）实现。 关于这次实验这里的env就是课上讲的pcb。父子进程的一个作用是父进程要为子进程收尸。 elf格式：linux下的可执行。创建进程并执行elf：没有文件系统怎么办？把指定的文件链接进目标文件，骗bootloader把程序也搬进内存。 -b binary path:-b帮我搬进来。binary这是个可执行程序。然后重生成一个符号表。把这个文件作为一个大数组缀到最后，然后直接使用这个数组。 编码的时候，这个数组还没有，链接的时候才有，怎么办？定义一个外部变量extern。只需知道生成符号表的规则，然后按规则命名即可。 进来之后还只是一个大数组，还需要经过链接之后映射要对应的虚拟地址才能执行。 Lab4-Preemptive Multitaskinglab3做完之后，当一个进程结束之后，就退出。在这个实验中，主要完成的是 本次实验主要是决定：在何时利用什么原则什么地方切换进程。上下文怎么切换？其中一项：一定要把页表换掉，也就是把cr3中的页目录项换掉。之后，连接tlb也会失效，处理流水线，吧上一个进程的东西全部清理掉。 本实验大部分代码都已经写完了，主要是读代码。 如何实现更加有效的调度？更加频繁的调用schedule_yeid。 时钟中断的作用：打断正在执行的程序，调用sched_yield进行进程轮转 在本次实验中有一个时钟中断，你要做的就是在这个时钟中断的响应函数之中做一些事情，决定下一个进程怎么上去谁会上去（就是我们学习过的调度算法） 多核处理器一开始是因为没有在一个进程运行的时候调用另一个进程的机制，本实验中的多核只是实验的设计者希望我们体验一下在系统中有多个进程活动是一个什么样的状态，因此鼓励你去多弄几个核心。只要是单核，其实每一个时刻只能有一个进程运行。 为什么会有多核处理器出现呢？在后摩尔时代，为了提升处理器的处理能力。 主核会在系统上电之后接管机器，他们的地位并不是平等的。 现代处理器的休眠唤醒机制现代处理器的模式一般有三种：active,idol,sleeping CPU在关闭的时候，内存并不会关闭。休眠时，找到一个调度点，这时不调度了，存好有用的东西，然后cpu耗电量就会变得非常低。有一个cpu中的寄存器会标志自己刚刚是休眠了还是关机了。如果是休眠，那么内存里面所有的东西都还在，只需要调到该去的地方，然后进行一轮新的调度；如果不是休眠而是关机了，内存中的东西就被清空了，就是上电启动过程。 有时手机会坏掉，就是在锁屏（休眠）之后也会重新起动，这也就是cpu中的那个寄存器坏掉了。 那么，如果帮一个休眠的cpu准备好了它的休眠位以及内存，就可以让它认为它是一个刚刚休眠的cpu。 bsp是主核，在系统上电之后是只有主核启动，直到系统启动完之后，直到需要另外一个核心运行一个进程，bsp帮ap制造一个它刚刚在休眠的假象，然后唤醒它，这样这个ap就会认为自己是刚刚休眠的，然后继续执行。运行完之后，主核就会选择把这个核心给关掉，然后省电。]]></content>
      <categories>
        <category>OS</category>
        <category>MIT Lab</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[哈希]]></title>
    <url>%2F2017%2F11%2F12%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E5%93%88%E5%B8%8C%2F</url>
    <content type="text"><![CDATA[emmm…大二的时候DS只考了80，出来混的，总是要还的。不希望文件太多都小于512k，会占我的空间。 哈希哈希其实没什么神秘的，不过是一群贪心的人的产物。 散列函数，将key转化为对应的value值得到索引。这个有诸如取模，ASCII平均，等等方法。橙皮书上有一种sfold，似乎性能会更好一些。 开哈希开哈希类似于静态链表，每一个value对应一个链表，成为挂着的桶。 闭哈希闭哈希将node存储在给定的一个数组中。这个数组的下标将作为value的索引值，由于value可能重复，需要探查方式，有很多方式，比如线性探查与二次探查。 关于闭哈希的删除，其实不必真的每次都向前挪，而是增加一个“墓碑”，它代表这里没有数据可以被插入，但是又不是真的空因为需要继续向前探查。当次数多了性能就会下降，一种解决方式是向前挪，另一种是重新散列。]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[语言们的输出格式控制]]></title>
    <url>%2F2017%2F11%2F12%2F%E8%AF%AD%E8%A8%80%E4%BB%AC%E7%9A%84%E8%BE%93%E5%87%BA%E6%A0%BC%E5%BC%8F%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[待整理]]></content>
      <categories>
        <category>语言</category>
      </categories>
      <tags>
        <tag>语言</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编译原理——词法分析]]></title>
    <url>%2F2017%2F11%2F09%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%2F%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86%E2%80%94%E2%80%94%E8%AF%8D%E6%B3%95%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[我有罪….我先是用学编译的时间逛了淘宝….然后又用学编译的时间逛了六维…..我有罪….\infty 时间：1012cp3 3:15开始 词法分析器介绍 编译并不是一件轻松的事情，对于较大的系统，编译的速度并不理想，这也是为什么我们需要优化编译技术。 基本概念词法单元（单词）：由一个词法单元名以及一个可选的属性值组成。名即是语法分析器的输入符号token。模式：一个词法单元的词素可能具有的形式。一个词素不能与两个或多个词法单元进行匹配（二义性）。词素：源程序中的字符序列，是程序中实际出现的字符串。 在lex与yacc中，有时会有一个全局变量。他保存了当前词素（词法单元：关于这里，龙书里面的和wg写的不一样呢？）的属性值，这个属性值可以被记录在语法树上。 词法分析器要干些什么？ 读入源程序字符，生成词素，确定词法单元序列 与符号表进行交互 过滤掉源程序中的注释与空白 将编译器生成的错误信息与位置联系 预处理：扫描阶段完成不需要生成词法单元的简单处理；词法分析阶段处理扫描阶段的输出并生成词法单元 跳过了一些东西 正则表达式（正规表达式、正规式）为什么需要正则表达式来描述字符串序列呢？像在上下文无关文法中所描述的那样，因为字符们所组成的可能的字符串是无穷的。 单词是什么？单词的本质就是符号串的集合。正则表达式就是代替了自然语言对特定符号串集合的描述。 概念符号表：符号的有穷集合符号串：字母表中符号构成的有穷序列。也成句子，字。|s|代表字符串s的长度，$\epsilon$是空字符串。语言：是一个给定符号表上的特定的符号串的集合。 比如：给定符号表{1,0}，有符号串01100010，一种语言是{0，1，00，11，000，111….}即串中只含一种字符的字符串集合。 特例：$\varnothing$是空语言。{$\epsilon$}是只含空串的语言。 运算符号串的运算连接：x=hou y=se xy=house s$\epsilon$=$\epsilon$s=s (emmmm说好的不能这样写呢？)幂：$s^n=s^(n-1) * s^1$ 语言的运算下表中运算符的优先级由低到高 运算 定义 并 $L\cup M={ s \ s\in L 或 s\in M} $ 交 $LM={ st \ s\in L 且 t\in M} $ Kleen闭包 $L^*=\cup_{i=0}^\infty L^i$ 正则闭包 $L^*=\cup_{i=1}^\infty L^i$ $$\color{red}{正则表达式&lt;-&gt;语言运算的简洁描述}$$ 正则表达式定义字母表$\sum$上的正规式r的定义规则，以及r所表示语言L(r)定义： $\epsilon$是正规式，表示语言{$\epsilon$} 若$a\in \sum$则a是正规式，表示语言{a} r , s是正规式，表示语言L(r)与L(s)，则： (r)|(s)是正规式，表示语言L(r)$\cup$L(s) (r)(s)是正规式，表示语言L(r)L(s) $(r)^*$是正规式，表示语言$(L(r))^*$ (r)是正规式，表示语言L(r) 第三条的四条，优先级从上到下依次升高。 $(a|b)^*$={所有由a、b组成的符号串} 正规式等价：r=s &lt;-&gt; L(r)=L(s) 正则运算的特性: 可以像产生式那样，为正规式指定名字： num -&gt; r1其实，上下文无关文法的描述能力包含了正则表达式的描述能力。所有可以被正则表达式描述的都可以被上下文无关文法描述，但是正则表达式并不能描述某些上下文无关文法可以描述的东西。那么为什么需要正则表达式来实现词法分析器？ 简化编译器的设计：使每一阶段需要做的事情更加简单清晰 提高编译器的效率：使用专门的字符缓冲技术提高编译速度 增强编译器的可移植性：输入设备相关的特殊性被限制在词法阶段 下面举一个例子： 无符号整数：digit -&gt; 0|1|2|…|9digits -&gt; digit digit* 其实也可以是$digit^+$optional_fraction -&gt; .digits | $\epsilon$optional_exponent -&gt; (E(+|-|$\epsilon$)digits)|$\epsilonnum -&gt; digits optional_fraction optional_exponent 符号简写： +:一个或多个实例?:0或1个实例：$r?=r|\epsilon$$\rightarrow$$L(r)\cup {\epsilon}$[]字符集:[abc]=&gt;a|b|c、[a-z0-9]=&gt;a|b|..|z|0|1..|9 非正规集正规式无法描述的语言：{wcw|w是a、b组成的字符串}正规式无法描述平衡或嵌套的结构正规式只能表示：有限的重复、一个给定结构的无限重复 关于正规式的练习，参考第三章练习 Lex使用流程与yacc类似。 $\color{red}{ATTENTION! 在使用project wizard建立lex的时候你写的那个词法分析器的名字就是那个名字， 你最好别自己再修改，否则在VS里面运行不出来！！！}$ 给的是字符流，出来的是单词流。 规则段放正则表达式与语义动作。 第四次作业词法分析器设计将会上传。click here to get 有限自动机有限自动机可以直接转换成程序。 NFA从正则表达式到自动机从这之后，正是lex所做的事情。 在这一节里，将介绍两个过程：一个是正则表达式到NFA，另一个是NFA到DFA。之所以让NFA做一个过渡，是因为正则表达式直接到DFA的算法很复杂。本次更新掠过。 NFA与DFA的性能差别很大：NFA占用空间比较少，但是使用NFA进行词法分析需要在错误态停止，可能需要花费$O(2^n)$的时间复杂度；DFA占用空间很大（最坏情况下$O(2^n)$），但是使用它进行词法分析的时候接近线性时间。 正则 -&gt; NFA正则表达式构造NFA使用MacMaughton-Yamada-Thompson算法。简称Thompson算法。这个算法描述如下： 基本规则： 自动机运转 s $\leftarrow$ e -closure({s0});c $\leftarrow$ nextchar;while c $\neq$ eof do s $\leftarrow$ e -closure(d(s,c)); c $\leftarrow$ nextchar;end;if S$\cap$F$\neq$ $\varnothing$ then return “yes” else return “no” s $\leftarrow$ s0;c $\leftarrow$ nextchar;while c $\neq$ eof do s $\leftarrow$ d(s,c); c $\leftarrow$ nextchar;end;if s is in F then return “yes” else return “no” 前面提到了，NFA占空间更少，DFA识别字符串更快，贪心的人类啊希望能糅合这两者的优点。看前面的NFA代码，其实在第四行那句，实际上就是前面提到的构造DFA的过程。人们想到使用Cache。使用NFA，当NFA构造出DFA的一个状态时，就把这个状态构造的条件以及状态本身存到cache里面。当while进一个c的时候，首先看一看现今状态加上c到达的态是不是已经存在cache，如果存在里面，最耗时间的那一部分就不用运行了。cache的管理仍然是程序局限性原则。占用空间不会太大以期望达到折衷的效果。 如果要构造出一个Lax，需要将所有的正则表达式得到的NFA进行一个并操作（保留各自的终态以区分）。然后构造它的DFA。 值得注意的是，这样不能在一个终态停止，而是在错误态终止并退回到最近经过的那个终态（每经过一个终态，记录当前的输入指针以及匹配模式）。以防止找到前缀，产生错误。这种方法是最长前缀法，在前面已经提到过。 DFA优化DFA状态数其实不会太多的影响时间复杂度，当状态变少的时候，将会减少存储空间的消耗。 区分：一个符号串可区分两个状态：这一个串从这两个状态出发在DFA上得到的结果一个是accept，一个是reject。在做区分的时候，其实可以看到：最终字符串得到的终态在不同集合，则他们是可区分的。 Exa不能区分状态A与B。而且还可以看到，以a开头的所有字符串都不可能区分A与B了。再进一步看到，a不可能区分任意两个，因为所有状态在经过a的状态迁移之后都到达了状态B。同理，b不可能区分ACE，以b开头的都不能区分ACE。但是b却可以区分BD。不要忘记，$\epsilon$可是可以区分的。而且他的区分应该被放在最前面，那是因为$\epsilon$区分了终态与其他状态。 在区分的过程中发现了这样一个规律：如果对于串s，A状态与B状态经过了s都到达同一个状态C，那么以s做前缀的字符串都不可能区分A与B了。当所有字符串都不能区分A与B的时候，可以把A与B合并成同一个状态。但是对于无穷的字符串，怎么确定 “所有都不行” 呢？ 在前面，我们已经提出了一个解决方案——当前缀s不行的时候，所有的sx都不行了。但是，即使是有了这个规律，使用“不行”的这种方法解决问题仍会显得繁琐。 真正在执行的时候，实行的是分裂，这样，通过有顺序地枚举字符串，将能被区分开的状态分开。这样对于前面的不同集合的说法，也能更好地理解。 算法描述：首先使用$\epsilon$区分终态与非终态，将它们分为两个集合。随后，像子集构造法那样，有顺序地枚举输入字符串，将那些经过状态迁移能到达终态（不同集合）的状态剔除出去组成一个新的集合（如果两者到达同一个集合，这两者是不能区分的，应该在同一个集合），对于那些含有多个元素的集合，如果经过一系列不同的状态迁移到达不同的集合，仍需要继续分开。直到不再产生新的集合。 仍然使用上面的例子，进行分裂的过程： $\epsilon$ -&gt; {A,B,C,D}、{E} a -&gt; {A,B,C,D} ({B,B,B,B})-&gt;全部一样，以a打头的不用再试 b -&gt; {A,B,C}{D} ({C,D,C,E}) b -&gt; {A,C}{B}{D} ({C,C,D}) -&gt; 不同集合 最终得到的最小DFA： 最后使用新的状态进行迁移的时候，一定不会出现问题。 补充：从自动机到正则表达式可以从一个DFA或NFA得到对应的正则表达式。但是这种方式并不是总是简单的，他只是提供了一个模糊的思路，当一个DFA很复杂的时候，还是需要有聪明才智才行。这里只是简单的给出这个方法，具体可查看这个文件。 为了使讨论更加简单，我们强制一个DFA/NFA应该有下列特性： 初态可以到达任意其他状态，没有状态可以通过状态迁移到达初态 只有一个终态，终态不能通过状态迁移到达非终态 初态不能是终态 除了初态与终态，其他状态彼此相连 这四个条件看起来很可怕，其实当我们引入了$\varnothing$并根据情况添加初态终态之后，很容易可以把一个DFA/NFA转为一个符合要求的有限自动机。 以一个例子来说明： 为了不让自己沾沾自喜，必须指出上面给出的例子很简单，看下面这个： 由于生成initstate的一个要求是，不能有进入initstate的箭头，好，像上面一样加一个init，加一个Ac，随即，在删除A的时候就会发现问题。这尼玛转来转去的究竟怎么写边上的正则表达式啊？！ 能不能与好不好在龙书的第九章。 流程可否更加简洁？ 正则 -&gt; DFA：本质上还是做子集构造法-吧正则的某些位置对应NFA里面状态，位置集对应NFA的状态集 优化结果？ 最小DFA]]></content>
      <categories>
        <category>编译原理</category>
      </categories>
      <tags>
        <tag>编译原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chap2-进程与线程]]></title>
    <url>%2F2017%2F11%2F06%2FOS%2Fchap2-%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[导进程模型的进化： 第一代：relay , vacuum tubes and plugboards。没有程序与进程的概念 第二代：批处理系统：一个程序完成所有工作。 带三代：mutiprogramming and timesharing。CPU可以切换运行。 第四代：现代OS：进程模型更加成熟，进程调度与相互交流更加成熟，内存保护与管理更加成熟。 进程：计算机上所有可以运行的软件，通常也包括操作系统，被组织成若干顺序进程，简称进程。它包括输入输出程序与状态。 需要区分进程与程序。 进程创建：系统初始化、运行进程的创建进程系统调用被执行、用户请求、批处理作业初始化。 进程终止：正常退出、出错退出（自愿）、严重错误、被杀死（非自愿） 在unix中，每个进程有自己的父进程，有着明显的层次结构，但是在Windows中，虽然也有“句柄”来标识父进程，拥有句柄即可控制及对应的子进程，但是这个“句柄”可以被转让，就不存在明显的层次关系了。 为什么要并发（Cocurrency）？whats os? A special kind of system software that can manage computer in efficient and reasonable way. It is in charge of managing hardware resource, controlling the running of programs and providing useful services. It is a convenient platform for people to use computer 进程进程概念 使用cpu的基本数据结构 逻辑程序：被用户设计实现（envs） cpu指令序列： 进程：程序与指令之间的数据结构 进程：进程是某一个特定程序的运行实例，包括输入输出程序与状态。在分时操作系统（time-sharing os）中，CPU被多个进程分享，复杂的算法将被用于进程之间的调度。 进程状态基本状态： running：真正占用CPU ready：可以运行，等待CPU的使用权 blocked：不能继续运行，等待外部事件（输入输出等） 其他状态： new：进程的数据结构已经准备好，但是程序镜像尚未完成装载（env_create到icode_load之前，此时还不可以调用env_run） exit：程序已经完成了所有工作，但是还没有回收进程的数据结构（exit gracefully之后，free之前） suspend：运行镜像已经被换到硬盘里面了 为什么block不能直接过渡到running：你都阻塞了，想回来啊？等吧。为什么ready不能直接block？你都没有运行，怎么直到自己要等待一个外部事件去block？ 那么为什么会挂起呢？ 挂起是由于：1.等待时间过长 2. 物理地址空间不足。导致该进程所需运行资源被切换到外存。 页面置换是一件很麻烦的事情，需要进行一系列的硬盘操作，硬盘是一个极其慢的设备，那么为什么还要有挂起状态？（废话如果内存也能有120G那么多空间谁会给他换到硬盘啊） 提高处理机效率：就绪进程表示空的时候，提交新进程，以提高处理机效率（哈？） 为运行进程提供足够多的内存 便于调试：在调试时，挂起被调试进程对其地址空间进行读写。 什么时候会挂起呢？在进程等待外部事件（阻塞）的时候，有可能被挂起。 除此之外的双挂起模型： 等待-&gt;等待挂起：没有进程处于就绪状态或者是就绪进程需要更多的内存资源。(???)就绪-&gt;就绪挂起：有高优先级的等待进程和低优先级的就绪进程（这是就绪进程被换到外存）运行-&gt;就绪挂起：对于抢先式分时系统，有高优先级的等待挂起进程因事件出现而进入就绪挂起。等待挂起-&gt;就绪挂起：等待的事件到了就绪挂起-&gt;就绪：没有就绪进程或者是就绪挂起进程的优先级比所有就绪进程的优先级都高等待挂起-&gt;等待：有一个进程释放了内存，一个等待挂起进程的优先级很高 值得一提的是，winxp用的就是上面的双挂起模型。 对挂起的详细分析 为什么要双挂起呢，os真的那么缺内存吗？from:gcssloop/note linux下使用的进程模型是： TASK_RUNNING TASK_INTERRUPTIBLE：进程被挂起，直到某些条件变成真。（产生一个中断，在中断中释放一些该进程等待的系统资源，传递唤醒该进程的信号）$$\color{red}{shenme玩意}$$ TASK_UNINTERRUPTIBLE：除了信号不能使它的状态发生变化之外与前一个相同 TASK_STOPED TASK_TRACED：进程运行被debugger打断 EXIT_ZOMBIE：程序运行已经结束了，但是他的父进程还没有调用一个wait4()或是waitpid()系统调用来返回死掉进程的信息。 EXIT_DEAD $$\color{red}{so why… kill之后为什么不死}$$ 不同的os，其状态设置的差异很大。 进程数据结构PCB：进程控制块：这就是在jos里面的envs那个大数组了，它由操作系统内核维护，也叫进程描述符。（经过了jos的洗礼，其实不用说太多） 所有pcb都在一个特定的内存空间之中。pcb表的size决定了os的并发度。不同状态的进程数据被存在不同的pcb表中。 在一个正经系统中的pcb比env中的项更多，列为： 为了将不同运行状态的pcb区分开，可以有两种方法，一种是：另一种是： 其中第一种是在jos中使用的方式。 进程切换进程切换就是我们的sched函数了。切换之前，需要保存在cpu运行程序的山下文（tf内容、pgdir等），切换之后，把新上来的进程的上下文恢复。 比如说sleep的实现：一个进程运行到了sleep，os去处理这个sleep，此时cpu的掌管权在kernel手里，随后设置一个硬件的时钟中断，然后保护现场，最后os就schedule，把运行权交给了另一个进程，另一个进程运行了一段时间之后硬件的时钟中断raise，打断了另一个进程的运行，于是os处理这个时钟中断保护现场，剥夺了另一个进程的运行权，再一次schedule，进程1开始运行。 运行镜像（process image）运行镜像就是☞进程的整个生存周期的描述。 process image的内容： 用户层面：该进程的用户地址空间，比如说程序、堆栈、数据段 寄存器层面：pc、pcw、ir，栈指针其他寄存器 系统层面：pcb等、动态内核指针 （emm个人觉得，其实就是pcb里面保存的那些东西，以及那些指针指向的那些空间） 进程调度算法p82 简述： Q：什么时候调度？ 进程被创建、进程退出 进程阻塞 出现io中断 Q：为什么要调度？ 做更好的选择：优先级、运行时长 保证CPU的效率 Q：怎么做调度？ 使用特定的方式选择一个进程占用CPU 在切换的时候切换上下文 A：注意： 调度的频率是非常重要的 有抢占式调度与非抢占式调度 CPU-bound（计算密集型）与i/o-bound（io密集型）进程 CPU资源的时分复用 ： 进程切换：CPU资源占用者切换 处理机调度：从就绪队列中挑选进程、从CPU中挑选可使用的CPU 调度程序：调度策略、调度时机 when and why上述的调度时间是一个笼统的说法： 内核运行调度程序的条件 进程退出 进程从运行态切换到等待 非抢占系统中 当前进程主动放弃CPU 可抢占系统 当前进程时间片用完 中断请求被服务例程响应完成时 其实在写完jos的sched函数之后，对何时调度应该有一个认识：无论是何时调度，都是os编写人员决定的（或是用户程序主动放弃）。os为了避免用户程序不自觉，提供了时间中断（timer interrupt），在每一个时间终端的处理中指定schedule。再比如上面提到的io中断，这部分也是os决定的sched，因为trap(jos)是属于kernel部分。 调度的目标：不同的系统中目标是不同的 在所有系统中： 公平性：给每一个进程一个公平使用CPU的机会 策略强制执行:seeing thatstated policy is carried out 平衡：保持整个系统都是有事可干 批处理系统： 吞吐量：使单位时间的工作量达到最大 周转时间（turnaround time）：在任务提交与任务完成之间时间尽可能小 CPU利用率：让CPU一直有事可干 交互系统： 响应时间 Proportionality：达到用户期望值 实时系统： meet deadline：别丢数据 可预测：在多媒体系统中别有质量上的降低 goal那么给定一个调度算法，怎么比较他们之间的优劣呢？ CPU使用率 吞吐量：单位时间内完成进程的数量 周转时间：进程从初始化到结束绝对时间 等待时间：进程在就绪中的时间（不算等待状态的时间，因为这个时间其实是必须花费的） 响应时间：从提交请求到请求响应时间 吞吐量与响应时间之间的区别 吞吐量是什么呢？其实就是希望通过合理的调度使规定时间内完成更多的进程，比如说文件传输的时候希望高带宽（10M/s与10k/s你想要哪个？）。响应时间是什么呢？就是希望进程对某一个动作尽可能快的作出反应，比如点击按钮搜索之后多久才响应。 吞吐量与响应时间其实是很不同的两个概念，两者我认为在某种情况下是此消彼长的。吞吐量描述的是整体，响应时间描述的特定。 响应时间目标： 减少响应时间 减少平均响应时间的波动在交互是系统中，减少平均响应时间波动其实更加重要。 响应时间是os的计算延时。 吞吐量目标： 增加吞吐量：减少os开销（减少上下文切换）、系统资源的高效利用（CPU、io） 减少等待时间：减少每个进程在就绪呆的时间os需要保证吞吐量的提高不会影响交互体验（os必须不时地进行调度，即使存在许多交互式任务） 吞吐量是os的计算带宽 批处理系统中的调度算法吞吐量、周转时间、CPU利用率 先来先服务：非抢占式 笨蛋算法、简单，某些情况下也合理、io密集型系统中对CPU利用率低到令人发指 最短任务优先：非抢占式 周转时间短、在现实的os中并不会是最优的 最短剩余时间优先：抢占式 将新任务的时间与当前任务的剩余运行时间做对比，如果新任务时间短就让新任务占据CPU、不现实啊 三层调度 admission scheduler memory scheduler CPU scheduler 先来先服务（FCFS）就是先来先运行，也没有抢占，运行到结束就行了。 优点是非常简单，但是缺点更加明显。 平均等待时间波动很大，短进程可能会在长进程后面 资源利用率低（一直运行一个你说利用率能高吗），CPU密集型导致io闲置，io密集型导致CPU闲置。 说到这里就想起来一个题外话。上编译课的时候编译老师说他上学那会儿用的编译器是非常老的编译器，性能也不好。一般都是晚上离开实验室的时候把写的东西运行上，第二天回来实验室的时候能出结果都已经很不错了。os课的时候老师说，假如你买了一个服务要去运行自己的程序，本来你就是一个hello world，前面那个人的程序可能特别庞大需要一天来运行，你倒霉催的正好排在那人后面，你可能几秒就完事了，但是那个服务器好巧不巧用的FCFS，那你可就等吧。 最短时间优先算法（SPN）每次选择就绪队列中的运行时间最短的进程来执行，就绪队列按照预期的执行时间来排序。 非常容易就可以想到的是，SPN必定具有最短平均周转时间。（如果学过贪心算法，应该很清楚这一点）（吞吐量可不会，SPN是非抢占，只能串行运行的） 缺点也非常明显，你一直运行hello world，人家正儿八经的要运行一天的大程序什么时候才能开始运行啊？可能会导致饥饿。 还有一个需要解决的问题是如何预测程序运行，不太可能准确预测一个程序需要的执行时间，尤其是当ifelse while等语句十分的情况下，这种运行时间一般都需要在运行时才能确定。不能预测这个算法还有什么好实现的？还有一种方法是问用户，你不能保证用户都是诚实的，但是你可以最多分配用户指定的时间，超出时间就杀死。但是这种方法真的太不友好太不专业了，程序运行中的状况很多，用户也不一定知道运行时间。 所以这种方法其实是不太可行的。 最短剩余时间优先算法（SRT）是SPN的可抢占改进版，允许当新进程进入时新进程如果运行时间很短可以代替老进程运行。 其实这才改是真正的最短平均周转时间。（即使是可抢占，也与吞吐量高无缘，又不会在等待的时候调度）。 缺点也差不多与SPN差不多。 最高响应比优先算法（HRRN）选择就绪队列中响应比R值最高的进程。不支持抢占。 响应比：R=(等待时间+执行时间)/执行时间 那也就是等待的时间越长越容易被选中。是在短进程优先算法基础之上的改进，防止无止境地等待。 三层调度 交互式系统中的调度 时间片轮转：抢占式 时间片耗尽时触发调度、进程等待（阻塞）时触发调度 多级队列： 有多种优先级class，美哟中class存在同一个队列、根据优先级选择进程、高优先级低时间片保证公平 优先级调度：抢占式 每个进程有自己的优先级、CPU选择最高优先级、动态优先级来避免饥饿 处理机资源的使用模式： 进程在CPU计算与io之间进行交替：每次调度决定在下一个CPU计算时将那个工作交给CPU，在时间片机制下，进程可能在结束当前CPU计算之前放弃CPU。 时间片轮转 （RR）每当时间片结束，就会引发一个调度，每当进程自己要等待，引发一个调度。每当下去，自觉排在队尾。 时间片轮转的问题是： 额外的上下文切换开销 时间片选择问题 其实归根结底是时间片选择问题，额外的上下文切换是一定必须的。如果时间片选择太大，就失去了调度的灵活性，等待时间变长，这在交互式系统中可能是不可忍受的。甚至在极限情况下，就退化成了上述的FCFS。如果时间片选择太短，将会浪费大量的时间在上下文切换。比如在linux，上下文切换一次可能需要1ms，如果4ms是时间片长度，那么整个系统中有20%的时间都在做上下文切换。这是没有意义的浪费。经验上，一般将浪费控制在1%，实践篇一般设置在20-50ms。当n（就绪队列长度）比较大的时候，可以把某一些就绪状态的进程给传到就绪挂起。 多级队列调度算法（MQ）就绪队列被划分为多个独立的子队列（终端、io、前台交互、后台批处理）每个队列可以有自己的调度策略（前台RR，后台FCFS等）队列之间的调度： 固定优先级：可能导致饥饿 时间片轮转：每个队列得到一个确定的能偶用于调度其进程的CPU总时间（比如前台80%后台20%） 多级反馈队列算法（MLFQ）进程可以在不同队列之间移动的多队列算法。时间片大小可以随着优先级级别增加而减小，如果进程在当前的时间片没有完成，降到下一个优先级。 其特点是：CPU密集型的进程优先级下降很快，而io密集型进程停留在高优先级。 优先级算法（PS）是多级队列算法的改进，平衡各进程对响应时间的要求。分为抢占式与非抢占式。通常可以控制其时间片长度。如果io完成，提高优先级，如果时间片用完，将低优先级。 静态优先级：在创建进程的时候，他的优先级就被确定，直到进程终止之前都不会改变。（系统进程优先级高、io密集型优先级高） 动态优先级：优先级在创建的时候被赋予，但是在进程运行的过程中可以被改变： 在就绪队列中，等待时间延长优先级高。 进程每执行一个时间片就降低这个进程的优先级。 对于不同类型的进程：io密集型进程：他是最高级优先。为什么io密集的优先级比较高呢？这是因为io密集型一般只会占用一小会儿CPU，随后就会等待io外部操作去了。最好的做法是，io一旦就绪就赶紧用一下CPU，然后就可以去等io事件了。如果io密集型进程的优先级比较低，将会浪费很多时间在就绪的等待上。CPU密集型时常需要CPU资源，由于优先级低，可以使用更大的时间片，减少上下文切换的浪费。 动态处理：对于io密集型，尽量别减小优先级。（如果是MLFQ，这是几乎可以保证的，因为io密集，可能在给定的时间片中没有用完时间片就自己进入阻塞状态了）（me）对于cpu密集型，在它的io完成之后，放回io请求时离开的队列，以免每次都回到最高优先级再逐次下降。 最短进程优先保证调度向用户做出明确的性能保证，然后去实现它。 初始：每个进程同等的share CPU。随后：计算每个进程理应获得的时间与实际获得的时间之比。结果：倾向于运行比率更低的进程，直到它的radio超过他的接近竞争者。 彩票调度就是os卖彩票，给每个进程一个彼此不同的彩票，一旦需要调度，就抽彩票，看看谁中奖，中奖的哪个进程获得资源。”所有进程是平等的，但是有一些进程更平等一些“给某些重要的进程额外的彩票，增加他们中奖的几率。 允许进程之间交换彩票，比如客户机进程获得了运行权，然后阻塞等待服务器的响应，这时客户机可以把自己的彩票给服务器机进程，以增加服务器及进程被选中的机会。（实际上，如果没有客户机进程，服务器及进程的存在就是一个错误） 调度实现unix：动态优先级算法5.3BSD：MQWindows：优先级算法Linux：抢占式调度（preemptive scheduling） 调度机制设定$$\color{red}{什么鬼这是}$$ 在oskernel设计调度算法，就像我们的schedule函数在kernel中完成，并封装用户接口供用户调用。 除了时间片，允许用户也做出调度的决定，完成调度策略设置。 可以参考lab4的文档 进程之间的通信消息、管道、消息队列、共享内存 可以参考lab4文档，里面有ipc以及lab5中有共享内存。 线程线程是进程中一个相对独立的、具有可调度特性的执行单元。 线程一定不是陌生的，早在大二上学期，就在Java中接触了线程。线程作为实现进程中的并发而存在。 系统提供了线程库Pthread： 线程库线程库是针对那些不提供多线程支持的os而设计的在用户态下的库，线程库的处理对这些os是透明的。 即使提供了核心线程支持的os，也有必要提供线程库，可以简化或有利于线程机制的使用。 线程库提供： 合适的多线程编程的接口 记录线程状态和调度各个线程的运行机制 在系统内部可以使用多种方式实现线程机制： ULT纯用户级线程：线程管理全部由用户程序完成，kernel只管理进程，增加”线程库“概念。 KLT核心级线程：线程有kernel管理，kernel为用户提供系统调用。 ULT：进程表在kernel，线程表在用户空间，使用线程库。线程表由运行时系统管理。 ult的优点是： 线程切换不需要陷入内核：比陷入内核快一个数量级 允许进程制定自己的调度算法而不会影响os的调度算法程序 ult管理模式可以在任何os下运行，不需要修改内核，只需要线程库。 ult的不足是： 系统调用会引起进程阻塞 不利于多处理器并行（why？？？） 关于系统阻塞的问题：os并不知道进程里还有线程，当一个线程在尚未发生键盘操作的时候读键盘，将会引发阻塞。这时可能整个进程都会被os的调度算法调度下来，整个进程都会阻塞。而要使用线程，应该允许每个线程都能够阻塞调用，而不影响其他线程的运行。现在显然是不行。有两种解决方法，一是修改read在没有外部事件时返回0，但是对read语义的改变休要大量代码的修改。另一种是允许进行阻塞检查，仅在外部事件发生时才进行系统调用，否则先让出使用权给其他线程运行。这种方式一点都不好看，但是也没有其他的方法了。 还有一个问题是进程的无休止运行。没有时间片操作。对ult最大的争论是程序员一般只会在经常发生线程阻塞的程序中才会大量使用线程。 klt：线程与进程都在用户空间完成（what？）进程表与线程表都在kernel 优点：线程在kernel中有信息，系统调用基于线程（不存在上述的阻塞）可以克服ult的阻塞与并行度差的缺点，并且kernel也可以使用多线程。 缺点：每次进行线程调度都需要陷入内核 线程的概念线程使劲蹭的一部分，描述指令流执行状态，是进程中的指令执行最小单元，是CPU调度的基本单位。 在进程与线程机制中，进程作为资源分配角色，包括地址空间、打开文件等；线程作为处理机调度角色，描述进程资源环境中的指令执行序列状态。 进程的表叫做TCB。 为什么进程有自己独立的栈？进程描述了指令执行状态，而栈中数据与之前执行的指令有关，因此每一个线程都应该有自己的栈。保证执行指令的独立性。 调用函数返回 errorno 进程中内容 线程中内容 地址空间 程序计数器 全局变量 寄存器 打开文件 堆栈 子进程 状态 即将发生的报警 信号与信号处理程序 账户信息 进程与线程|进程|线程||资源分配单位|CPU调度单位||有完整的资源平台|只独享指令执行的必要资源||基本状态与其他状态与转换|就绪等待运行状态与转换| 线程：减少并发执行的时间与空间开销 创建时间比进程短（why） 终止时间比进程短 同一进层内的线程切换时间更短 同一进程之间的线程共享内存与文件，不需要通过内核进行通信。 what is 多对多 轻权进程内核支持的用户线程。 一个进程可以有一个或者多个轻量级进程，每个轻权进程由一个单独的内核线程支持。太过复杂，最后被抛弃。 经典IPC问题进程之间的通信，可以参见lab4ipc。 进程之间通信 进程之间通信将产生什么问题？ 异步：从一个进程传递信息到另一个 排外：与其他进程争夺资源 同步：维护适当的运行序列 进程之间通信的难处： 信息的格式：signal、switch、message 排外与同步：合作问题 金字塔规则 竞争条件：两个或多个进程读写某些共享数据，而最后的果取决于进程运行的精确时序。 书上有一个打印机的例子， 就是说A与B都需要使用打印机，打印机维护in与out指针，供所有进程去访问。假设某一时刻A想打印东西，于是去查找out指针的值，存在临时变量next_free里面，这时时间片来了B上来了，B也要打印东西，于是正常的完成了将东西放在out的位置，out++。这时A回来了，他发现自己next_free是原out值，于是覆盖了B的文件数据，然后把next_free加一，存到out里面。 生产者与消费者问题固定大小buffer，生产者加数据，消费者拿数据，更新count，当count是0的时候，消费者休眠，是N的时候生产者休眠。每个进程检查唤醒。 ——在数据更新的过程中访问了数据！ 概念：race condition：两个或更多进程竞争同一项资源，在一个进程占用资源的时候其他进程不应该访问。critical region：对共享内存进行访问的程序片段优秀结果标准： 不可以有两个进程同时处于临界区 不应对CPU的数量与速度有要求 临界区外运行的进程不能阻塞其他进程 进入临界区时不能无限等待 《甘特图：临界区》 实际程序中，可以将所有代码根据是否访问共享区域分为四个部分： 1234entry section critical sectionexit section remainder section 家庭采购协调问题 时间 A B 3:00 看冰箱 没面包 – 3:05 离开家去商店 – 3:10 到达商店买面包 看冰箱 没面包 3:20 到家，放面包 去商店 3:25 – 到商店买面包 3:30 – 到家，放面包 我们分析这个问题： 如何保证买面包动作的成功与高效：有且仅有一个人去买 可能的解决：加锁 导致的问题：无法取到冰箱中其他东西（具体查看PPT，时间有限） 关于临界与外部事件发生：可以将等待临界空闲的进程转到阻塞态。 忙等待设计思路：通过全局变量保存临界区状态供进程参考 屏蔽中断（disabling interrupts）基本思想是在进入临界区之前关中断，这就导致时钟中断也会被关闭，从而没有进程可以打断它。 问题： 不支持多CPU 把关中断权限交给用户是不明智的选择 但是对于内核来说，关中断是一种很好的方法，可以用来维护多线程（如果支持）或者多CPU之间对就绪队列等的访问（别都选到一个进程就尴尬了，在jos里这会发生错误）（话说，在jos里面实现多CPU的时候可有内核锁机制，下面来看一看锁都加在了哪里） 锁变量（Lock variable）保存一个名为lock之类的全局变量供各个进程进行检查，实际上无济于事——这不也是临界区吗 严格轮换法（Strict alertnation）要求进程轮流进入临界区。看了代码就会明白： 12345678910111213while(true)&#123; while(trun!=0);//A进程必须等待turn是0的时候才能进去 critical_region(); turn=1; noncritical_region();&#125;while(true)&#123; while(turn!=1);//B进程必须等到turn是1 critical_region(); turn=0; nocritcal_region();&#125; 不是一个很好的方案。 缺点： 违反了“进程不应该被处于非临界区的进程阻塞” 浪费CPU时间：忙等待时间 很明显啊，他们在轮转的时候，如果A这时需要进入临界区但是B在运行非临界区的程序，A可以被放到阻塞态，这时违反了规则3A可以继续循环，这时每次A上去CPU都会浪费时间空循环，还不如去阻塞态。 还有，如果A需要多次进入临界区，而B主要时间在非临界区，A的效率就变得非常低，绝大多数时间都是在空转。 自旋锁：用于忙等待的锁。 PPT另有两种，都是失败的方法。暂且不提。 Peterson算法1981-满足线程之间互斥的经典基于软件的解法 似乎仅用于两个进程：wiki 1234567891011121314151617#define FALSE 0#define TRUE 1#deine N 2 //进程数量int turn;//轮到进程编号int interested[N];个各进程是不是想去临界区，是不是已经在临界区void enter_region(int process)&#123; int other;//在临界区的 other=1-process; interested[process]=TRUE;//我想进去l临界区 turn=other;// while(turn==other &amp;&amp; interested[other]==TRUE);//&#125;void leave_region(int process)&#123; interested[process]=FALSE;&#125; 运行到while处可能会挂起。 怎么使用呢？在每个进程进入临界区之前调用critical_region，退出之后调用leave_region。 扩展到N个线程的互斥filter算法： TSL指令：TSL RX LOCK 将lock给rx然后往lock中存一个非0值：保证原子操作，锁内存总线。 代码： enter_region: TSL REGISTER , LOCK//原值在寄存器，新值在内存 CMP REGISTER,#0 JNE enter_region RET//原来是0，可以进去了 leave_region: MOVE LOCK , #0 RET 一个可以代替tsl的是xchg（是不是很眼熟！）xchg完成的操作是交换两个位置的内容。 enter_region: MOVE REGISTER,#1 XCHG REGISTER,LOCK CMP REGISTER,#0 JNE enter_region RET leave_region: MOVE LOCK, #0 RET 锁是一个抽象的数据结构，有方法Acquire与Release。 在获取所的时候，如果锁目前被别人拥有，就等待。释放锁的时候，通知那些等待的进程你们等的锁到了。 自旋锁使用TSL实现自旋锁： 123456Lock::Acquire()&#123; while(test-and-set(value));&#125;Lock::Release()&#123; value=0;&#125; Acquire:不停地区获取锁的值并将锁的值赋为1，直到锁的值变为0。（说明有进程从临界区出来了） 忙等待确实可以解决2个进程之间互斥运行的问题，但是缺点也很多，浪费CPU时间，编程困难，可能会造成优先级错乱。 无忙等待锁 睡眠与唤醒进程间通信原语，在无法进入临界区的时候进入阻塞状态而不是忙等待。 当一个进程发现自己不能进入临界区的时候，就系统调用sleep，阻塞去。另一个进程要离开临界区，就调用wakeup将她唤醒。sleep\wakeup(pid); 简单睡眠唤醒机制正如上述。 悲惨的是，假如wakeup信号丢失了，没有被唤醒的进程还在阻塞，假如剩余一个进程进入临界区需要该进程的作用，就都阻塞。 对MCPU不支持：使用进程号。 终于，现在可以考虑一下生产者消费者的解决了： 略。可见书或PPT 这是失败的解决，可能会导致wakeup信号丢失结果二人都去阻塞。 信号量解决P-&gt;down V-&gt;up 信号量：一种新的变量类型，表示唤醒操作剩余次数。（所有相关线程引起的总竞争条件检查次数）信号是一个抽象数据类型，由一个整形变量与两个原子操作组成。 down：对某个信号量down是检查他的value，如果不是0，就减一，如果是0就去sleep。up：对某个信号量的值加1。如果睡眠，就唤醒。 信号量是被保护的，在初始化完成之后，只能通过pv修改，而pv操作是被保证的原子操作。 通常嘉定信号量是公平的，也就是说不会一直被阻塞在p操作。（假设先进先出） 信号量的实现与前面说到的无忙等待锁很像：其实block也相当于被调度了。 区别在于前面说的无忙等待锁并不是原子性的。 解决方案：每一个临界区设置一个信号量对象，初值是1代表初始时可以进入一个到临界区去。p在进入之前，v在进入之后。必须成对出现。 同步同步可能会被调度序列打乱。（？） 同步与互斥的区别： 互斥值放值其他进程进入cr 同步是指实现一个合理的逻辑序列 whats this ipc问题分析——使用信号量解决生产者消费者问题1.ipc问题产生 原因： 物理序列依赖于调度 逻辑序列依赖应用层需的意愿 竞争条件排斥资源获取 在内核态以及用户态都有ipc问题，在内核态是io设备的管理，在用户态是网络应用、数据库等的管理。 ipc问题的关键在于： 理解逻辑与物理序列 逻辑序列依赖于调度 逻辑序列可以被用户控制 whats that….. 使用信号量可以实现条件同步。 生产者消费者问题：一共需要三个信号量：mutex\full\empty。首先，buffer是一个临界区，无论核心进入临界区出来临界区都需要一个信号量，其次，当buffer满的时候（N），生产者不可以进去buffer，需要消费者消费之后up才能进，消费者同理。我认为，后两者实际上是在利用信号量的特点完成程序的逻辑部分，而不仅仅是对临界区的进入控制。 monitor solution信号量的一个缺点是对编程者来说不好写出代码。 monitor（管程）是一对过程、变量、数据结构的集合，（可以被看作是编译器），他们组成一个特殊的模块或软件包 应用：任意时刻管程中只能有一个活跃进程（有效完成互斥）wait and signal：就像pv、du一样不足：只有很少的语言支持。 管程组成：一个锁（管程代码互斥）、0或多个条件变量（管理共享数据的并发访问） 进入管程时的互斥由编译器完成 条件变量：（像是信号量一样的东西）是管程内的的等待机制，允许在进程无法继续运行的时候被阻塞。wait：无法继续运行时调用，将自己阻塞并掉一个互斥访问进管程signal：指示一个呼哧进程开始运行，自己退出管程。 wait与signal很像是在之前的sleep与wakeup。但是关键的区别是，这里管程保证了互斥，不允许在wait之前切换进程进入管程。（其实存疑） 条件变量实现 管程解决生产者-消费者问题 hansen与hoare hansen主张signal只能是管程过程最后一个语句，二hoare则认为不一定，主张signal之后就应该自己阻塞让新的进程进入管程运行。 也是因为这样，，hansen的判断方式使用while而hoare判断使用if。 并发与同步-xybaby 同步互斥，就是在并发的前提下保证一些操作的原子性。 IPC问题：哲学家就餐对互斥访问有限资源的竞争建模 进程同步也是进程之间直接的制约关系，是为完成某种任务而建立的两个或多个线程，这个线程需要在某些位置上协调他们的工作次序而等待、传递信息所产生的制约关系。进程间的直接制约关系来源于他们之间的合作。 from：浅谈进程同步与互斥的概念-宋沄剑 分析互斥：相邻哲学家只有一个人可以使用筷子 同步： 想要进餐的哲学家应该拿到两个筷子 同一时刻至多有两个哲学家一同进餐 死锁与饥饿避免 ppt IPC问题：读者与写者为数据库访问建模 （会不会产生问题：在不是writer想要放弃的时候强迫writer放弃）——理解错误，P：可不可以得到资源？可以，OK继续执行：不可以OK我去阻塞这个“我”指的是“调用P的那个过程。 保证公平这个，concur是什么？是 ##IPC问题：睡觉的理发师 猴子过索桥消息传递]]></content>
      <categories>
        <category>OS</category>
        <category>课</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[chap3-内存管理]]></title>
    <url>%2F2017%2F11%2F06%2FOS%2Fchap3-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%2F</url>
    <content type="text"><![CDATA[内存中的概念地址空间：一个进程可用于寻址内存的一套地址集合。内存管理：逻辑地址与物理地址之间的映射内存管理的特性： 高效：使得更多的地址可以被使用（其实都是骗–人–进程的） 合理：alloc、free、locate、protect 便利：？内存管理class 简单机制：静态固定 复杂机制：交换、paging 为什么会有这种欺骗的行为存在呢？程序员希望拥有一个又大又快又永久的存储器，希望他们的寻址方式是统一的；但是实际上，又快又大又永久的存储器目前还是不现实的。现在我们有的是： cache：非常快，昂贵 内存：速度适中，价格适中 硬盘：慢，廉价 在计组课里面应该就学过一个各种存储器的速度金字塔。最快的寄存器甚至是按照字节来计算的存储设备。 于是提出问题：如何使用有限的高速存储设备以及较多的低速存储设备来提高的响应速度呢？ 内存管理的任务 申请与撤回：资源管理 地址转换：映射管理 分享与保护 空间扩张：你本来不可能占4G的，你非说你占了4个G 动态重定位 从接口中知道，CPU希望访问一个地址的时候，会给出对应的地址（上总线）以及对应的读写信号etc。 对程序员来说，每一个程序就是一方天地，并不想在程序里面去思考你os应该解决的存储问题，程序认为自己的地址都是从m开始，想访问哪里就访问哪里，但是os并不可以这样做。就像在实验中提到的那样，程序的elf（exe）文件中会有自己的链接地址，这个地址表示程序假设自己被加载到内存的位置，os加载运行的时候需要进行重定位，对程序中相关的地址都经过变换。 对于上述问题，使用两个寄存器来解决，一个是基址寄存器，一个是界限寄存器，它们在每一个CPU中都存在。基址寄存器存储当前进程的开始物理地址，界限寄存器中存储该程序长度。 当使用一个地址a的时候，首先判断a是否大于界限寄存器中存储的值，如果不是，再将a加上基址寄存器中的值，然后送到地址总线。这些动作都是CPU硬件完成的。 monoprograming：单道程序处理multiprogramming支持多个进程的os内存管理都需要做什么？ 申请空间、释放空间 地址转换、内存保护（several method） CPU利用：MTF的表现 内存扩张：更加柔韧的内存管理 使用partition来为每一个进程分配空间 动态分区分配：当程序被加载执行时，分配一个进程制定大小可变的分区，在此分区内地址连续os需要维护所有进程的已分配数据结构以及空闲分区。$$\color{red}{whats this}$$ 交换技术通常情况下内存是不够用的。仅仅Windows后台应用都会占据一些内存，更不用说开浏览器，开vs等等。为了处理这样的情况，需要，把某一些进程放到外存，为当前运行进程提供内存空间。 交换：把一个完整的进程调入内存，使该进程运行一段时间，然后存回磁盘。这里提到的交换还不是后面说到的页面置换。 交换中的内存管理： 数据结构与算法：如何描述内存的使用 ； 如何申请、free内存 函数执行：如何消除内存碎片 核心问题的方法？灵活性、稳定性、扩展性 关于内存碎片：每次移入内存都是固定的大小，但是有时会移出去，有时会移进来，最终可能会产生许多内存空洞。为了消除内存空洞，需要进行碎片整理（内存紧缩），这个操作很花时间。 碎片整理：紧缩：什么时候移动？ 碎片整理：分区对换：通过抢占并回收处于等待状态进程的分区，增大可用空间。 核心问题：写程序肯定会经常new吧，这个new是动态分配的内存，只有在运行到这里的时候才会去帮你分配，这种空间是不可预知的，无法准确计算需要空间的最大值。于是在为没一个进程分配空间的时候都可以多分一点。这种分法带来新的问题：将进程换回外存的时候其实并不需要换那些没有有效数据的地址，这是一种浪费。 交换的空闲内存管理位图就像lab5中的bitmap一样，0代表没有占用，1代表占用。不同的是，这里一个bit代表可能是内存中的一个分配单元，可能是4byte，可能是其他。 但是使用位图的话，不利于分配连续的空间，因为需要查找连续的固定字节空间的时间可能比查找一个分配单元空闲多花更多时间。 链表这并不是lab2中使用的方法。 维护一个空闲内存段链表与已用内存段链表。在每一个节点标志其状态以及开始地址以及连续地址。 这种方式对上述问题友好。新的问题是如何进行节点的更新与回收，这需要节点的合并与删除、增加等操作 分区管理分配算法： 当进行内存申请的时候，希望能尽量避免做内存紧缩，这就需要更好的申请方式，而不是每次遇到剩余空间比自己更多的就决定要这个块。 首次适配：时间性能好、但会容易导致内存碎片 下次适配：从上次分配的分区开始查找。时间性能好、空闲去分布均匀，较大的空闲分区不易保留 最佳适配：较大空间保留，碎片小而多 最坏适配：着更大的分配：较大分区不会被保留 最佳适配与最坏适配都可以通过维护二级索引来实现更快的查找 快速适配：链表的改变十分费劲。为常用大小的块提供专门的索引 总结：mono\multi\swap 位图连续空闲空间寻找 链表的空洞 交换的缺点： 内存碎片 内存的动态增长 如何利用小空间运行大进程？ Mono MFP Swapping Size of proc total mem partion size total size of free mem Alloction static static dynamic multi-programming unsupported supported supported mem space continuous continuous continuous mem growth unsupported un supported 除了上述的碎片整理，还有覆盖技术：（程序员控制 划分功能区（ifelse） 确定模块之间的覆盖关系 执行之前预先加载并交换 其实是很不好完成的，基础就不好完成，不好判断功能模块，要求的编程技巧太高。 但是，从覆盖技术引出了一个：虚拟内存 虚拟内存 进程的程序段、数据段、堆栈段的总和可以大于物理存储空间 进程不必完全装入内存 os定时将暂且不用的信息换出内存 os负责将换出去的换回来 分页 页：描述进程逻辑空间的单元 页框：描述物理内存中对应的单元 页表：页与页框之间的映射 在标准的4KB页面中，位数分别是10-10-12 页转换在mmu中完成，CPU访问到的，在程序之中执行的都是虚拟地址。 还记得在计组实验中还被问到了1/0是干吗的，至今难忘。 可能会有是否越界的比较（在标准中不存在，这是因为数据都是正好的） 为了考试… 虚拟地址（英语：Virtual address space）在電腦的专用术语中是指标识一个虚拟（非物理地址）的实体地址。虚拟地址这个术语常用在虚拟内存和虚拟网络地址当中。from wiki 在计算机科学中，物理地址（英语：physical address），也叫实地址（real address）、二进制地址（binary address），它是在地址总线上，以电子形式存在的，使得数据总线可以访问主存的某个特定存储单元的内存地址。from wiki 虚拟内存是计算机系统内存管理的一种技术。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。与没有使用虚拟内存技术的系统相比，使用这种技术的系统使得大型程序的编写变得更容易，对真正的物理内存（例如RAM）的使用也更有效率。from wiki 页表项结构概念page number：逻辑空间中的页id，frame num：物理空间中页框的idp/a：页是不是在内存里面protected：r/w/e，记录页允许的访问modified：是不是被修改（脏位referenced：这个页有没有被使用disable caching：页面禁用高速缓存 why 禁用高速缓存？对于那些映射到设备寄存器而不是普通物理内存的页面来说，不希望在自己等待设备对自己刚发出去的指令做反应的时候自己的导向地址竟然是cache而不是外部接口。 in ppt: page num p/a frame num protected disable caching referenced modified Design issue 多级页表10-10-12 除了修改位，每集页表项都是一样的。在非底层页表中，取值为0 其实还可以更多级。 加速分页过程：TLB快表：一个将虚拟地址直接映射到物理地址的小型硬件设备，通常在MMU中，其中的项基本不超过64个。 将虚拟地址放在MMU中进行转换时，首先查快表：将该页面号与TLB中所有项同时（并行）进行匹配，如果命中，而且不违反保护位，页框号可以直接从TLB拿出，不必再进行内存访问（访问存储有页表项的内存），如果保护位不允许，就会发生一个页面访问错误。 如果不命中MMU就从内存中找页表项，并将最终找到的页号与页框号等拿出，淘汰tlb中某一个项并添加新来的项。 当从tlb中淘汰值的时候，记得将tlb中存储的修改位换到页面。 tlb表项（示例） 有效位 虚拟页面号 修改位 保护位 页框号 1 123 1 RW 31 1 87 0 RX 87 … 既然TLB这么厉害，为什么不搞一个很大很大的TLB呢。TLB属于高速设备，功耗非常大。 加速分页过程：软件TLB当tlb失效的时候，mmu将会告诉os，让os找到要找的页面，从tlb删除一个页面，把这个页加上去。必须在有限的指令内完成，因为tlb失效更加频繁。 但是，当tlb更大一些，这种机制就会变得很有效。这样做的好处是得到一个简单的mmu，从而为CPU其他性能改善提供了空间。 os可以“直觉”那些页面要被使用，然后预先加载到tlb。 《？》在内存固定位置维护大的tlb表项的软件高速缓存。首先检查这个缓存，os可以实质性地减少失效。 软失效：页面在内存中但是映射不在tlb。硬失效：页面本身不再内存（当然也不在tlbso为什么是这样） 针对大内存：反置页表 为什么会出现反置页表？在64位系统下内存64位系统，如果仍然保持一个页是4K，那么一共需要有$2^52$个页，只是存储这些页就花费几百G的空间，显然是不合理的。 而目前面临的状态是实际的内存很小，于是可以为每一个页框记录一个页表项。这样对于4K的页以及1G的ram只需要$2^18$个页表项即可。页表项中记录哪一个(进程,虚拟页面)对应于该页框。虽然节省空间，但是不足也是很明显的：将虚拟地址转换为物理地址变得困难 可以使用tlb。但是当tlb失效的时候就很难。基于hash：把虚拟页号与进程号作为输入，得到的散列值来寻找。 hahs冲突 虚拟存储的基本特征： 不连续（$\color{red}{啥叫虚拟地址空间使用非连续？是说各个区分开吗}） 大用户空间：提供给用户的虚拟地址空间可以大于实际的物理内存 部分交换：虚拟存储只对部分虚拟地址进行调入调出。（不会像交换一样一下一个进程） 虚拟页式存储的外存管理： 在哪里保存没有被映射的页？ 需要可以方便的找到在外存中的页面内容 交换空间（磁盘或文件）：采用特殊格式保存没有被映射的页面 虚拟页式存储中的外存选择 代码段：可执行二进制文件 动态加载的共享式程序段 其他段：交换空间 虚拟页式存储的性能：有效存储访问时间 EAT=访存时间*(1-p)+缺页异常处理时间*缺页率p pagingsys的工作流程 全局pgtable初始化 创建进程 获取首指令 pgfault 加载页 更新pgtable 更新tlb 页替换 pgfault 选择一个页，写回磁盘 把新页换到这里 更新tlb 缺页中断 如果内存还有剩余页，分配；把希望访问的页从disk装到这个物理空间，把这个页对应页表的a/p置为1，物理地址映射到新分配的物理地址，重新执行引起缺页中断的指令 如果内存没有剩余的页面，依据页面置换算法选择一个将会被替换的物理页，如果这个物理页的值被修改过，把内存中的值写回外存，把对应逻辑页的a/p置为0，把希望访问的物理页装到这个空间，修改物理页对应的逻辑页面的指示物理页地址以及存在位，重新执行却页指令。 我现在认为，前面提到的挂起状态与现在说的“为了腾内存空间而将一些进程存储的东西先存到外存”是不一样的。挂起的意思应该是pcb都被移动到了外存，根本无法找到这个进程的运行情况，地址空间等；但是这里仅仅是为了节省内存空间，将某些页换到了外存，该进程还是可以继续运行的。只是在需要用这些页的时候可能会引发缺页中断。挂起存在的理由不仅仅是为了节省内存，还有一点是为了更有效的调度，因为所有调度算法考虑的都是就绪队列的进程。 概念 缺页中断：需要的页不存在内存之中 页替换：当所有的物理页都被占用；选择一个页被换出去 表现： 抖动：耗时，低效率 预测：在需要之前就把页面加载进来 最优方案：最远将来（不现实） 页面置换算法的功能与目标： 功能：当出现缺页异常并且物理内存已经被占满，调出一个物理页给新需要的页使用 设计目标：极可能减少页面的调入调出次数 页面置换算法最优页面置换算法通常是衡量置换算法的标准 置换在未来最长时间内不访问的页面 最近未使用：NRU发生pgfault的时候，检查所有页面，将页面分为四类： 没有访问 没有修改 没有访问 已经修改该 已经访问 没有修改 已经访问 已经修改 需要替换的时候按照首先替换0的规则进行替换。 这是因为每次访问页面都会引发中断：写R/W位，于是os可以利用这个时间做一些事。定时把R位清零来区别最近没有被访问的和已经访问的。 FIFO替换最先被换进来的。 通过维护一个记录所有位于内存的逻辑页面链表，将该链表按驻留时间排序，联手最长，连伟最短。缺页的时候进行置换，新页面加到链尾 实现简单，可以用硬件实现，但是性能很差，基本不会单独使用这个算法。 Belady现象： 分配的物理也数增加，但是却也次数也会增加的现象。 原因：FIFO的置换特征与进程访问内存的动态特征矛盾被他置换出去的不一定是近期不会访问的。 LRU：最近最少使用页面算法最近经常访问的页面可能在以后也会经常访问，最近不经常访问的页面可能以后也不会访问。于是选择最长时间没有被访问过的页面替换出去。 这是最优置换算法的一种近似 虽然可以实现，但是代价很高——需要一个全面的链表，最少使用的在前，最多使用的在后。——需要一个栈，访问页面的时候将这个页号压入栈，并把栈内相同的页号抽出，缺页时拿栈底 使用一个n*n矩阵表示所有页框的信息，当k被访问的时候，把k行设置为1，k列设置为0，一段时间后，每一行的二进制值最小的就是最近最少使用的。 Simple Implementation：页表项上的计数器硬件实现：为nn矩阵，使用了特殊的寄存器*软件实现：NFU 最不常用算法：LFU/NFU是对LRU的软件实现。 将每个页面与一个计数器关联，取计数值最小的页面替换 LFU的缺点是他从来不会忘记。以前频繁使用的页面很大可能不会被调出去。：通过计数器定时右移来改正-&gt;老化算法LRU关注的是多久未访问而LFU关注的是访问次数，是不一样的。 时钟算法环状结构，当一个缺页中断到来的时候，首先检查指针所在位置页面的访问位，如果是0就淘汰这个页面，否则置为0，转圈，转到的，如果是0就淘汰，如果是1就变成0，知道找到第一个0。 是LRU与FIFO的折中。 改进的时钟算法在页面添加修改位，并在访问时进行相应修改：新改的：RW。每次扫过都将：如果R是1，把R置为0；如果R是0，如果W是1，写这页，写完之后W=0，接着找，如果R=0W=0，就是这个了。 缺页时修改页面标志位，以跳过有修改的页面。 上述的都是局部页面置换算法。局部页面置换算法选择范围仅仅限于当前进程占用的空间，不考虑进程访存差异。全局页面置换算法可以逼出其他进程的物理页面：工作集算法、缺页率算法需要动态确定好给每一个进程的物理页面数。 CPU利用率达到极致以后，再增加并发进程数iu会出现内存抖动。进程数少时，提高并发进程数，可提高CPU利用率并发进程导致内存访问增加并发进程的内存访问会降低了访存的局部性特征局部性特征的下降会导致缺页率上升和CPU利用率下降 工作集缺页率置换算法缺页次数 / 内存访问次数 或 缺页平均时间间隔的倒数 影响缺页率： 页面置换算法 分配给进程的物理页数目 页面大小 程序的编写方法 可以通过调整常驻集的大小，使每一个进程的缺页率保持在一个合适的值。若进程缺页率过高，则增加常驻集以分配更多的物理页面若进程缺页率过低，则减少常驻集以减少它的物理页面数 为每一个页面计数，达到-m的时候，回收，你要页面就给页面。 普通访问不做任何事情，缺页的时候，算一下多久没有缺页了，如果数值比较大，看一看是不是有的页面已经没用了，在这期间没有访问的页面被释放。如果小一些，看看是不是需要补一些页面。 页替换过程 段机制段：一个程序的逻辑分区页机制缺点：复杂，消耗资源 地址映射：段中的addr +段中的偏移内存分配：全局段表+本地段表调度：需要时加载段段+分页：用段技术组织节目内容，用分页技术组织物理内存 段地址空间进程的段地址空间由多个段组成 ：主代码段 子模块代码段 公用库代码段 堆栈段 堆数据(heap) 初始化数据段 符号表等 段式存储管理的目的：更细粒度和灵活的分离与共享一般用于权限控制 段一般是一种段是连续的。有起始地址以及段内偏移量。 段：表示访问方式和存储数据等属性相同的一段地址空间 段页结合 内存共享：通过指向相同的页表基址，实现进程之间的段共享。 link of segments]]></content>
      <categories>
        <category>OS</category>
        <category>课</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JUnit之一]]></title>
    <url>%2F2017%2F11%2F05%2F%E5%BE%80%E4%BA%8B%E4%B8%8D%E5%A0%AA%E5%9B%9E%E9%A6%96%E7%83%9F%E9%9B%A8%E4%B8%AD%2FJUnit%E4%B9%8B%E4%B8%80%2F</url>
    <content type="text"><![CDATA[这是一个简单的JUnit入门介绍。 junit是一个测试框架，把一个java工程按照JUnit运行的时候会启动这些检测，但是这并不影响这个项目作为一个JAVA程序的本质。这个程序仍然可以以Java Application来运行。 在eclipse中使用Junit4进行单元测试安装eclipse的时候，应该已经有了junit的jar包，如果没有，可以自己去maven仓库搜索下载。 在eclipse中使用Junit4进行单元测试 为了方便，我会把上述的方法自己实践并写在下面： 不要直接finish。点击next，你将可以选择对哪些方法进行测试，eclipse就会自动帮你命名（which is very essential） 看！]]></content>
      <categories>
        <category>计算机网络</category>
        <category>实验室</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>模拟器</tag>
        <tag>实验室</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络番外三]]></title>
    <url>%2F2017%2F11%2F04%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%95%AA%E5%A4%963%2F</url>
    <content type="text"><![CDATA[第二次书面作业 在目前的报文交换网络中（如Internet），主要采用存贮转发式交换。源主机通常将应用层较长的消息（例如，图像、视频等）分成小的报文段在网络中进行传输，接收端再将报文段组合成原始的消息，提交给应用层。下面我们给出了消息直接传输（不分报文段）和分成报文段传输的示意图，假设消息长度为8×106 bits，每条链路的传输速率为2Mbps，忽略传播延时、排队延时和处理时间。请回答下列问题： 1) 如图a所示，如果消息不进行分段直接进行传输，每台交换设备均采取存储转发式交换，请计算消息从源主机发出到目的主机完全接收所需的时间； 答：$t=3*8Mb/2Mbps=12s$ 2) 如图b所示，如果消息被分成800个报文段进行传输（忽略各层的封装），每个报文段长10000 bits，请计算消息从源主机发出到目的主机完全接收所需的时间； 答：$t=3*10000/2M+799*10000/2M=802*0.01M/2M=4.01s$ 3) 比较消息交换和报文交换的优缺点，除了传输延时方面的考虑，采用报文交换还有哪些其他方面的考虑？ 答：消息交换省去了对分片数据进行处理合并的时间、减少了首部的数据传输，但是时延长，可能会长时间占用路由器的大量缓存空间。报文交换大大减少了时延，同时由于数据的减少检错也变得更加容易，错误发生率减小，可靠性提升，但是需要额外传送首部数据，并且需要注意报文的顺序合并，还会带来排队时延。采用报文交换除了对时延方面的考虑，还有对发送优先级以及数据可靠性的考虑。另外，过长的消息堵塞路由器可能导致其他消息不能及时送往目的地而带来一系列问题。 发送者A和接收者B之间使用TCP协议进行通信（A发送数据，B回送ACK）。假设TCP连接建立之后A立即开始发送数据（第一个数据段随三次握手中的最后一个ACK一同发送，初始序列号为1）。链路带宽（传输速率）为100 Mbps，往返延迟RTT为10ms，MSS为1000字节，最初的拥塞窗口设成1个MSS，假设接收端有足够大的缓存空间，拥塞控制的初始阈值设为64。试回答下列问题：1) 假设A缓冲区中有7000字节数据要向B发送，发送的每个数据段均包含1000字节数据，请画出A、B之间的交互过程，并计算所需的时间（从发起连接开始计算，要求给出计算过程）。 从图中可以看出：一共经过了4次RTT以及3段将数据报送出的时间，加上TCP/IP首部字节数认为是40，因此：时间：$t=4*RTT+3*((40+1000)*8/100M)=40+0.2496ms=40.2496ms$ 2) 快速重传机制是对TCP性能的优化，考虑第一问中的传输情况，如果传输过程中有数据段丢失，那么第几个数据段的丢失有可能触发A的快速重传？解释原因。 答：承载数据的第四（seq=3002）个：如果第一个数据包发生丢失，B不会发送ACK，将会因此超时引发慢启动；如果第二个丢失，只会发送一个冗余ACK，然后超时进入慢启动。如果第三个丢失，接下来可以连续发送2个报文段，由于第三个包无法被确认，只能回收两个冗余ACK。如果第四个丢失，5、6、7都正确到达，将会引起3个冗余ACK，会引发快速重传。五、六、七丢失都不能引发快速重传了。 3) 假设发送端发送一系列数据段（1、2、3……n），但A一直未收到任何确认（ACK），正常情况下，第一个数据段的重传定时器会首先超时，A将TCP的拥塞窗口设置成1个MSS，并重传第一个数据段。如果我们现在修改TCP协议，在上述情况下不重传第一个数据段，而改为发送第n+1个数据段，请你分析在什么情况下这种做法有利，在什么情况下不利。 答：如果接收方其实全部收到了包，只是发送方的定时器时间设置太短或是突然拥挤的网络导致包传输减缓，这时发送第n+1个数据段是有利的。因为这时前面数据段的ACK会相继到达，n+1包是最终一定会发送出去的包，因此所有工作都不是无用功；如果重传1包，那么在1包原本的ACK到达之后，这个被重传的包就是冗余包，将会被丢弃还会浪费资源。在其他情况下，比如有部分包甚至全部包没有收到，这种机制似乎并不能有效地解决问题：比如有一个包x（0&lt;=x&lt;=n）未收到，这时无论重传多少次n+1包，最终可能收到的都是ACK=x，陷入无尽的循环。 第三次书面作业]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>网络课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络应用层之番外二]]></title>
    <url>%2F2017%2F11%2F04%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%BA%94%E7%94%A8%E5%B1%82%E7%95%AA%E5%A4%96%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[前言其实这里该是运输层番外….但是这是应用层作业啦。 多用户并发访问与可靠文件传输，不能有下载大小的限制。 为了用UDP实现多用户并发访问，一定是需要使用多个socket。仿照FTP的协议设计：使用一个UDP的socket在master进行监听，这个socket绑定一个确定的端口号，用户客户机连接服务器发请求使用。 考虑的请求比较小，可以使用一个包传送完成： Server在端口号X进行监听。 将有一个N。一个client要求连接，发送请求之后立即fork一个子进程，仍然使用这个socket，立即进入准备接收的状态。Server收到了，立即fork一个子线程，master继续监听，确保其他client的请求能被接收到。子线程新建一个UDP的socket，准备进行接收。由于UDP的不可靠，希望在传输数据的时候，Server应该首先，在fork出子线程之后立即对命令请求进行分析，告诉client一共要穿多少个包。（因为在n结束之后，client的子线程就会结束。如果不采用n结束子线程就结束，肯定需要有一个例如，里最后一个包recv之后多久end。这样应该是不太可靠的…对于server，需要有超时重传。emmmm 其实这样也行： client子线程立即等待server传回的数据。同时启动一个定时器，如果超过了一定时间，反正也是同一个socket，就再重传，然后去等。 server呢，在子线程fork出之后就去分析命令，然后开始传包。每一个包有一个序列号。采用选择重传的机制进行文件信息的传输。当发送端的所有发出的包已经发送完毕并且所有的一发送包都得到回执确认之后，向接收端发送最终的发送完毕包。这个包在发送完之后，client接受到之后必须给ACK。server收到ACK之后才能关闭。 有状况：如果client没接到信息或者信息错了，按照选择重传，不会有动作，server重传没毛病；如果client给的ACK丢了，server不能确定client已经收到，也会重传，所以client不可能在发送完ACK就关闭，而是影该等待server的回执，让server知道我已经知道我拿到完整的包了。一旦等到，立即关闭。所以client这边对于最后一个包的动作是：recv-&gt;收到错报，不动，等重传/收到对的包，回复ACK同时启动一个超时重传机制，开始接收server的回执，不管接受到了什么，关闭。（因为这个时候server只要收到了client的东西就证明client肯定已经知道包已经传完了）因为server最终只发送一次，如果client连着很多次超时重传都没有收到回应，很大可能已经server关闭了，为了不陷入无休止的重传，client关闭。 server的动作是-&gt;发送最后一个结束包-&gt;超时重传/接收到client的信息-&gt;发送一个ACK，关闭。 server也知道client这时server也已经关闭 最终交付 计算机网络书面作业：网络协议设计 yayi2456 &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;本协议仿照了FTP协议以允许多客户机的并行操作，使用选择重传的方法在UDP的基础上进行一定程度的可靠性的保证与效率的保证，加入其他机制保证大文件的可靠传输。 &nbsp;&nbsp;&nbsp;&nbsp;server端的主socket绑定一个端口号，进行对客户请求的监听。一旦监听到客户机的请求，立即fork一个子线程，在子线程中重新绑定一个socket，由这个socket与客户机进行通信。 &nbsp;&nbsp;&nbsp;&nbsp;client端根据程序并行度可选择是否需要在子线程发出请求，这取决于不同的应用程序的动作，不做讨论。提到client的动作时，并不指定是在哪个进程。 &nbsp;&nbsp;&nbsp;&nbsp;将该协议描述如下： &nbsp;&nbsp;&nbsp;&nbsp;server监听端口A，一旦监听到client的请求，立即fork子线程。在子线程中对该请求进行分析，并决定需要发送给client的数据。 &nbsp;&nbsp;&nbsp;&nbsp;client向server发送请求，并启动一个定时器，当超过一定时间仍未收到server传回的第一个包，client重新发送请求信息。使recvbase为0，收到第一个数据包之后，recv=(recv+1)%(2*N)，该定时器关闭。 &nbsp;&nbsp;&nbsp;&nbsp;注：在server收到请求之后，并没有立即发送ACK通知client自己已经收到了请求。原因在于server最终一定会发送数据给client，只需要把第一个数据包作为server收到的确认信息即可，同时也减少了可靠性保证所花费的额外的时间。但是由于server对准备发送的数据需要做一定的处理，这个时延可能会稍长。 &nbsp;&nbsp;&nbsp;&nbsp;server开始向client发送包。采用选择重传机制，server为每一个包附上一个序号，同时利用UDP头本身具有的checksum字段进行一定程度的检错判断。server每次最多传送N个报文段，协议中具有2*N个序号。初始时，发送缓冲区中的sendbase是0，server每传送一个报文段就会启动一个对应于该报文段的定时器，当某个报文段的定时器超时之后，server对该报文段进行重传；当server收到了某个序号的报文段的ACK之后，将该序号置为“已确认”，如果该序号是sendbase，那么将sendbase=(sendbase+1)%(2*N)，如果sendbase是“已确认”，再将sendbase=(sendbase+1)%(2*N)，直到sendbase是“已发送但未确认”或是“可用”。同时，当sendbase改变时，如果包尚未发送完，则可以使用新的“可用”来发送新的报文段。 &nbsp;&nbsp;&nbsp;&nbsp;client接受到第一个数据包之后关闭第一个定时器，并向服务器发送对第一个数据包对应的序号的ACK，随后开始接收其他数据包，每接收到一个检验和没有错的数据包，返回一个对应该数据包序号的ACK包。无论是不是server端没有接收到上一个对应该序号的ACK，返回一个ACK，对于最大为2*N的空间来说，是没有问题的。对于在[recvbase,recvbase+N-1]空间中的序号对应的包加以解析送给应用层使用或者是缓存之后将对应的序号标为“接收已确认”，而另外的序号对应的数据包只返回ACK，对数据包直接丢弃。每次接收到一个被“接收已确认”的数据包，如果该数据包的序号是recvbase，recv=(recv+1)%(2*N)，如果这时recvbase对应序号仍是“接收已确认”，recv=(recv+1)%(2*N)，直到recvbase对应序号是“期待但未收到”或是“可用”。 &nbsp;&nbsp;&nbsp;&nbsp;在所有的有用数据包传送完成之后，server需要告知client，有用的数据已经传送完了。 &nbsp;&nbsp;&nbsp;&nbsp;场景分析如下： &nbsp;&nbsp;&nbsp;&nbsp;当server的所有发出的包已经发送完毕并且所有的已发送包都得到回执ACK之后，向client发送最终的发送完毕包。这个包在发送完之后，client接收到之后必须给ACK。server收到ACK之后才能关闭，否则可能导致client不知道自己已经拿到完整的数据而陷入空转。 &nbsp;&nbsp;&nbsp;&nbsp;如果client没接到最终包信息或者信息错了，按照选择重传，client不会有动作，server等待超时之后重传；如果client回复的ACK丢了，server不能确定client已经收到，必须重传来确认client已经知道自己可以关闭连接了，所以client不可能在发送完ACK就关闭，而是该等待server的回执，让server知道client已经知道client拿到完整的包了，否则可能会使server陷入无尽的重传。一旦等到server的回执，client立即关闭。若许久都未等到回执，关闭。 &nbsp;&nbsp;&nbsp;&nbsp;下面对最后的动作进行描述： &nbsp;&nbsp;&nbsp;&nbsp;server的动作是：发送最后一个结束包，启动定时器，若超时则进行重传；直到接收到client的信息之后，关闭定时器，server发送一个ACK，立即关闭。 &nbsp;&nbsp;&nbsp;&nbsp;client最终的动作是：等待接收数据，如果收到错误的包，等重传；如果收到对的包，回复ACK同时启动一个定时器，启动超时重传机制，并开始接收server的回执，不管接受到了什么，关闭。若超时一定次数之后仍未接收到server的回执，因为server最终只发送一次，如果client连着很多次超时重传都没有收到回应，很大可能已经server关闭了，为了不陷入无休止的重传，client关闭。 从宏观的角度来看，客户机与服务器的交互是： 扩展FSM： server： client：]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>网络课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[窗口文档试图（3]]></title>
    <url>%2F2017%2F11%2F04%2FMFC%E5%9F%BA%E7%A1%80%2FMFC%EF%BC%9A%E7%AA%97%E5%8F%A3%E6%96%87%E6%A1%A3%E8%A7%86%E5%9B%BE%EF%BC%883%2F</url>
    <content type="text"><![CDATA[麻蛋！这已经是第三次了！你妹的第三章！！！！！还好CSDN还有视图！只是又要自己动手麻了！！！ 一、边框窗口窗口类CWnd提供了MFC中所有窗口类的基本功能。CWnd类和消息映射机制隐藏了窗口的回调函数WndProc。 对WndProc：WndProc有四个参数，第一个是产生消息的窗口句柄，第二个是消息，第三第四分别是参数与长参数。当窗口产生一个消息时，消息被送到WndProc函数中，由这个函数判断产生消息的窗口与消息类型，然后将它送到对应的消息处理函数处理消息。WndProc在MFC中被封装。允许用户对其重写。 创建Windows窗口要分为两步进行： 引入构造函数，构造CWnd对象； 调用Create函数建立Windows窗口并将它连接到创建的CWnd对象上。 以CWnd作为基类，派生出了更具体的窗口类型： CFrameWnd：SDI程序主框架窗口的基类 CMDIFrameWnd：MDI程序主框架窗口的基类 CMDIChildWnd：MDI程序文档框架窗口的基类 CDialog：对话框 对话框CDialog作为对话框类的基类，又派生出更多的类： CFileDialog：提供打开或保存一个文件的标准对话框 CColorDialog：提供选择一种颜色的标准对话框 CFontDialog：提供选择一种字体的标准对话框 CPrintDialog：提供打印一个文件的标准对话框 CFindReplaceDialog：提供一次查找并替换操作的标准对话框 除了这些子类，用户可以自己从CDialog派生类。 对SDI产生的窗口，分成主边框窗口和视图窗口；MDI产生的窗口，分为主边框窗口、子边框窗口和视图窗口。 下面以一个小程序来加深了解： 主边框上创建一个button，看看它会在哪里： 12//在CMainFrame.h中CButton m_button; 12//在CMainFrame::OnCreate()中m_button.Create(&quot;new button&quot;,WS_VISIBLE|BS_DEFPUSHBUTTON,CRect(0,0,100,50),this,0); 运行之后产生的界面： 由于MainFrame已经是最外面的边框了，如果在Create函数中将参数this换做GetParent()，程序运行产生错误如图： 在视图中创建一个button:只需将上述所提的MainFrame改为×View即可。所得结果： 说明一： OnCreate函数的参数：LPCREATESTRUCT是一个指向结构体CREATESTRUCT的指针，其定义如下：1234567891011121314typedef struct tagCREATESTRUCT &#123;// cs LPVOID lpCreateParams; HINSTANCE hInstance;//应用程序的实例句柄 HMENU hMenu;//窗口菜单句柄 HWND hwndParent;//父窗口句柄 int cy; //指定新窗口的高度，以像素为单位 int cx;//指定新窗口的宽度，以像素为单位 int y;//指定新窗口的左上角y坐标 int x;//指定新窗口的左上角x坐标 LONG style;//指定新窗口的类型(方式) LPCTSTR lpszName;//指定新窗口的名称 LPCTSTR lpszClass;//指定新窗口类的名称 DWORD dwExStyle;//指定新窗口扩展风格。 &#125; CREATESTRUCT; 说明二： 边框窗口的样式可以定制 WS_SYSMENU WS_MAXIMIZEBOX：最大化按钮不可用 WS_MINIMIZEBOX：最小化按钮不可用 123456//在CMainFrame::PreCraeteWindow()中cs.cx=600;cs.cy=460;cs.x=0;cs.y=100;cs.style=~WS_MAXIMIZEBOX; 将这段代码运行，得到的结果：（为什么我的窗口没有被更改呢？ 二、文档与视图文档与视图是MFC最常用的类。文档类负责数据管理（存储、修改、读取等），视图类负责与用户进行交互，将文档数据在视图上显示出来。 文档类的基类是CDocument，视图类的基类是CView。他们各自派生出了一些类。CDocument是CCmdTarget的派生类，而CView是CWnd的派生类。 串行化Serialize：文档对象管理来自数据源的数据，例如磁盘、串口、网卡等。 串行化是指从对象写入字节流或者从字节流读到对象。 operator&lt;&lt;:写字节流 AND operator&gt;&gt;:读字节流 IsStoring:写状态 AND IsLoading:读状态 WriteString:写字符串 AND ReadString:读字符串 12345//可以在×Doc::Serialize()中写内容来实现串行化输入输出:if(ar.IsStoring()) a&lt;&lt;m_str;else ar&gt;&gt;m_str; 当写了Serialize函数以后，便可以通过保存按钮将m_str保存到文件中，也可以再通过打开文件将文件中保存的数据还原到m_str变量之中，供程序使用。 注意：当选择打开文件时，并不是将文件内容显示在视图上，而是执行读操作，将文件内容存到变量里面。如果想要将东西显示，需要自己编辑代码。 文档与视图之间建立联系： CView通过GetDocument()可以获得CDocument对象的指针，通过这个指针可以访问CDocument的数据； CDocument通过函数UpdateAllViews()以消息形式通知视图数据变化，需要重新显示；CDocument可以获得CView对象指针，直接访问视图类成员变量或调用类视图类成员函数。 当文档被修改，调用UpdateAllViews函数，其声明：1void UpdateAllViews(CView*pSender,LPARAM lHint=0L,CObject*pHint=NULL); 参数说明： pSender：指向修改文档的视图，如果所有视图都被更新，设置为NULL，即，被这个参数指定的视图不会再次被通知更新。 lHint：包含文档被修改的信息; pHint：指向一个储存修改信息的对象 当调用UpdateAllViews时，与此程序相关的除了pSender以外的所有视图的UpdateView函数被调用。即：UpdateAllViews只起到通知作用，具体的绘画操作则由OnUpdate来决定。 另外，UpdateAllViews并不会进入消息队列，而是直接立即重画。 Question:为什么我打开文件时有时候会重画有时候不会重画？？？ 三、主框架菜单操作菜单操作有几个常用的函数，现列如下：1234567GetMenu();//获得菜单GetSubMenu(int pos);//获得子菜单CheckMenuItem(UINT nIDCheckItem, UINT nCheck);//标记菜单SetDefaultItem(UINT uItem, BOOL fByPos= 0);//设置默认菜单nableMenuItem((UINT nIDEnableItem, UINT nEnable);//有效、无效化菜单SetMenuItemBitmaps(UINT nPosition,UINT nFlags,const CBitmap* pBmpUnchecked,const CBitmap* pBmpChecked);//设置位图菜单SetMenu();//设置菜单 1.设置标记菜单123//在CMainFrame::OnCreate()中GetMenu()-&gt;GetSubMenu(0)-&gt;CheckMenuItem(0,MF_BYPOSITION|MF_CHECKED);GetMenu()-&gt;GetSubMenu(0)-&gt;CheckMenuItem(ID_FILE_NEW,MF_BYCOMMAND|MF_CHECKED); GetMenu()返回一个CMenu指针指向主菜单，类似于数组名与数组的关系。 GetSubMenu(int pos)被上述返回的主菜单指针调用。pos从0开始。返回一个子菜单项的指针。 CheckMenuItem(UINT nIDCheckItem, UINT nCheck)。第一个参数指定位置第二个参数确定指定位置的方式以及标记方式。有两种指定位置的方式，使用pos（从0开始）并且使用MF_BYPOSITION或者使用item的ID指定并且使用MF_BYCOMMAND。 需要注意的是：分隔符占据一个位置，即： “编辑”是主菜单项的第1个子菜单项，“撤销”是“编辑”的第0个item，“剪切”是第2个item。 如果CheckMenuItem选中的位置是分隔符或者位置大于item最大编号，不会发生变化。 最后的运行结果如下 2.设置默认菜单123//在CMainFrame::OnCreate()中GetMenu()-&gt;GetSubMenu(0)-&gt;SetDefaultItem(1,true);GetMenu()-&gt;GetSubMenu(0)-&gt;SetDefaultItem (ID_FILE_OPEN); SetDefaultItem(UINT uItem, BOOL fByPos=0)。同样可以使用pos与ID两种方法。如果使用ID，只需一个实参，如果使用pos，由于默认值是0，所以必须在后面添加实参true，否则item不会产生变化。 运行结果： 3.设置位图菜单12//在MainFrame.h中CBitmap m_bitmap; 12345678910111213//在CMainFrame::OnCreate()中m_bitmap.LoadBitmapW(IDB_MYBITMAP);GetMenu()-&gt;GetSubMenu(0)-&gt;SetMenuItemBitmaps(3,MF_BYPOSITION,m_bitmap,m_bitmap);CString str; str.Format(L”Menu Height=%d”,GetSystemMetrics (SM_CYMENUCHECK)); MessageBox(str);CDC* pDC=GetDC(); CString str;GetParent()-&gt;GetWindowText(str);pDC-&gt;TextOutW(0,0,str);ReleaseDC(pDC); LoadBitmapW(UINT nIDResource)加载位图，将自定义的一个位图与m_bitmap联系起来。 SetMenuItemBItamps(UINT nPosition, UINT nFlags,const CBitmap pBmpUnchecked, const CBitmap pBmpChecked)。同样的，可以使用ID与pos确定位置的两种方法。第三个参数是该item未被选中时所显示的位图的指针，第四个参数是这个item被选中时显示的位图的指针。该例未作区分。 注意：m_bitmap一定要定义在MainFrame.h中，否则由于函数执行完之后释放资源，m_bitmap就会被释放掉，导致无法正常显示位图。如果一定要在OnCreate中定义，可以尝试使用指针。如下：123CBitmap*m_bitmap=new CBitmap();m_bitmap-&gt;LoadBitmapW(IDB_MYBITMAP);GetMenu()-&gt;GetSubMenu(0)-&gt;SetMenuItemBitmaps(3,MF_BYPOSITION, m_bitmap,m_bitmap); 结果： 4.禁用、可用菜单项12//在CMainFrame的构造函数里m_bAutoMenuEnable=false; m_bAutoMenuEnable是定义在CFrameWnd中的一个BOOL值，他决定了item是否会自动变为可用。其默认值为true。只有当它的值是false时，我们对其DISABLED生效。 123//在CMainFrame::OnCraete()中GetMenu()-&gt;GetSubMenu(0)-&gt;EnableMenuItem (2,MF_BYPOSITION|MF_DISABLED|MF_GRAYED);GetMenu()-&gt;GetSubMenu(0)-&gt;EnableMenuItem (ID_FILE_SAVE_AS,MF_BYCOMMAND|MF_ENABLED); EnableMenuItem(UINT nIDEnableItem, UINT nEnable)。同样的，两种确定位置的方法。 MF_GRAYED是使item变灰并且不可用，MF_DISABLED使item不可用。MF_ENABLED是使item可用。 四、浮动菜单用户点击鼠标右键时，弹出浮动菜单，又称弹出菜单、快捷菜单等。点击右键时，窗口发出菜单消息WM_CONTEXTMENU，其对应处理函数是OnContextMenu(CWnd* pWnd, CPoint point)，其中的point是屏幕坐标，并非窗口坐标。 隐式菜单创建 在资源视图中创建菜单IDR_POPMENU 创建二级菜单Line，其ID是ID_POPUP_LINE 创建二级菜单Circle，其ID是ID_POPUP_CIRCLE 12345//在C×View::OnContextMenu()中CMenu menu;menu.LoadMenu(IDR_POPMENU);CMenu*pMenu=menu.GetSubMenu(0);pMenu-&gt;TrackPopupMenu(TPM_LEFTALIGN,point .x,point.y,this); 首先提一个问题：为什么这里可以不用指针啊？？？？ 即使POPMENU只有一个子菜单项，也必须做GetSubMenu，道理就如只有一个元素的数组名a与a[0]一样不同。 TrackPopupMenu(UINT nFlags, int x, int y,CWnd* pWnd, LPCRECT lpRect = 0)。第一个参数决定对齐方式，TPM_LEFTALIGN代表菜单跳在鼠标右边，TPM_RIGHTALIGN代表菜单跳出在鼠标左边。此外还有其他方式，不再叙述。x与y决定了跳出位置，这个位置是屏幕位置。最后一个参数决定？？？？？ 这种创建方式很像位图菜单的添加方式。先Load，然后Set/Track。 接下来，便可以像对普通的菜单消息那样处理浮动菜单消息了。 非隐式浮动菜单创建（鼠标右键消息）12345678//在C×View::OnRbuttonDown()中。CMenu menu;menu.CreatePopupMenu();menu.AppendMenu(MF_ENABLED,ID_LINE,L&quot;Line&quot;);menu.AppendMenu(MF_ENABLED,ID_CIRCLE,L&quot;Circle&quot;);Cpoint pt;GetCursorPos(&amp;pt);//获得当前鼠标所在的屏幕坐标menu.TrackPopupMenu(TPM_LEFTALIGN,pt.x,pt.y,this); 与隐式浮动菜单创建所用方式比较，这种方式将LoadMenu的工作自己完成了一遍：CreatePopupMenu、AppendMenu。 但是实际上，这并不是隐式与非隐式的区别，只是两种不同的方法而已。将这种方法写在OnContextMenu()中也可以，把OnContextMenu()中的方法用到这里也没问题。 此外，由于这个处理函数得到的Cpoint是窗口的坐标，而TrackpopupMenu需要窗口坐标。故不可以直接用参数。而是获得当前鼠标光标在窗口上的位置。 运行结果： 五、派生视图类在CWnd下派生出的CView类作为视图类的基类，有派生出其他视图类。 CCtrlView：可编辑、列表框、树状控件 CScrollView：视图滚动、缩放显示 以这两者为例。 编辑视图：使用编辑视图需要在创建新项目时将C×View的基类设置为CEditView： 这样直接生成的project即可以将视图作为文本界面进行输出，而且这样生成的project直接具有保存打开功能，即这时的Serialize函数已经做了一些必要的实现。 以下是一个小例子： 添加菜单项ID_TEST。 对在IDR_MAINFRAME中新添加的菜单项，默认弹出项是true，这时不可以编辑ID。如果想以之为功能菜单，需要在“属性”-&gt;“外观”-&gt;”popup“一项设置为false。 123456//在C×View::OnTest()中CDC*pDC=GetDC();CString str;GetParent()-&gt;GetWindowText(str);//获得窗口的标题pDC-&gt;TextOutW(0,0,str);ReleaseDC(pDC); 这段代码完成获得窗口标题并将标题画在视图区。但是这种方法画出的标题很脆弱，只要一个字符的输入，就会使它们消失（重画了视图）。 还可以设置窗口标题，下面一段代码完成了取得窗口标题并将它逆序重新设置的工作。1234567891011121314//在C×View::OnText()中CString str1,str2;GetParent()-&gt;GetWindowText(str1);str2.Empty();for(int i=str1.GetLength()-1;i&gt;=0;i--)&#123; if(str1.GetAt(i)==&apos;\0&apos;)&#123; str2+=&apos;\0&apos;; i--; &#125; else str2-=str1.GetAt(i);&#125;GetParent()-&gt;SetWindowText(str2);//设置窗口标题 str.GetLength()函数返回字符串的长度（不带’\0’） str.GetAt(i)函数返回str第i位的字符值（从0开始） SetWindowText(str)函数可以设置调用对象的标题值。 滚动显示滚动显示允许浏览比视图窗口更大的文档，需要从CScollView类派生。 在创建滚动视图时，需要重载CView成员函数OnInitialUpdate()，调用SetScrollSizes()计算视图大小 OnInitialUpdate()是虚函数，用户选择File-&gt;New或Open后调用，初始化试图对象，调用OnUpdate函数。 123456//在C×View::OnInitialUpdate()中CSize sizeTotal;sizeTotal.cx=sizeTotal.cy=300;//修改这个常数值可以确定屏幕何时产生滚动条SetScrollSizes(MM_TEXT,sizeTotal);//没有这句话程序将会出现运行错误。 缩放显示同样需要从CScrollView派生。不同的是视图会自动适应边框的大小，当改变窗口的大小时绘图自动适应视图区的大小，不会产生滚动条。 1234//在OnInitalUpdate中CSize sizeTotal;sizeTotal.cx = sizeTotal.cy = 300;//决定缩放比例SetScaleToFitSize(sizeTotal);// 缩放公式： 显示x=实际x*ViewWidth/sizeTotal.cx（横向） 显示y=实际y*ViewLength/sizeTotal.cy（纵向） 分割窗口同样的，视图类需要从CScrollView派生。分割窗口是指把一个窗口分为多个独立视图，这种分割可以分为两类：动态分割和静态分割。动态分割产生的视图使用同一个视图类，使用的是CSplitterWnd::Create()，静态分割产生的视图使用的是不同的视图类，使用CSplitterWnd::CreateStatic()。12//在MainFrm.h中CSplitterWnd m_splitter; 12//在CMainFrame::OnCreateClient()中return m_splitter.Create(this,2,2,CSize(20,20),pContext); pContext是OnCreateClient中带的参数。2,2分别是横向分两部分与纵向分两部分。this是要分割的窗口的父框架窗口，pContext是切分窗口的ID。 动态创建的分割窗口的窗格数目不能超过2x2。 六、多文档窗口实例]]></content>
      <tags>
        <tag>MFC</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[覆千秋1]]></title>
    <url>%2F2017%2F11%2F03%2F%E6%9C%88%E5%8D%8E%2F%E8%A6%86%E5%8D%83%E7%A7%8B1%2F</url>
    <content type="text"><![CDATA[夜色凉将军府的海棠开了。 粉粉嫩嫩，一簇一簇的，细风吹来，花朵轻轻落在地上，把这个小园衬出几分诗意。 只是府上光景却不如这海棠繁盛。 前日里前线传回来消息，说是这宅院的主人被俘了。被俘了，是不要紧，要紧的是他帮着敌军截断了己方粮草，杀了一名副将。 皇帝知道之后龙颜大怒，直接下令封了将军府。管你是真降还是假意。 大臣们都以为，功高盖主，老将军即使不降，回来也风光不了几日了，没差。 平民慷慨激昂，市面上的书里，茶馆里，甚至风月里都是对老将军叛国的不耻，这些模糊的面孔在舌灿莲花的时候，选择性的忘记了老将军当年战绩的辉煌。 当街月色应如水“千霜——”，打扮精致的女人独自从廊中走来，在几步之外站定，唤。 坐在小亭中的女孩循着声音忽地回头，抬着脸叫：“娘——”。]]></content>
      <categories>
        <category>我的故事</category>
        <category>枯骨流沙</category>
        <category>覆千秋</category>
      </categories>
      <tags>
        <tag>千霜</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络网络层]]></title>
    <url>%2F2017%2F11%2F02%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E7%BD%91%E7%BB%9C%E5%B1%82%2F</url>
    <content type="text"><![CDATA[#]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>网络课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络运输层]]></title>
    <url>%2F2017%2F11%2F02%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E8%BF%90%E8%BE%93%E5%B1%82%2F</url>
    <content type="text"><![CDATA[这些东西是很简单，可是想来想去还是决定记录一下，以免以后遇到像C++语法不知道一样的尴尬。 概述与运输层服务运输层的协议提供的是逻辑通信，并不是直接相连的。 现在我们聊的是对等层通信，本机的运输层发数据给其他机器的运输层。运输层协议在端系统里面，并不是在路由器里。 实际上，当应用程序希望能与其他设备进行通信，调用运输层，给运输层一堆信息。运输层可能会把这些信息分段，然后加上头部信息成为报文段。报文段交给网络层，网络层再封装成数据报再向目的地发送。到了目的地之后做一个相反的动作，送给应用层使用。需要区分清楚的是，制定目的地、决定报文段怎么产生、决定报文段如何合并都是运输层的工作，网络层相当于送信的邮差，只负责传输。但是话又说回来了，网络层更加底层，网络层提供了怎样的服务、有多大的带宽都限制了运输层的服务。 现在因特网的运输层主要有两个协议：UDP、TCP。UDP是不可靠的、多目的地的、无序的传输；TCP是面向连接的可靠的传输。具体特性将在后面讲到。 因特网的网络层协议是IP协议（网际协议）。IP非常不可靠，他是尽力而为交付服务，一不确保报文段的交付，二不保证报文段交付的按序，三不保证报文段交付的完整性，被称为不可靠服务。 TCP与UDP的基本职责是将两个端系统之间的IP交付服务扩展为运行在两个端系统之上的两个进程之间的信息交付服务。将主机之间的交付扩展为进程之间的交付就是运输层的多路复用与多路分解。 运输层的多路复用与多路分解多路复用与多路分解服务是所有计算机网络都需要的。 我们知道，实现运输层的服务需要借助于socket，一个进程可以对应一个或几个socket（？）。在send端，运输层在报文段中加了首部信息之后，把各进程产生的数据无差别的交给网络层；在rev端，运输层从网络层那里拿出数据，解析报文段的首部信息从而==定位socket==，把分解后的报文段信息给对应的socket。 为了实现这种服务，在首部信息里面一定封装有端口号。端口号是一个16bit的数，在0-65535之间，其中0-1023的端口号是周知端口号，他们被保留给周知应用层协议来使用。一般来说，服务器端都是一个固定的端口号，而客户端则是随机分配。关于端口号的更多信息，可以访问RFC 3232获得。 1. 无连接的首先了解UDP的套接字标志方法：UDP的socket以一个二元组(dstaddr,dstport)来标识，与源信息无关。也就是说，虽与一个机器无论是从什么地方发送过来的数据，只要给的是同一个port，都将被同一个socket处理。这样，容易理解，在UDP中，每一个port会对应一个自己的缓冲区。 关于这个缓冲区，UDP不可靠也会体现在这里，在发送UDP包的时候不能过大，也是出于对缓冲区大小的考虑。如果新到来的包太大了、不能塞进缓冲区了，这个包会被直接抛弃。app层不会知道，只有通过发送端的超时重传机制对包进行重传。 2. 面向连接的TCP的套接字标志方法与UDP不同，TCO使用(srcaddr,srcport,dstaddr,dstport)，这样，只有四个值都相同才会被定向到同一个socket，放到同一个缓冲区。 这里只是简单一提：关于安全性的问题。攻击者可以利用在某个端口监听的有缺陷的应用程序攻陷目的主机。我不了解安全，这里只是复述了《自顶向下方法》中的解释。 使用nmap既可以扫描到因特网中任一台主机，顺序的扫描主机的各个端口，对TCP/UDP，寻找能接收TCP连接/能对UDP报文段进行处理的端口号，并返回打开的、关闭的、不可达的端口号列表。 3. Web Server与TCP其实没什么新东西，列举： 连接套接字与进程之间并非一一对应的关系。先进的高性能Web server只有一个进程，但是为每一个连接的新客户（不是客户机喔）创建一个新的线程。 非持续HTTP会严重影响web server的性能。（在应用层中涉及），有些OS技巧可以减轻这个问题的影响。（参见[Nielsen 1997,Nahum 2002]） 他的复用与分解是这样的： UDP概述UDP很弱，除了上一节提到的复用分解机制以及少量的差错检验之外，基本没有功能了，如果程序员选择了UDP，那基本上就是在与IP打交道了。 以一个DNS查询为例：应用层给出了一个查询报文交给运输层，UDP加了首部段，交给网络层，网络层将他封装进一个IP数据报，发送给一个名字服务器。DNS如果没有收到对方的回应，要么向另一个服务器发送请求，要么告知调用它的应用程序没有响应。 1. UDP特点 无连接： 两个UDP之间没有握手； UDP报文段彼此独立 不可靠： 没有确认接收； 没有重传； 没有检查包丢失与包失序 检验和只覆盖部分信息 没有拥塞控制 UDP很弱，为什么不使用更加可靠的TCP呢？ 关于何时发送什么样的数据的控制更为精细。UDP是只要应用层交付，UDP就立即给网络层，而TCP有一个拥塞控制机制，可能会遏制发送方，是数据传输变得缓慢。 无需建立连接，减少时延。 无连接状态，不需要维护连接状态。连接状态包括接收和发送数据缓存、拥塞控制参数、序号以及确认号的参数等。某些应用程序运行在UDP之上可以支持更多的活跃用户。 分组首部开销小 UDP的这些特点使得： DNS简单查询； 流媒体应用； P2P应用 网络管理应用：通产工作在高压状态之下； 路由转换协议 等将有更佳的适用度。 现今，由于出于安全考虑，某些机构阻塞UDP流量，而且当丢包率低时，TCP将更多的用于流媒体应用。 然而，由于UDP没有拥塞控制机制，当网络繁忙时，路由器会有大量的分组溢出，几乎没有UDP分组能够成功通过路由器到达目的地。而且，具有拥塞控制机制的TCP发送方会减慢自己的速率。UDP没有拥塞控制机制不仅造成了UDP会话之间的高丢包率，也挤垮了TCP会话。很多研究人员已经提出了新的机制，使所有数据源执行自适应的拥塞控制。 希望使用UDP实现可靠传输的话需要在应用层协议上加上可靠性保证。这种方法既可以保证可靠传输，又可以拒绝拥塞控制的影响。 表1：流行的因特网应用及其下协议 应用 应用层协议 下层运输协议 电子邮件 SMTP TCP 远程终端访问 Talnet TCP Web HTTP TCP 文件传输 FTP TCP 远程文件服务器 NFS 通常UDP 流式多媒体 通常专用 UDP或TCP 因特网电话 通常专用 UDP或TCP 网络管理 SNMP 通常UDP 路由选择协议 RIP 通常UDP 名字转换 DNS 通常UDP 2. UDP报文 长度：指明了包括首部信息在内的UDP报文段长度（单位：字节：Byte）； 下面重点说检验和： 在计组里面就学了几个检错方法，对于一个检错机制：数据=冗余位 实际数据。决定检错能力的是冗余位数与算法。对于UDP，他提供的是一个很简单的检错机制，而且只能检错，不能修改错误。 Persudo Headerpersudo header结构是这样的： 在发送端，首先会将报文段中的checksum清零，然后把报文段与persudo header的数据当作16bit的很多数据，对他们进行求和运算，将得出的16bit结果求反给checksum字段。 在接收端，产生新的伪首部，然后只需要将这些数据全部求和，最终如果是16个1，说明可能是没错的，但是也可能发生的错误已经超出了检错能力，如果不是16个1，那说明一定是错了。 checksum有什么用呢？对于明确错误的信息，UDP会要么丢弃；要么把数据给应用层，但是给应用层警告说数据是错的。 其实伪首部破坏了分层结构，在运输层产生了网络层的信息。 UDP校验和覆盖的范围超出了UDP数据报本身，使用伪首部的目的是检验UDP数据报是否真正到达目的地，正确的目的地包括了特定的主机和该主机上特定的端口 checksum机制在ipv4下是可选的，但是在ipv6下是必须的。 在checksum中看到了端对端原则。端对端原则是一个被受赞扬的原则，该原则表述为某种功能必须基于端对端实现：”与在较高级别提供这些功能的代价相比，在较低级别上设置的功能可能是冗余或几乎没有价值的。“在这里，由于不能保证从网络到物理到链路都有有效的检错机制，甚至在某些路由器的内存中也可能引入比特差错，实现端对端的错误检测机制是有必要的。 可靠数据传输原理在这一节里，将所有的底层数据传输视为不可靠的，可能会发生数据的丢失、差错、失序等。 这里讨论的是普遍的计算机网络使用的理论，将以分组代替报文段被使用。同时，只考虑单向数据传输，其实双向数据传输并不会更难。 构造可靠数据传输协议rdt1.0：信道完全可靠假如信道完全可靠，UDP完全可靠。发送方只要接收到rdt_send就做处理并调用udp_send，接收方只要接收到rdt_rcv就处理。有限状态机（FSM）图如下： 发送端： 接收端： rdt2.0：信道具有比特差错自动重传请求（Automatic Repeat reQuest）：在接收方确认接收到正确的报文之后给出肯定确认，接受到不正确的报文之后给出否定确认。 实际上，这种机制需要其他的支持： 差错检测 接收方反馈：如果正确，返回ACK，不正确返回NAK。 重传：发送方在接收到NAK时重传。 FSM： 发送方： 接收方： 但是，如果ACK或者NCK的包错误了怎么办呢？一般有三种解决方法： 发送请求，询问上一个差错包的内容。这样很容易陷入询问的死循环。 增加足够的检错纠错能力。导致冗余数据过多。 直接重传。可能会引入冗余分组，使得接收方不知道这个包是新包还是重传包。 对于第三种方法，可以引入序列号的概念来解决问题。对于我们现在讨论的停等协议，只需要两个序号即1bit即可。 这个版本是rdt2.1，新的FSM是这样的： 发送方： 接收方： 其实，如果不使用NAK，而是对上次的接收再发送一个ACK，也能起到同样的效果，这样，有了rdt2.2版本： 发送方： 接收方： 比特交替协议——rdt3.0：信道可能丢包、产生比特差错如果产生了丢包，接收端是不会知道的，只能在发送端处理这个问题。一个是发送端主动发送的数据丢失，和接收端没有关系，一个是接收端已经收到了包，但是发送的确认信息丢失。 发送方需要重传，应该做到： 每次发送数据之后启动一个定时器 响应定时器中断 停止定时器 在重传中，延时时间的设置是很重要的。过长的延迟时间将影响应用层的体验，果断的延迟时间将会引入冗余数据分组。rdt2.2已经有能力处理冗余数据分组：当在等待1的时候又传来了0，接收端会直接丢弃这些数据。而对于停等协议，不会有在等1的时候正好发送了1的冗余包的情况。 发送方： 流水线可靠数据传输协议rdt3.0对于错误处理已经比较完善了，但是他的问题在于他是一个停等协议。停等协议对链路的利用率低到令人发指！ 对于一个速度是1Gbps的链路，发送一个大小1000Byte的包： 进入所需时间：$$t=\frac{L}{R}=\frac{8000bit/pkt}{10^9bit/s}=8us/pkt$$ 假设传输所需时间是15ms，那么信道的利用率是： $$U_sender=\frac{\frac{L}{R}}{RTT+\frac{L}{R}}=\frac{0.008}{30.008}=0.00027$$ 为了提高传输效率，停等协议需要被摒弃。现在使用的技术被称为流水线。使用流水线技术，1个bit的序号是不够用的，在后面我们将讲到对于n个同时发出的包，需要2*n个序列号。而且，在发送端和接收端都需要有缓存机制来暂时存储：发送端需要存储已经发送但是没有确认接收的数据，接收端需要存储已经正确接收的数据。 这一节并没有完整的讨论流水线机制下的协议，从下一小节开始，对缓存的处理、序列号的处理进行讨论。 回退N步：GBN允许发送方连续发送N个数据包，接收方按序接收数据包，失序的包会被丢弃。（这时由于没有考虑双向传输，而且接收端的机制，在接收端的结构暂且不提） 在发送方将会有一个缓冲区，把结构抽象成这样： 在这次传输的过程中只能使用[send_base,sendbase+N-1]之间的序号。扩展FSM如图： 发送端： 接收端： 在这个FSM中存在变量，初始化是需要的。在发送端，当上层请求发送数据时，有一个判断：如果还可以继续发送（nextseqnum&lt; base+N），就继续发送，如果在发送这个之前所有的包都已经被确认过了，就需要开一个定时器，从这里可以看出：计时器以最左边界启动。如果不能再发送了，拒绝发送数据。这时可能有三种处理方式：将该数据返回给上层，隐含地表示已经不能再传了；缓存这些数据；使用同步机制只允许上层在窗口不满的时候才能调用rdt_send。数据发送出去之后，如果按时接收到了一个ACK，比如说是ACK(i)，那么说明从base到i都已经被确认了。假如这时已经没有未确认包了，计时器停止，否则，重新为新的最左包启动一个定时器。如果ACK损坏了，什么也不做。因为有定时装置，只需等待重传。这与rdt3.0的机制是相同的。好了，timeout了，将现在所有的未确认全部重传，然后重启定时器。 在接收端，同样初始化。接收端只会等待需要等待的按序的包，如果不是按序的，不予接收，并将上一个确认信息给发送方。类似于rdt2.0的处理方式。发送方收到的这个包并不会对发送方有什么影响，只是由于timer不能被停止或重启，一定时间之后便会触发重传。但是对于那些ACK丢失的包有重大意义：推动sendbase向前。如果接受端收到了一个按序的、在检错能力之内没有错误的包，才对他进行处理，更新自己的期望包序号，并向发送方发出自己的确认信息。 这种方式的弊端在于失序数据的丢弃。 假如发送方一口气发送了N个包，恰巧第一个包坏了，其他都好的，由于接收端拒绝接受第一个坏的包，其他包也被丢弃了，只能重传所有的N个包。或者，其实这N个包都好好的到了接收端，接收端返回了N个确认包。 emmm其实这里做的比较好，因为反回了N就代表N以及以前的都已经收到了。 Go-Back-N动画 选择重传对上一小节最后提出的回退N步的弊端，在选择重传之中得到了解决。但是应该知道，功能的增强需要结构的复杂作为代价。 允许失序，接收方会对一些失序的包进行缓存。这样，确认接收的机制也需要进行修改、接收方也需要拥有一个缓存区来实现。 在这种方式中，其实在上一节最后说的那点优点是不可能存在了，因为需要选择重传，必然是选择确认。而且，每个分组都必须有自己的定时器，而不能像上面一样按最左来做定时器。 在发送端，base只能移动到没有已发送但未确认的最右。对于上图，发送端的绿色必定对应接收端的粉色或者无色，接收端的灰色必定对应发送端的黄色，在sendbase右边不可能有对应接收端灰色的色块。 发送方的动作与前面类似，只是需要将确认机制修改成单独确认，接收方的动作如下： 如果收到了[recvbase,recvbase+N-1]内的包，是正常的，把收到的包的对应序号ACK，如果在这之内的某个包出了问题不用管，丢掉。如果等于recvbase了，就更新recvbase。（这也使得2.是必要的） 收到了[recvbase-N,recvbase-1]之内的包，可能是这之内的包已经被接收端ACK了，但是没有被发送端ACK，一定需要传一个ACK包给发送端，否则会使得sendbase无法前进。 其他情况忽略即可。 情况2.也说明了为什么需要2*N个序号： 尴尬的情况：究竟是重复包还是新包？ 在书中提到了分组重排，我不是十分理解： 分组重拍的一个表现是具有确认号x的旧副本可能会在网络中出现，即使现在发送端与接收端的窗口中可能都包含x。对于分组重排，信道可被基本看成是在缓存分组，并在将来的任意时刻自然地释放这些分组。因为序列号要被重用，所以这种情况要十分小心。实际采用的一个方法是直到发送方确认网络中不会在存在x分组。这通过设置一个分组在网络中的最大存活时间来限定。在高速网络的TCP扩展中，一般是3min。[sunshine 1978]描述了一种使用序号的方法，可以使重新排序问题完全被避免。 Selective Repeat动画 这些都搞清楚了之后，TCP隆重登场~ TCP：Transport Control ProtocolTCP是面向连接的协议，这是因为TCP在传输数据之前需要进行三次“握手”，它传输的是字节流，也就是收TCP并不管传输内容的有意义的分割，只是够了可以出发的字节数（或者不够，这是其他的机制）就会将这个报文段发出，这就要求了接受的数据必须能够按序排列好。 TCP的传输有以下特点： 流量控制 拥塞控制 点对点 全双工服务 流水线机制 TCP称得上是最复杂的协议之一，由于TCP的底层是IP协议，而上面已经提到IP协议是“尽力而为”服务，几乎没有可靠性的保证，我们只能假设底层是完全不可靠的服务，由此构建出了TCP协议。 基本概念介绍TCP连接并不是一条实际的连接或是一条虚电路，所谓的TCP连接只是存储在端到端系统中的连接状态，而路由器、链路层交换机对TCP连接完全视而不见，他们看到的只是数据报。 全双工服务（full-dumplex service）：指的是只能AB之间互相传输，是点对点，不可能有第三者加入的情况出现。与多播有明显不同。 客户进程：发起连接的进程；服务器进程：接收连接的进程 三次握手：客户首先发一条特殊报文，服务器用另一个特殊报文来响应，最后客户用第三个特殊报文响应。$\color{red}{前两个报文不承载有效载荷，而最后一个可以有}$ 当app层给运输层TCP一些数据，会被放入发送缓存里，在TCP方便的时候，就会从缓存中拿出一些数据发送。 最大报文段长度MSS（Max Segment Size）常根据最大传输单元设置，典型值是1460字节。注意不包括各种首部，只包括应用层数据大小。TCP/IP首部一般是40bytes。 最大传输单元MTU（Max Transmission Unit）：本地主机发送的最大链路层帧长度 TCP报文段：TCP将这次要发送的数据用一个TCP首部进行封装。 就像前面说到的，MSS限制了TCP报文段的最大长度。当一个大文件被发送的时候，它将被分为许多长度为MSS的报文段发出。另一方面，对于那些不需要传递大量数据的交互应用，也可以发送较小的数据段。那么什么叫TCP方便的时候呢？一般来说，TCP会在三种情况下发送数据： segment full 超时 app层的push 发送与接收动画 个人觉得（未经过资料查证，只是陈述想法），TCP连接就只是一种连接状态：recv与send都知道对方时刻准备着接受自己的数据，自己发出的数据可以说送到正确的地方，这就够了。TCP连接组成包括：这对主机各自的：缓存、变量、进程连接的套接字。 TCP报文段与UDP的报文段对比起来，TCP报文段可以说是非常复杂了。 源端口号、目的端口号：TCP使用四元组确定一个连接，该信息用于复用分解。序号、确认号：像前面讨论到的保证可靠性的机制一样，TCP使用序号来确定每一个字节，注意TCP为每一个字节分配一个序列号，而不是像rdt一样为每一个包分配一个序号。这个机制将在后面提到。确认号：TCP确认已按序收到的下一个字节。接收窗口：用于流量控制，接收方告知发送方醉倒还能给我发送多少字节。首部长度：一般是20字节，比UDP多12字节（Byte）。选项可令TCP首部长度发生改变，首部长度按照32bit的字为单位。因特网检验和：同UDP。checksum紧急数据指针：指向app层标识的紧急数据的尾字节。当紧急数据存在并存在紧急数据指针的时候，TCP必须通知上层。该字段一般不用。选项：用于双方协商MSS的大小、时间戳等。可参考RFC 854与RFC 1323了解细节。URG：urgent，紧急。指示存在紧急数据。ACK：指示该报文段包括一个对已经被成功接收的报文段的确认。PSH：要求将数据立即给APP层。RST：在连接出现问题时重置。SYN：连接建立请求。FIN：终止连接请求。 需要注意的是：TCP的确认是累积确认，也就是只会确认到有序的字节流的下一个。对于那些失序的包，选择权交给了实现TCP的编程人员： 立即丢弃 缓存：这是实际中做的。 $\color{green}{关于究竟缓存是怎么实现的，需要再查阅资料。}$ 稍带确认：一方向另一方发送信息时顺带确认另一方向自己发送的信息。每一次发送的TCP报文段都必须有SEQ与ACK字段。当没有新数据到达时，SEQ就为下一个期待的字节的序号。 往返时间估计与超时往返时间（RTT）的估计是为了能够设置一个良好的超时重传的时间，以避免时间太短带来的不必要的重传以及时间太长而影响应用层的体验。 SampleRTT指的是某TCP报文段从被发出到收到确认之间的时间间隔。 TCP在任意一个时刻，只为当前已经发送但仍未确认的一个TCP报文段计算SampleRTT，得到一个新的SampleRTT值。TCP不会为重传的报文段计算RTT，它只会对第一次上传输的报文段计算，这是为什么？ 由于路由器的阻塞以及系统负载的变化，SampleRTT将会随之波动，因此采取了一种对SRTT取平均的方法，委会一个EstimatedRTT。$$ERTT=(1-\alpha)*ERTT+\alpha*SRTT$$ $\alpha$通常取0.125，故：$$ERTT=0.875*ERTT+0.125*SRTT$$ 这种指数加权平均移动将使得之前的SRTT的权值快速减小。 DevRTT是RTT的偏差，用于估算SRTT偏离ERTT的程度： $$DRTT=(1-\beta)*DRTT+\beta* | SRTT-ERTT|$$ $\beta$通常取值0.25，故： $$DRTT=0.75*DRTT+0.25*|SRTT-ERTT|$$ $$\color{red}{千万不要忘记给公式里面的markdown符号加转义谢谢}$$ 最终的超时时延应该设置为：$$TimeoutInterval=ERTT+4*DRTT$$ 推荐的初始TI是1s。 快速重传：当发送方连续三次收到对同一个字节的确认消息，默认为是对下一个字节的NAK，将会忽略定时器，立即对下一个报文段进行重传。对于有问题的报文段，TCP并不管是丢失、数据错误、ACK损坏，都以重传报文段来解决问题。TCP使用流水线，可以显著的增加吞吐量。一个发送方可以具有的未被确认的报文段数量由流量控制与拥塞控制机制决定。 可靠数据传输TCP的可靠数据传输服务保证另一个进程从其接收缓冲中读出的数据无损坏无间隔非冗余的按序字节流。 提出问题：对于那些被接收方缓存但是由于无序不能确认的包，有什么机制呢？（这个不同于回退N步，亦不同于选择重传（选择重传N个定时器）） 简化的TCP发送方动作12345678910111213141516171819202122232425262728293031sendbase = initial_sequence number nextseqnum = initial_sequence number loop (forever) &#123; switch(event) /* event: data received from application above create TCP segment with sequence number nextseqnum compute timeout interval for segment nextseqnum start timer for segment nextseqnum TCP只会为第一个设置一个定时器 pass segment to IP */ ; nextseqnum = nextseqnum + length(data) ; /*event: timer timeout for segment with sequence number y retransmit segment with sequence number y compute new timeout interval for segment y restart timer for sequence number y */ //event: ACK received, with ACK field value of y ; if (y &gt; sendbase) &#123; /* cumulative ACK of all data up to y */ cancel all timers for segments with sequence numbers &lt; y ; sendbase = y ; &#125; else &#123; /* a duplicate ACK for already ACKed segment 快速重传机制*/ increment number of duplicate ACKs received for y ; if (number of duplicate ACKS received for y == 3) &#123; /* TCP fast retransmit */ resend segment with sequence number y ; restart timer for segment y ; &#125; &#125; /* end of loop forever */ &#125; 超时间隔加倍前面讲到TimeoutInterval根据ERTT与DRTT推导出，其实这只是在首次发出报文段的时间间隔。之后每超时一次，这个时间间隔都会被设置为原来的2倍。这也算是拥塞控制的一部分，因为当数据报丢失时，很可能是因为网络的拥堵。在后面将会更加详细的介绍TCP拥塞控制机制。 快速重传就像前面已经提到的，3个对同一数据的冗余ACK激发快速重传。 GoBackN or Selective Repeat？TCP看起来更像是Go Back N，因为只有一个定时器，但是TCP又会在接收方提供缓存机制，而且每次重传都只会重传一个报文段。 对TCP提出的一种修改意见是选择确认，也就是允许TCP对失序报文段有选择的确认。这种机制我们不讨论。 云巽：yunxun，意外发现了一个很好听的词！ 流量控制emmm这里是想直接嵌入js的，没想到失败了。就先这么放着，在文章最后可以看到。 需要注意的一点是，流量控制与拥塞控制并不是同一个概念。流量控制是为了使接收方的缓存区不会溢出，拥塞控制则是为了降低网络的负担。 TCP的发送端维护接收窗口rwnd，接收窗口将指示给发送方接收方还能最多收到多少字节的数据。定义：LastByteRead：接收方的应用进程从缓存中读出的最后一个字节的编号。LastByteRcvd：从网络到达接收方并放入接收缓存的最后一个字节的编号。接收缓存RecvBuffer。由于TCP不允许溢出：LastByteRcvd-LastByteRead&lt;=RecvBuffer接收窗口的大小：rwnd=RecvBuffer-(LastByteRcvd-LastByteRead) LastByteSent：发送方维护的已经发送的最后一个字节的编号。LastByteACKed：被确认的最后一个字节的编号。 根据接收方的动作，由于被Read的一定是已经接收方被ACKed的（但是发送方可能会因为其他问题还没有被ACK），因此，只需要保证LastByteSent-LastByteACKed&lt;=rwnd，这样就可以保证接收方的缓冲区不会溢出。 动作：接收方每次ACK，都告诉发送方自己的rwnd，发送方将最多发送rwnd字节的数据。 仔细想一想，其实这个真的是有用的吗？如果一个包ACK了N字节，但是ACK损坏掉了，这时可以看到rwnd指示有额外的空间，但是在发送方却没有额外的空间了（sent-acked=rwnd），这时应不应该继续发送呢？ 这种方法其实有一个问题：接收方ACK的时候，告诉发送方自己的rwnd=0，过了一会儿，APP层拿走了一些数据，这时rwnd有空间了，但是发送方却不知道有空间了，不会发送数据。这就会形成死锁。有两种可能的解决方法，但是TCP要求接收方尽可能简单，于是这个任务落在了发送方。发送放在被告知对方的rwnd=0之后一段过时间将开始向接收方发送只含有一个字节的探测报文，这些报文段将会被接收方确认，直到发送方接收到了一个rwnd!=0的报文段ACK。 UDP不提供流量控制。 TCP连接管理连接建立 三次握手如上： 客户端发送一个不承载数据的SYN被置为1的报文段SYN报文段。client_isn是随机生成，为了消除分组重传带来的错误（取决于网络时延）。有一些在如何选取client_isn方面的有趣研究。 服务器端发送SYNACK报文段：一旦服务器端接收到了上一个报文，就开始准备为这条连接分配缓存与变量，并发送一个允许连接的报文段：SYN被置为1表示请求连接。（TCP连接互不干扰，实际上存在两条连接，在关闭连接时更能体现出），seq指明了自己的初始序号，ACK是对前面一个请求连接报文段的确认。此后，客户端就可以向服务器端发送信息了。 客户机为这条连接分配变量与缓存，并发送确认报文：是客户端确认服务器端连接的普通报文段，这个报文段可以承载数据（因为client-&gt;server的连接已经建立）。此后，服务器端就可以向客户端发送信息了。 client_isn以及server_isn一般有自己对应的counter产生，从而确保相近时间创立的连接的seq不同。 可以想象，如果在A到B的使用到了seq=N的连接刚刚关闭，新开的A到B的相同端口号的连接又使用了序号N，而由于网络时延的关系，上一个连接的N还存在于网络之中，就有可能出现上一个N被误当作这次的N被接收ACK，导致应用层获取数据错误的情况发生。 上面的是一个标准的打开过程，实际上，打开过程可能会出现各种幺蛾子，比如： Simultaneous Open ：实际上，这种打开是成功的。两端都有各自的连接，实际上所起的效果是一样的。这里的第二个报文之所以没有seq，是因为seq是给对方ACK使用的，由于这里的每一条连接是单向的，就不需要给出一个新的seq。 半打开：半打开是失败的打开，是因为一方的连接建立起来之后另一方没有再回消息，也就是第三条报文不见了。比如机器非正常关机等都可能会导致半打开。数量较大的版打开将会影响效率与空间。怎么消除半打开的连接呢？可以定时检查，向对方发送报文，如果不如回应，就把己方的连接关闭。 连接关闭参与TCP连接的任意一方都能随时终止连接，连接结束之后，为连接维护而存储的变量与缓存都将被释放。红色部分之后，client不再发送报文段，但是还可以接收；绿色之后，server不再发送报文段，连接正式关闭。 半关闭：半关闭是正常现象，指的就是A-&gt;B的连接关闭之后，A不会再发送但是还能接收，B到A的也关闭了之后才都消停下来。 TCP连接状态序列客户机的TCP状态序列： 为什么直到等待一个IP数据报在Internet上可能存活的最大时间长的两倍（即120秒）后，一个连接才能从TIME_WAIT状态转移到CLOSED状态？当连接的本地一方已经发出一个ACK数据段响应对方的FIN数据段时，它并不知道这个ACK数据段是否成功地被传递。结果是，另一方可能有重传一个FIN数据段，而这个第2个FIN数据段可能在网中被延迟。如果允许连接直接转移到CLOSED状态那么可以会有另一对应用进程会打开同一个连接（即使用同一对端口号），而前面连接实例中被延迟的FIN数据段这时会立即使后来的连接实例终止。同时也避免了分组重传带来的错误信息。 服务器的TCP状态序列： TCP定时器总结Connection Establishment Timer：当SYN包发出时，连接建立定时器就开始计时，如果在75秒内未收到响应，则连接建立失败。The Retransmission Timer：重发定时器是TCP发送数据时设置的，如果数据在重发定时器超时时还没有返回确认，TCP就重发数据。定时器的设置是动态的，它基于TCP对往返时间（round-trip time）的测试，重发时间设在1到64秒Delayed ACK Timer：当TCP实体收到数据时它必须返回确认，但并不需要立即回复，它可以在500ms内发送ACK报文，如果在这段时间内它恰好有数据要发送，它就可以在数据内包含确认信息，因此需要ACK延时定时器。The Persistence Timer：管理一种较为少见的事件，即死锁情况。为了让发送方暂停发送数据，接收方发送一个接收窗口为0的确认。后来，接收方又发送了一个更新了窗口大小的分组，但该分组丢失，于是，双方都处于等待为了防止上述事情发生，发送方在收到接收方发来一个窗口为0的数据时，就启动持续定时器，等该定时器超时还没有收到对方修改窗口大小的数据的话，发送方就发一个探测数据，对该探测数据的响应应包含了窗口大小，若仍为0，则定时器清0，重复以上步骤，否则则可以发送数据。The Keep-Alive Timer：当一个连接长时间闲置时，保持存活定时器会超时而使一方去检测另一方是否仍然存在，如果它未得到响应，便终止该连接The Quiet Timer：当TCP连接断开后，为防止该连接上的数据还在网络上，并被后续打开的相同的连接接收，要设置闲置定时器以防止刚刚断开连接的端口号被立即重新使用 SYN洪泛攻击在上面提到了：半Open。其实这种情况大都在一分钟之后被服务器端发现并断开连接，回收资源了。但是这一分多钟的时间的资源浪费将为经典的Dos攻击即SYN洪泛攻击创造了环境。在这种攻击模式中，攻击者发送大量的SYN报文段而不发送最终的ACK，导致大量的半连接占用服务器的资源。现在有一种有效的解决方式：SYN cookieSYN cookie的工作方式是：当server接收到一个SYN，他并不立即为这个连接分配缓存与变量，而是使用这个TCP报文段携带的源ip与源port信息，运行一个仅有server知道的一个散列函数得到一个初始序列号，这种精心制作的初始序列号被称为cookie。server仅仅是发送一个具有该序号的SYNACK。该序号也不会被保存。如果一段时间之后接收到了同一个源ip与源port的ACK报文段，server发现二者并没有连接，于是再次运行散列函数，得到的序号如果加一就是本ACK携带的序号，server就认为这是一个正常的client，为之分配资源，建立连接，否则，server不会分配资源，之前的攻击没有任何影响。（哎呀其实也稍稍影响了处理效率了吧） 其他情况前面考虑的都是特别理想的情况，如果client向server一个并不接受TCP连接的port发送了一条报文将会怎样？ server将发送一个特殊重置报文段给client，这个报文段将RST标志位置为1，告诉client自己没有那个port接收TCP，请他不要再发送了。 如果发送的是一个UDP报文段，如果不匹配，server发送一个ICMP数据报。这在网络层进行讨论。 nmap工作原理：nmap向某一台主机的一个port发送一个SYN，接下来有三种情况：收到一个SYNACK，则会标明那个端口上有一个已经打开的TCP应用程序，返回“打开”，如果收到RST，说明这个端口没有一个TCP应用程序，如果什么都没有收到，说很可能是被防火墙给墙了。nmap下载 TCP option 先只放一个图。 拥塞控制原理在讨论TCP的拥塞控制之前，首先来讨论更加普遍的拥塞控制原理。 我们把分组重传作为网络拥塞的信号。实际上，分组重传不全是因为网络拥塞。 ATM：异步传输网络ABR：可用比特率 1. 两个发送方与一个无限缓存的路由器不考虑分组重传、流量控制、拥塞控制，忽略首部信息的额外开销。 这种情况下，发送方完全不节制，每连接的吞吐量如下：吞吐量不可能有超过R/2的稳定状态，这是因为二者共享一个吞吐量R的链路。当发送速率在[0,R/2]时，接收方的吞吐率等于发送方的发送速率，也就是发送方的所有数据经过有限时间传输之后到达接收方。 但是，再看速度与平均时延的关系：看起来吞吐量接近R/2是件好事，但是从时延的角度来看，接近R/2的时候，平均时延就会越来越大。 代价1：巨大的时延。 （为什么？？？到R/2的时候不是正好利用完所有链路吗？又没有重传，时延为什么会这么大？？？ 2. 两个发送方以及一个具有有限缓存的路由器假设：路由器缓存已经满了的话，新来的数据包就会被丢弃。 供给载荷：运输层向网络中发送报文段的速率。 仍然使用上面的图。 如果控制得非常好，yin=yout 如果只对丢失的包进行重传，yin`&gt;yout 对迟到的包重传，yin`远大于yout 以上三种情况下的吞吐量随着供给载荷变化：（所谓吞吐量，就是☞yout吧） 第二图的R/3-R/2是部分重传丢失占用的带宽，第三图的R/4-R/2是部分重传丢失+延时重传带来的丢失。 代价2：不必要的重传占用带宽 3. 四个发送方以及有有限缓存的多台路由器及多跳路径 从虚线开始，吞吐量就开始下降，一直到最后几乎为0.这时路由器几乎一直在丢失重传丢失重传。 拥塞控制方法 端到端的拥塞控制：IP协议并不提供对拥塞控制的支持，如果要在运输层做拥塞控制，也只能通过行为来判断。例如3次同一数据的ACK，被认为是丢失报文段，进而以为网络有些繁忙。 网络辅助的拥塞控制：路由器向发送方提供显式的拥塞信息。这个信息只需要一个比特。有两种方式：一种是直接反馈，路由器直接告诉发送方拥塞；另一种是间接反馈，路由器标记数据，当接收方收到被标记的数据之后在ACK的时候告诉发送方。 网络辅助的拥塞控制：ATM ABRTCP拥塞控制TCP的拥塞控制的基础是认为所有数据包的丢失都是路由器因为阻塞给我丢掉了。实际上，有线网络传丢的可能性很小，所以这个基础是没什么问题的。但是在无线网络中，TCP的拥塞控制则需要有一定的改进。 TCP拥塞控制概述拥塞窗口cwnd：发送方维护一个变量，他对一个TCP发送方能对网络中发送数据的速率进行了限制。特别的：$$LastByteRcved-LastByteACKed&lt;=min{rwnd,cwnd}$$ cwnd限制了发送方每次向接收方发送的字节数量，考虑一个丢包与发送时延皆忽略不计的连接，粗略的讲，发送方发送的速率大概是（cwnd/RTT)字节/秒。因此，调整cwnd可以调整发送速率。 那么发送方要怎么知道有了拥塞？第一就是像前面所说的丢包或是连续三个ACK。有没有可能丢包不是因为网络拥塞呢？当然是可能的！ 对于不丢包的理想情况下，TCP的发送方将会收到对以前未确认报文的确认，它们使用这些确认来增加cwnd。到达的速率将会影响cwnd增长的速率，因为TCP使用触发（或计时）来增大它的拥塞窗口长度，TCP是自计时的。 TCP有一些处理方法： 一个丢失的报文段意味着阻塞 一个确认报文段指示网络正在向接收方交付发送方的报文段，因此当对先前未确认的报文段到达时，增加发送速率 宽带探测。 TCP拥塞控制算法慢启动： 一条TCP连接开始时，首先cwnd会被设置为1个MSS。1个MSS真的很小，因此TCP此后每当一个报文段首次被确认（注意不是收到ACK哦，是被确认哦）就把MSS增加1.这样1变2，2变4，4变8…指数增长。 什么时候停止这种爆炸增长？ 存在丢包事件，将ssthresh置为cwnd/2，将cwnd重新置1，重新慢启动，。 存在丢包事件，将cwnd的值置为ssthresh，结束慢启动，进入拥塞避免阶段。 检测到3个冗余ACK，执行快速重传，进入快速恢复。 拥塞避免： 进入拥塞避免之后，离拥塞可能并不遥远。每个RTT将增加一个MSS。例如一个RTT发了10个包，那么这十个包只将cwnd增加1个MSS。 什么时候结束这种线性增长？ 丢包，将cwnd设置为1个MSS，sstresh设置为cwnd/2。 三个冗余ACK，将cwnd减半（三个已经收到的ACK要加上3个MSS），将ssthresh更新为cwnd/2，进入快速恢复 快速恢复： 对于引起TCP进入快速恢复的报文段，对每收到的一个冗余ACK都加一个MSS。这个阶段时说明网络其实并不是特别堵，只是传丢了一个，不用太过限制。直到最终丢失的报文段ACK到达，TCP在降低cwnd之后进入拥塞避免阶段。如果出现超时事件，将将cwnd设置为1个MSS，sstresh设置为cwnd/2，进入慢启动。如果出现冗余丢包事件，将cwnd设置为1个MSS，sstresh设置为cwnd/2。 TCP Tahoe与TCP RenoTahoe不管发生什么事件，都会无条件的将cwnd变为1，然后重新慢启动。Reno综合了快速恢复。 Tahoe的过程：在4时达到初始阈值，在8时有三个冗余ACK，在10.5时达到阈值。Tahoe不能容忍丢包，一旦丢包，就会进入慢启动。 123456789/* slowstart is over */ /* cwnd &gt; threshold */Until (loss event) &#123; every w segments ACKed: cwnd ++; &#125;//拥塞控制阶段;threshold = cwnd /2;cwnd = 1;perform slowstart//重新慢启动; Reno过程：在4时达到初始阈值，在8时有三个冗余ACK，之后减小cwnd，进入快速恢复。Reno分超时丢包与冗余丢包，冗余丢包进入快速恢复，超时慢启动。 123456789101112/* slowstart is over */ /* cwnd &gt; threshold */Until (loss event) &#123; every w segments ACKed: cwnd ++ &#125;//拥塞控制;threshold = cwnd /2If (loss detected by timeout) &#123;//进入慢启动; cwnd = 1 perform slowstart &#125;If (loss detected by triple duplicate ACK)//进入快速恢复 cwnd = cwnd /2 于是发现：什么对超时都是没有容忍度的，直接会慢启动。但是对于3个冗余ACK的表现个不一样，一般进入快速恢复。 公平性：TCP与UDPTCP是自律的，如果UDP不自律，可能会挤跨TCP。因此在使用UDP的APP层应该做类似的”平滑、缓慢变化“的拥塞机制，保证公平。 端口与进程最后，我需要补充一下端口号与进程之间的关系： 首先：缓冲区对应的是谁？在上一篇中就应该明确，是socket。 端口号是什么？ 在网络技术中，端口大致有两种意思：一是物理意义上的端口，比如，ADSL Modem、集线器、交换机、路由器用 于连接其他网络设备的接口，如RJ-45端口、SC端口等等。二是逻辑意义上的端口，一般是指TCP/IP协议中的端口，端口号的范围从0到65535，比如用于浏览网页服务的80端口，用于FTP服务的21端口等等。我们这里将要介绍的就是逻辑意义上的端口。 服务器一般通过知名端口号来识别。例如，对于每个TCP/IP实现来说，FTP服务器的TCP端口号都是21，每个Telnet服务器的TCP端口号都是23，每个TFTP(简单文件传送协议)服务器的UDP端口号都是69。任何TCP/IP实现所提供的服务都用知名的1～1023之间的端口号。这些知名端口号由Internet号分配机构（InternetAssignedNumbersAuthority,IANA）来管理。 端口号的作用正是为了区分不同的网络服务。 上面的比较官方，下面将由我自己写的程序来—— TCP里面，一个端口号可以被多个socket绑定。而UDP不行，我的理解是数据不知道要给谁。 已经被绑定之后，再次要求绑定： 这是再次运行，也就是说，其实这个并不是一个进程不能绑定同一个端口号，而是两个UDP的socket不能绑定同一个端口。跟进程没有什么关系。fork子线程的时候，也可以使用其他的socket绑定其他的端口号。 端口这个概念就是计算机网络领域的概念，有网友直言说进程与端口号没有什么关系，其实是对的。 thanks for ur help! [1] 进程与端口映射 [2] 端口号是什么？ [3]IBM Knowledge Center 这个有很多东西，不止端口号 [4]TCP 在最后的复习时刻！ UDP的源端口号：即使不用ACK，但是交互总要有个来源吧。服务器给client发东西得直到源端口号啊。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>网络课</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[the One使用记录]]></title>
    <url>%2F2017%2F11%2F01%2F%E5%BE%80%E4%BA%8B%E4%B8%8D%E5%A0%AA%E5%9B%9E%E9%A6%96%E7%83%9F%E9%9B%A8%E4%B8%AD%2Fthe%20One%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%951%2F</url>
    <content type="text"><![CDATA[一个小tip：使用linux命令行进入带空格的文件，如果直接cd filename进入的话是不行的，那应该怎么进入呢？ cd “filename”就好啦！ 又一个小tip：不下心关掉了eclipse的项目工程目录怎么办？ Window-&gt;Show View-&gt;Others-&gt;General-&gt;Project Explorer emmm，markdown行内代码形式：``包起来就行 从github下载the-one犹记我初学git的时候也是傻傻的，这里就放出来具体操作方法了！ 首先需要一个GitBash。在gitbash里使用cd命令进入想存放the one的文件夹，然后输入命令：git clone https://github.com/akeranen/the-one.wiki.git，前面两个是命令，最后一个是参数，代表的是这个仓库的地址。这个下载下来的是master….应该是不行的….下载v1.6吧。 等到完成之后就会发现在这个文件夹下面多了好多东西呀！ done！ 将项目import进Eclipse并运行eclipse，使用java的孩子应该没有不知道的吧。哦对，the one是java代码编写。 到了这一步就出了一点小问题…一直是使用eclipse的File-&gt;import功能向workspace导入外部的项目的，导入the one的时候竟然告诉我未找到项目文件！我尝试使用File-&gt;Open Project From FileSystem来，这次可以了。the one 成功出现在了project explorer里面！但是！有错误！ 这个应该在说明文档里面说了，1.1以后版本的java要编译theone需要添加一些liabrary到项目的build path，但是我看了我的build path，已经添加了呀？怎么还有错？ click here 在上述网站，第二个回答解决了这个问题。由于JUnit3.0与4.0都在，我就都删除了，然后重新添加了JUnit4.0.done！ 如图，现在整个项目都已经没有错误了！ 选择整个项目，右击Run As-&gt;JUnit Test成功！ the one涉及到了JUnit，如果不了解JUnit，需要先了解一下~ click here~ JUnit之一 在我以JUnit Test来运行时，theone出现了两个fail。这表明….可能是有bug的啊….mark 好吧，我先忽略了， 然后 run了下（主类是core.DNTSim），发现其实可以出来东西。由于可能需要命令行参数，我又使用cmd来编译运行，结果… 但是eclipse成功了呀？我找到了一个在eclipse设置命令行参数的方法，企图先跳过jdk版本带来的（？）编译问题。 DTNSim的API Run-&gt;Run Configurations-&gt;DTNSim-&gt;Argumets:加上你想要的参数。即可： 好了，至此，程序初步可以运行使用了。 解决问题时间 好的，现在是解决问题时间啊。 询问了老师，老师说这个可能是JUnit包加载不正确。但是我重新写了一个工程，使用一样的方法，那个是没错的。 所以我想是不是版本问题。 于是我下载了v1.6。使用同样的方法import进来，这次错误更多！但是我发现这次最初是没有添加README里面说要自己添加的2个jar包的，所有感觉有希望！ 添加jar包： Project右键-&gt; build path -&gt; configure build path-&gt;libraries-&gt;add jars-&gt;the-one-1.6.0-&gt;lib 好了，把这两个jar都添进来。 JUnit的添加方法还与上面一样，记得要添加的是4.0 没错了。 然后来测试一下。 还有错:-)。 既然是有错的，那就只能一点一点分析是怎么回事了。 首先，我又运行了1.6的compile，还是不行，这次我决定把电脑里面的jdk换成8。 如图，配置好的环境变量在cmd竟然没有更换！这也是导致javac不能用的一个原因。如果你确认自己配的环境变量肯定是对的，关掉cmd重新打开，就可以了。 环境变量配置应如下：这次compile的结果。（jdk9不支持那个选项了？好了，这次使用one.bat也可以运行了。（jdk9：exm？？？ but….eclipse测试还是没过…. C:\ProgramData\Oracle\Java\javapath 了解运行方法与配置信息将参数设置为：[-b times] [ur conf_files] -b后必须跟一个数字，这个数字表示simulation将会在batch mode（批处理）下运行，不会出现可视化界面，而是打印信息。后面的数字代表运行次数或者是num1:num2的形式来确定一个范围。 conf_files是一系列你自己写的conf file的文件名，数量任意。如果没有这个参数，会使用default_setting.txt。需要注意的是，如果多个conf设计同一个属性，那么在后面的设定将会覆盖前面的设定。 Conf文件 以下译自README 所有的模拟参数都是通过cond文件给出的。conf文件就是普通的txt文件，在文件里有一些ket-value对。大多数变量的语法都是：Namespace.key = value例如：key的前缀是namespace命名空间，然后加一个.点，然后是key的名字。key和value被等于号=隔开。命名空间需要以大写字母开头，而且namespace和key都以CamelCase方式命名，大小写敏感。namespace宽松地定义了设置影响的某部分模拟环境simulation environment。许多（并非所有）namespace的名字与正在读的class的名字一样。特别是动作模块(movement models)，报告模块(report modules)以及路由模块(routing modules)遵照了这个习惯。有时namespace被用户定义，eg：使用网络接口，用户可以选择任何标识符，在该名称空间中定义特定于接口的设置，并在配置每个组应使用的接口时给出名称空间的名称。 数字可以使用.作为小数点，可以使用kilo(k)，mega(m)，giga(G)作为后缀。bool接受”true”,”false”,”0”,”1”。 许多设置确定了寻找外部文件的路径。路径可以是绝对路径也可以是相对路径，但是路径的分隔符必须是”/“。Unix与Windows都是。 有些变量包含以逗号隔开的值，对他们来说，语法是：Namespace.key = value1,value2,etc. 对于运行索引（run-indexed）值，语法是：Namespace.key=[runvalue;run2value;run3value;etc]。每一个runvalue可以是一个被逗号分隔的值。 设置文件可以有注释，以#开头。 一些值（scenario and report names at the moment）支持”value filling”。有这个特性做支撑，可以从设置的值动态地构造，例如，scenario name。这在使用run-indexing的时候非常有用。Just put setting key names in the value part prefixed and suffixed by two percent (%) signs. These placeholders are replaces by the current setting value from the configuration file. See the included snw_comparison_settings.txt for an example. 这个机制像是：比如，完善java的环境变量的时候：JAVA_HOME=C:/Program Files/Java/path=%JAVA_HOME%jre/…” default_settings.txt这个文件，如果它存在，在运行的时候一定会被read。此后给的文件可以在此基础上设置更多的东西，也可以覆盖掉默认设置的一些定西。 Run indexingrun index可以让你只使用一个conf文件就能运行很多个不同的配置configuration，方法是，你提供一个setting的数组，为在不同的conf文件之间需要改变的变量。例如：如果想用5个不一样的随机数生成器种子来生成movment models来运行模拟器，那么你可以这样define设置文件：MovementModel.rngSeed = [1;2;3;4;5]现在，你使用参数-b 5 my_config.txt运行。 warp-around：类似于OS里面的。也就是说：used values is the value at index (runIndex%arrayLength)。这样，就可以很轻易的运行很多排列。 模块们Movement models在模拟中，运动模型控制着节点的运动。运动模型提供了coordinates坐标、速度、停顿时间。基本的安装包括：random waypoint,map based movement,shorest path map based movement,map route movement,external movement。除了external的所有这些运动模型，都有可控的速度以及停顿时间分布。可以给出最大值以及最小值，运动模型使得值在给定返回之间uniformly distributed均匀分布。在external里面，速度以及停顿时间都由文件中的给定值解释执行（interpreted）。 如果一个节点使用了随机航点运行模型（random waypoint:RandomWaypoint），这个节点在模拟区中被给予一个随机的坐标。节点直接以恒定的速度到达给定的目的地，然后停顿一段时间，然后获得新的目的地。这个过程在整个模拟的过程中持续进行，节点在这些zig-zag（蜿蜒的）路径上走 基于地图的运动模型将节点的运动限制在预先定义好的路径上。可以定义不一样的路径，可以定义对全体节点都有效的路径。这样的话，比如说，汽车才不会直接开进门里或者是开到人行道上。 基本的基于地图的运动模型（map-based:MapBasedMovement）初始时把节点们分布在两个相邻的地图节点之间，然后节点们开始运动，从一个adjacent map node到另一个。当节点到达下一个地图节点的时候，他随机选择下一个节点。但是只有当这是唯一的选项（即，避免回到它来自的地方）时才选择它来自的地图节点。一旦节点移动了10-100个地图节点，它暂停一段时间，然后再次开始移动。 更加复杂的版本的基于地图的运动(ShortestPathMapBasedMovement)使用了Dijkstra的最短路径算法来寻找他在整个地图范围内的路径。一旦一个节点到达了他的目的地，他等一段时间，选择下一个随机的地图节点，用最短路径走过去。（这个算法只对valid map nodes起作用） 对于基于最短路径的运动模型，地图的数据信息还包括POIs（point of interests）。instead of为下一个目的地选择任意随机地图节点，移动模型可以被配置为以可配置的概率给出属于某个POI组的POI。可以有无限数量的POI组，并且所有组可以包含任何数量的POI。所有节点组对于所有POI组可能具有不同的概率。POI可以用来模拟例如商店，餐馆和旅游景点。 基于路线的运动模型（MapRouteMovement）可以用于对遵循特定路线的节点建模。（例如，公共汽车或电车线路。）只需要定义路线上的停靠点，然后使用该路线的节点就会经由最短路径，从一个站点到另一个站点，并在每一个stop停留设置好的时间。 所有的运动模型都可以决定什么时候节点是活跃的（他运动，可以被连接），什么时候不活跃。所有模型，除了external，可以给出多个时间间隔（time interval），在那个组的节点只会在那些时候比较活跃。 所有基于地图的运动模型都通过（WKT）格式的一个子集所规范的文件中获取输入信息。映射路径数据的解析器支持WKT文件的LINESTRING和MULTILINESTRING指令。对于点数据（例如POI），也支持POINT指令。 （MULTI）LINESTRING中的相邻节点被认为形成一个路径，并且如果某些行包含一些具有完全相同坐标的顶点，路径从这些地方加入（这是如何创建交叉点）。 WKT文件可以使用任何合适的地理信息系统（GIS）程序从现实世界的地图数据进行编辑和生成。包含在模拟器发行版中的地图数据使用免费的基于Java的OpenJUMP GIS程序进行转换和编辑。 不一样的地图可以通过在不同的文件中存储属于不同类型的路径来定义。POIs简单的用WTK POINT定义，而POI组通过将所有的属于同一个组的POIs存储在同一个文件中来定义。所有的POI也必须是地图数据的一部分，所以他们可以使用路径进行访问。用LINESTRING定义路线的停靠点，停靠点按照它们在LINESTRING中出现的顺序进行遍历。一个WKT文件可以包含多个路由，并按照它们在文件中出现的顺序将它们提供给节点。 使用外部移动数据（ExternalMovement）的实验移动模型从文件读取时间戳节点位置，并相应地移动模拟中的节点。有关格式的详细信息，请参阅输入包中的ExternalMovementReader类的javadocs。一个合适的实验转换器脚本（transimsParser。pl）的TRANSIMS数据包含在toolkit文件夹中。 要使用的运动模型是使用“movementModel”设置为每个节点组定义的。设置的值必须是movement包中的有效运动模型类别名称。在MovementModel类中读取所有运动模型通用的设置，并在相应的类中读取运动模型特定的设置。有关详细信息，请参阅javadoc文档和示例配置文件。 路由模块以及消息的创建路由模块定义了在模拟中消息如何被处理。6个基本主动路由模块（First Contact,Spray and Wait,Direct delivery, PRoPHET and MaxProp），一个被动路由用于外部路由的模拟。主动路由模块是用于DTN路由的众所周知的路由算法的实现。也有这些模型的变体和包含在最新版本中的几个不同的模型。有关详细信息，请参阅路由程序包中的类。 被动路由器专门用于与其他（DTN）路由仿真器交互或运行仿真，而不需要任何路由功能。路由器除非由外部事件命令，否则不执行任何操作。这些外部事件由实现EventQueue接口的类提供给模拟器。 有两个基本的类可以用作消息事件的来源：ExternalEventsQueue和MessageEventGenerator。前者可以用一个合适的脚本（例如，toolkit文件夹中的createCreates.pl脚本）或通过将例如dtnsim2的输出转换成合适的形式来从手动创建的文件中读取事件。有关格式的详细信息，请参阅输入包中的StandardEventsReader类。 MessageEventGenerator是一个简单的消息生成器类，它创建具有可配置消息创建间隔，消息大小和源/目标主机范围的均匀分布的消息创建模式。可以使用MessageBurstGenerator和One {From，To} EachMessageGenerator类创建更具体的消息传递场景。有关详细信息，请参阅javadocs。 该toolkit文件夹包含一个用于dtnsim2输出的实验解析器脚本（dtnsim2parser.pl）（曾经是一个更强大的基于Java的解析器，但是由于这个更容易扩展的脚本而被丢弃）。该脚本需要dtnsim2的代码的一些补丁，可以从toolkit / dtnsim2patches文件夹中找到。要使用的路由模块是按设置“路由器”的每个节点组定义的。所有路由器都不能正常交互（例如，PRoPHET路由器只能与其他PRoPHET路由器一起工作），所以通常对所有组使用相同（或兼容）路由器是有意义的。 报告可以使用报告创建模拟运行的摘要数据，连接和消息的详细数据，适合使用例如Graphviz进行后处理的文件（创建图表）以及与其他程序接口。有关详细信息，请参阅报告包类的javadocs。 对于任何模拟运行可以有任意数量的报告，并且使用“Report.nrofReports”设置来定义要加载的报告的数量。报告类别名称使用“Report.reportN”设置定义，其中N是从1开始的整数值。设置的值必须是来自报告包的有效报告类别名称。所有报告的输出目录（可以使用“输出”设置对每个报告类别重写）必须使用Report.reportDir -setting进行定义。如果报告类别未提供“输出”设置，则生成的报告文件名称为“ReportClassName_ScenarioName.txt”。 所有报告都有许多可配置的设置，可以使用ReportClassName.settingKey -syntax来定义。有关详细信息，请参阅Report类的javadocs和特定报告类（查找“设置id”定义）。 主机组一个host group是一组分享同样的运动和路由设置的主机。不同的组的设置值不一样，这样的话，它们可以表示不同类型的节点。可以在“组”（Group）命名空间中定义基本设置，不同的节点组可以覆盖这些设置或在其特定的命名空间（组1，组2等）中定义新的设置。 the settings有很多设置可以被设置。非常多，这里不提了。有关详细信息，请参阅类，尤其是report，routing和movement class的javadoc。另请参阅包含设置文件的示例。也许最重要的设置如下。 脚本设置（Scenario setting）123456789101112131415161718192021Scenario.name //脚本的名字，所有报告默认以此为前缀Scenario.simulateConnections //connection是否应该被模拟。如果只对运动模型感兴趣，这个可以被disable，以获得更快的模拟速度。通常情况下，是enable的。Scenario.updateInterval //每次更新时需要几秒。增加数值使模拟更快，但是可能以精度损失为代价。0.1-2 are goodScenario.endTime //How many simulated seconds to simulate.Scenario.nrofHostGroups //现在在模拟中有几个hosts group 接口设置（用来定义node可能会使用到的接口）12345678type //这个接口使用了什么类（来自接口目录）//其余设置是特定于类的。可以是例如：transmitRange //接口范围（meters）transmitSpeed //接口的传输速度（bytes per second） 主机组设置（在Group或GroupN的命名空间使用）]]></content>
      <categories>
        <category>计算机网络</category>
        <category>实验室</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>模拟器</tag>
        <tag>实验室</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2017%2F11%2F01%2F%E5%BE%80%E4%BA%8B%E4%B8%8D%E5%A0%AA%E5%9B%9E%E9%A6%96%E7%83%9F%E9%9B%A8%E4%B8%AD%2FCloud%20RAN%20for%20Mobile%20Networks%E2%80%94%E2%80%94A%20Technology%20Overview%2F</url>
    <content type="text"><![CDATA[前言移动数据的传输容量正在连续增加。根据Cisco的预测，在智能手机与穿戴设备的推动下，从2012到2017年容量将增长13-fold。因此，移动网络运营商需要增加网络的capacity来满足日益增长的用户需求。当LTE（long term evolution）的spectral efficiency标准正逼近Shanon极限，增加网络capacity的最好方法要么是增加基站覆盖区域，创建一个结构复杂的多元小基站网络（HetSNets）要么是使用像多用户多输入多输出（MIMO）或是Massive MIMO这样的多根天线在同一频率时段服务于多个用户的技术。然而，这将导致更大的的小基站区间干扰水平（Growing inter-cell interference levels）以及更多的花费。 移动网络的TCO（total cost of ownership）包括了CAPEX（CAPital Expenditure）和OPEX（OPerating EXpenditure）。capex主要指关于网络构建的花费，网络构建可能会从网络规划一直到网址需求，RF硬件，baseband硬件（基带），软件许可，leased line连接（专用网络连接），安装，civil cost（民用花费），网站支持，像供电或者是冷却（cooling）。OPEX包括需要去操纵网络的花费，比如，站点出租，专用网络，电力，运营与保持，升级。CAPEX与OPEX在更多base station被部署之后都显著增加了。更具体地说（more specifically），CAPEX增加是因为基站是无线网络infrastructure基础设施中最昂贵的组成成分，而OPEX增加是因为基站覆盖区需要相当多的电力去驱动，比如，中国移动估计有72%的电力花费在基站覆盖区域（cell sites）。移动网络运营商需要支付网络建造，运营，保持和升级的费用；同时人均收入（ARPU）随之时间的增长保持不变甚至有所下降，因为典型的用户对数据的需求越来越多却希望为移动流量付更少的费用。像图1中所示，如果补救措施，移动网络运营商将有可能面对入不敷出的局面。 因此，在移动网络领域，优化了花费和能源消耗的新型建构方式变得必需。 C-RAN是一种新型的移动网络结构，有着接受上述所有挑战的能力。这个概念最初在论文9中被提出并且在6中被详细描述。在C-RAN中，baseband processing（基带处理）被中心化，被被放在一个虚拟的BBU pool中被诸多site分享。这意味着它可能能够适应nonuniform traffic非均匀流量并更加有效率地利用一些资源，比如，基站。由于这个特性在C-RAN结构中将用到比传统结构更少的BBU，而且C-RAN还有降低网络运营费用的潜能，这是因为电力与能量的消耗相较于传统的RAN结构已经被减少了。新的BBU可以更轻易地被添加被升级，从而改善网络的稳定性并使得网络更容易被维护。虚拟化的BBU pool可以被多个不同的网络运营商所分享，允许他们通过云服务来租RAN。由于多个网站的BBU在同一个pool中co-located（协作），他们彼此之间可以以更小的延迟时间进行通信，这样，被介绍给LTE-Advanced来增加spectral efficiency和throughput吞吐量的机械装置，比如说增强版的ICIC与CoMP都被facilitated，在两个基站覆盖区内实行的负载平衡方法也被facilitated。而且，网络的表现也被改善，例如通过减少BBU pool内部的移交操作的延时。据China MObile Research Institute的猜想，C-RAN结构被移动网络运营商设为了目标，例如IBM、Alcatel-Lucent、华为、ZYTE、诺基亚西门子网络、Intel和Texas instruments。而且，在2020年的水平上来看，C-RAN被视为是典型的在5G中支持soft and green technologies的实现。然而，C-RAN并不是唯一可以对抗上述运营商们面临的挑战的选手，其他解决方式，包括small cells、being part of HetSNets and Massive MIMO。small cells的部署是户外hot spot闹区和室内coverage scenarios平均方案 。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Linux、Vim、Git常用命令——简明扼要版]]></title>
    <url>%2F2017%2F10%2F31%2FLINUX%E5%9F%BA%E7%A1%80%2Flinux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[第一次操作系统实验课记录。 一。linux下常用命令二。vim编辑器用法命令 首先确保linux下安装有vim。可以使用上述命令sudo apt-get install vim来确定。如果已经安装了vim，会显示没有变化，否则会帮你安装vim。 然后就可以开始使用vim啦！ 你使用 vim 或vim filename.suffix 进入了vim的命令模式。 在命令模式下，不能进行文本编辑操作，需要按下A/a/I/i进入插入模式，在这个模式下可以像notepad一样进行文本编辑。 如果使用第二种命令进入vim，vim将会自动帮你确定文件类型。这样说吧，比如你创建了一个yayicpp.cpp文件进入编辑，vim将会使代码高亮、进行括号匹配等操作。 好的！进入文本编辑模式之后，你迫不及待地写了一段helloworld。代码完成之后，你觉得只打印一行helloworld不太够，你想知道有没有类似于VS环境中那种Ctrl+C和Ctrl+V的操作。 其实是有的。这个时候需要按下Esc重新进入命令模式。在命令模式下有很多功能组合，上述的复制粘贴就是其中一种，但是这里并不想以复制粘贴作为第一个被介绍的命令，让我们先从光标的移动开始。 按下h键，光标左移；j光标下移；k光标上移；l光标右移。 按下d键进入删除模式，这时按下h可删除光标左侧的一个字符，按下j可删除光标所在行以及下面一行；按下k可删除光标所在行与其上面一行；按下l可删除光标所在的字符。双击d键删除光标所在行。 按下u键可以撤销前一步所做的改变。 按下V（Shift+v）或是v可以进入到一个选择的可视化界面，同样可以使用hjkl控制选择范围，v按照字符选择，V按照行数选择。选择完成之后按下y就可以复制选定内容。按下p就可以将复制内容粘贴到选定的位置。 按两下y可以复制光标所在行。 写到这里，你觉得可以了，可以从vim里面退出来了。 在命令模式下输入冒号，进入最后行模式。在最低端出现了光标。 在光标位置输入w，保存文件。 输入q，退出。 这些命令可以进行组合wq。wq可以用x替代。 你进入了最后行模式，又不想退出了，想继续编辑。 按下Esc或者Backspace可以回到命令模式。 三。git初步使用git是一个强大的版本管理工具，是Linus写的。这个人emmmmm…技术天才有些狂妄。]]></content>
      <tags>
        <tag>Git</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[归并、快排、堆排序]]></title>
    <url>%2F2017%2F10%2F31%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E5%BD%92%E5%B9%B6%E3%80%81%E5%BF%AB%E6%8E%92%E3%80%81%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[归并排序算法是分治策略的一种体现。所谓分治策略就是把一个大问题分解成几个较小的部分，通过递归分别解决几个小问题，然后再在线性时间内将几个小问题的解合并成一个完整的解。 归并归并排序也是一种排序算法。问题：将n个数由从小到大地排序。归并提出的解决是： 将这列数分成两半 递归地将每一半排序 将两个有序列合并成一整列 归并排序在做串的切分时不考虑大小因素，只从中间切分。于是在合并时便需要对两个有序串做一定处理才能保证结果串的有序性。为此，一个容易想到的方法是创建一个临时的数组存储有序列。如图： 每次都比较1串与2串当前位置元素大小，将较小的那一个输出到TMP数组中当前位置并加一，将输出串的当前位置加一。直到两个串都输出完毕。这种方式所用的额外空间是O(n)，只需要O(n)次比较。 实际上，归并排序一般是递归进行一直到每个串的长度是1，主要运算过程全部落在合并上面。下面由递归式分析归并排序算法的时间复杂度。 归并时间空间复杂度分析： 设T(n)表示该算法在规模为n的输入实例上最坏的运行时间，假设n是2的整数次幂，可以得到递推公式如下： 则有递推关系： 将这些时间都加在一起即为nlog2N。即归并的时间复杂度是O(nlogn)级别。 下面将严格证明这个命题： ——————这个过程线省略———— 归并的代码： 123456789101112131415Array.prototype.mergeSort=function(s,e,b)&#123; //start,end,temp if(s==null)s=0; if(e==null)e=this.length-1; if(b==null)b=new Array(this.length); if(s&gt;=e)return; var m=(s+e)&gt;&gt;1; //取中间值 this.mergeSort(s,m,b); this.mergeSort(m+1,e,b); for(var i=s,j=s,k=m+1;i&lt;=e;++i) b[i]=this[(k&gt;e||j&lt;=m&amp;&amp;this[j]&lt;this[k])?j++:k++]; for(var i=s;i&lt;=e;++i) this[i]=b[i];&#125; 快排快排提供的解决是： 选择一个枢轴，小于枢轴的到左边，大于枢轴的到右边 对两边分别递归地使用快排 合并 与归并相似的一点是，二者都采用递归方法解决问题，但是归并的排序工作都留在了合并过程中完成，而快排正与之相反，排序工作都在分割的过程中完成。 从图中可以明显看出，快排最终得到的串就是一个有序的串。 快排时间空间复杂度： 快排算法依赖于枢轴PIVOT的选择。当选择的枢轴越接近中间值，树越接近于完全树的树高，算法效率越高，最好可达到O(nlogn)。糟糕的枢轴选择将会使效率急速下降，甚至达到O(n*n)的级别。于是，当一个串越是接近于无序，快排的效率越高。快排的平均时间复杂度是O(nlogn)，是所有排序算法中平均时间复杂度最好的算法。快排需要栈的辅助，其空间复杂度是O(logn)。 快排的代码： 12345678910111213Array.prototype.quikSort=function(s,e)&#123; //start,end if(s==null)s=0; if(e==null)e=this.length-1; if(s&gt;=e)return; this.swap((s+e)&gt;&gt;1,e); var index=s-1; for(var i=s;i&lt;=e;++i) if(this[i]&lt;=this[e]) this.swap(i,++index); this.quickSort(s,index-1); this.quickSort(index+1,e);&#125; 堆排序 堆排序数据结构结课的时候还考了呢。怕是写错了吧当时。哎陈年旧事，不提也罢。 p又查到说，堆的建立过程就是不断插入的过程，所以可能根本不是完全建好了一个堆才去改变，也许是边建边改变。（有道云笔记你的markdown真的问题还很大 堆是一种数据结构，可以看做是一棵任一孩子结点都小于（大顶堆）或都大于（小顶堆）父亲结点的完全二叉树。这样根结点总是整个堆中最大或小的结点，每次只需将根取出来即可保证有序。但是，每添加或减少一个结点都需要对堆进行必要的维护。于是，堆排序中最关键的操作就是将一个序列调整成为堆。 堆排序给出的解决方法： 将序列建成堆 迭代地取根进入有序队列并调整堆直到堆为有序序列 堆的产生过程其实就是一个调整过程，下面给出堆的调整过程（以大根堆为例）： 最终取出数字的顺序即为最终顺序。 堆排序适合于结点数较多情况下的要求前几个结点。当记录数较少时，不推荐使用堆排序。 hash表+堆排序是处理海量数据的绝佳组合。 堆排序时间空间复杂度 完全二叉树高度log(n+1)，即对每个节点进行调整的时间复杂度是O(logn)，包括建堆的时间耗费与取值和调整，整个算法时间复杂度是O(nlogn)。额外空间只有temp用来存取出的数，O(1)。 堆排序的代码 12345678910111213141516Array.prototype.heapSort=function()&#123; for(var i=1;i&lt;this.length;++i)&#123; for(var j=i,k=(j-1)&gt;&gt;1;k&gt;=0;j=k,k=(k-1)&gt;&gt;1)&#123; if(this[k]&gt;=this[j])break; this.swap(j,k); &#125; &#125; for(var i=this.length-1;i&gt;0;--i)&#123; this.swap(0,i); for(var j=0;k=(j+1)&lt;&lt;1;k&lt;=i;j=k,k=(k+1)&lt;&lt;1)&#123; if(k==i||this[k]&lt;this[k-1])--k; if(this[k]&lt;=this[j])braek; this.swap(j,k); &#125; &#125;&#125; 本篇文章中的代码部分来自于作者twobin于网址http://www.cnblogs.com/twobin的博文《排序算法性能比较》。]]></content>
      <tags>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[序列比较]]></title>
    <url>%2F2017%2F10%2F31%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E5%BA%8F%E5%88%97%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159#include&lt;iostream&gt;#include&lt;string&gt;#include&lt;cstring&gt;#include&lt;stack&gt;using namespace std;class Pixel &#123;public: int a, b; Pixel(int x, int y) &#123; a = x; b = y; &#125;&#125;;int min(int a, int b, int c) &#123; if (a &lt; b) &#123; if (c &lt; a)return c; else if (c &gt;= a)return a; &#125; else &#123; if (c &lt; b)return c; else return b; &#125;&#125;int alpha(char fir, char sec) &#123; if (fir == sec)return 0; else return 1;&#125;/*int S(int m, int n, string a, string b, int beta) &#123; for (int i = 0; i &lt;= m; i++) M[i][0] = i*beta; for (int i = 0; i &lt;= n; i++) M[0][i] = i*beta; for (int i = 1; i &lt;= m; i++) for (int j = 1; j &lt;= n; j++) M[i][j] = min(alpha(a[i-1],b[j-1]) + M[i-1][j-1], beta + M[i-1][j], beta + M[i][j-1]); return M[m ][n];&#125;void back(int m, int n, string A,string B,int*result,int beta) &#123; if (m&lt;A.length()&amp;&amp;n&lt;B.length()&amp;&amp;M[m][n] +alpha(A[m],B[n])== M[m+1][n+1]) &#123; result[m] = 0; back(m + 1, n + 1, A,B,result,beta); &#125; else if (m&lt;A.length()&amp;&amp;n&lt;=B.length()&amp;&amp;M[m][n]+beta == M[m + 1][n]) &#123; result[m ] = 1; back(m +1, n, A,B,result,beta); &#125; else if(m&lt;=A.length()&amp;&amp;n&lt;B.length()) &#123; result[m] = -1; back(m, n + 1, A,B,result,beta); &#125;&#125;*/int SL(int m, int n, string a, string b, int beta) &#123; int**M = new int*[2]; M[0] = new int[b.length() + 1]; M[1] = new int[b.length() + 1]; for (int i = 0; i &lt;= n; i++) &#123; M[0][i] = beta*i; &#125; M[1][0] = beta; for (int i = 1; i &lt;= m; i++) &#123; M[1][0] = i*beta; for (int j = 1; j &lt;= n; j++) &#123; M[1][j] = min(alpha(a[i - 1], b[j - 1]) + M[0][j - 1], beta + M[1][j - 1], beta + M[0][j]); &#125; for (int j = 0; j &lt;= n; j++) &#123; M[0][j] = M[1][j]; &#125; &#125; int re = M[0][n]; delete[]M; return re;&#125;void DACA(int o,int r,int x, int y, string a, string b, stack&lt;Pixel&gt;*P,int beta) &#123; if (x-o &lt;= 1 || y-r &lt;= 2) &#123; int**M = new int*[x+1]; for(int i = 0; i &lt; x -o+ 1; i++) &#123; M[i] = new int[y -r+ 1]; M[i][0] = beta*i; &#125; for (int i = 0; i &lt;= y-r; i++) M[0][i] = i*beta; for (int i = 1; i &lt;= x-o; i++) for (int j = 1; j &lt;= y-r; j++) &#123; M[i][j] = min(alpha(a[i - 1], b[j - 1]) + M[i - 1][j - 1], beta + M[i][j - 1], beta + M[i - 1][j]); &#125; for (int i = x-o; i &gt;= 0; ) &#123; int j = y - r; for (j=y-r; j &gt;= 0; ) &#123; if (i&gt;=1&amp;&amp;j&gt;=1&amp;&amp;M[i][j] == alpha(a[i-1], b[j-1]) + M[i - 1][j - 1]) &#123; Pixel*p = new Pixel(i - 1+o, j - 1+r); P-&gt;push(*p); i = i - 1; j = j - 1; &#125; else if (i&gt;=1&amp;&amp;j&gt;=0&amp;&amp;M[i][j] == beta + M[i - 1][j]) &#123; Pixel*p = new Pixel(i - 1+o, j+r); P-&gt;push(*p); i -= 1; &#125; else if (i&gt;=0&amp;&amp;j&gt;=1&amp;&amp;M[i][j] == beta + M[i][j - 1]) &#123; Pixel*p = new Pixel(i+o, j - 1+r); P-&gt;push(*p); j -= 1; &#125; else break; &#125; if (j == 0 &amp;&amp; i == 0)break; &#125; return; &#125; string a2; cout &lt;&lt; "here:" &lt;&lt;( y-r) / 2 &lt;&lt; "," &lt;&lt; y-r &lt;&lt; endl; string b2 =b.substr((y-r) / 2 , y-r); int q[2] = &#123; 0,0 &#125;; int min; for (int i = 0; i &lt;= x-o; i++) &#123; a2 = a.substr(i, x-o); q[0]=SL(i, (y-r) / 2, a, b, 1); cout &lt;&lt; "done!"; q[0]+=SL(x-o - i, y-r - (y-r) / 2, a2, b2, 1); cout &lt;&lt; "done!" &lt;&lt; endl; if (i == 0)min = q[0]; else &#123; if (min &gt; q[0]) &#123; min = q[0]; q[1] = i; &#125; &#125; &#125; min = q[1]+o; Pixel*p = new Pixel(min, (y - r) / 2 + r); P-&gt;push(*p); DACA(o,r,min, (y-r) / 2+r, a, b, P, beta); cout &lt;&lt; "and here:" &lt;&lt; min &lt;&lt; "," &lt;&lt; x &lt;&lt; endl; a2 = a.substr(min-o , x-o); cout &lt;&lt; "???"; cout &lt;&lt; "hhhh" &lt;&lt; x - min &lt;&lt; ";;;" &lt;&lt; y - y / 2; DACA(min,(y-r)/2+r,x , y , a2, b2, P, beta);&#125;int main() &#123; string A, B; while (cin &gt;&gt; A &gt;&gt; B) &#123; stack&lt;Pixel&gt;*P = new stack&lt;Pixel&gt;(); cout &lt;&lt; SL(A.length(), B.length(), A, B,1); cout &lt;&lt; endl; DACA(0,0,A.length(), B.length(), A, B, P, 1); cout &lt;&lt; "LLLLL" &lt;&lt; endl; while(!(P-&gt;empty())) &#123; Pixel p = (P-&gt;top()); P-&gt;pop(); cout &lt;&lt; "(" &lt;&lt; p.a &lt;&lt; "," &lt;&lt; p.b &lt;&lt; ")"; &#125; delete P; cout &lt;&lt; "what!" &lt;&lt; endl; &#125;&#125;]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[背包问题初涉]]></title>
    <url>%2F2017%2F10%2F31%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E8%83%8C%E5%8C%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[算法上机考试，怎么说，虽然没做出来但是收获很多？好吧也只能这么安慰自己了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;//硬币。存储硬币的价值及其对应个数class Coins&#123;public: int value; int num;&#125;;//更小值函数。若值为0，代表不可能，返回另一个值，否则返回更小值int mini(int a, int b) &#123; if (a == 0)return b; if (b == 0)return a; if (a &gt; b)return b; else return a;&#125;//int max(int a,int b)&#123;// if(a&gt;b)return a;// else return b;//&#125;//int comp(const void *a,const void *b)&#123;// Coins* A=(Coins*)a,*B=(Coins*)b;// if(A-&gt;value&gt;B-&gt;value)return -1;// else if (A-&gt;value&lt;B-&gt;value)return 1;// else return 0;//&#125;//找零钱的函数，coins存储了各种硬币的面值与个数，n是硬币种数（coins的长度），m是找零的钱数。int GetCoin(Coins*coins, int n, int m) &#123; //新建一个二维数组用于存储在每一个要找的钱数下用i种硬币最少用几个硬币 int**M = new int*[2]; M[0] = new int [m + 1]; M[1] = new int [m + 1]; //初始时，用0个硬币找除0以外的钱数，不可能。 //且用0作为初始值便于后续计算。 for (int i = 0; i &lt;= m; i++) &#123; M[0][i] = 0; M[1][i] = 0; &#125; for (int i = 0; i &lt; n; i++) &#123; //对前i种硬币 for (int j = 0; j &lt;= m; j++) &#123; //要找j的零钱 int dola = M[0][j]; //保存未更新之前的值 for (int k = 1; k &lt;= coins[i].num; k++) &#123; //对这种硬币的每个数量 if ((j - k*(coins[i].value) &lt; 0)) &#123; //若k个硬币总钱数大于j，不可能。break M[0][j] = M[0][j]; M[1][j] = M[0][j]; break; &#125; if ((M[0][j - k*(coins[i].value)] != 0)) //否则。若满足条件，说明在M[0][j-k*(coins[i].value)]处有满足条件的解，与M[0][j]计算更好的值。此时这里一定有非0解 M[0][j] = mini(M[0][j], k + M[0][j - k*(coins[i].value)]); else if ((M[0][j - k*(coins[i].value)] == 0)) &#123;//否则，不一定存在非0解 if (k*(coins[i].value) == j) &#123;//若存在k个硬币正好找j元，更新解 M[0][j] = mini(M[0][j], k); //M[1][j] = M[0][j]; //M[0][j] = dola; //break;不行！ &#125; else M[0][j] = M[0][j];//否则，不更新解 &#125; &#125; //将M[0]转移到M[1]，M[0]恢复原值继续下一轮计算。这样可以防止对硬币i使用的数目多于现有数目的情况 M[1][j] = M[0][j]; M[0][j] = dola;// cout &lt;&lt; M[1][j] &lt;&lt; " ,"; &#125; for (int j = 0; j &lt;= m; j++)M[0][j] = M[1][j];//把新值给M[0]，进行对下一种硬币的分析。 // cout &lt;&lt; endl; &#125; return M[0][m];//返回最优解&#125;//int Getcoin(int*coins,int m,int n,int**M,int**N)&#123;// int*resu = new int[n], *resunum = new int[n];// for(int i=0;i&lt;=m;i++)&#123;N[0][i]=0;// M[0][i]=0;&#125;// for(int i=0;i&lt;2;i++)&#123;N[i][0]=0;// M[i][0]=0;&#125;// for(int i=1;i&lt;=n;i++)&#123;// for(int j=1;j&lt;=m;j++)&#123;// //cout &lt;&lt; "the j" &lt;&lt; j &lt;&lt; endl;// if (coins[i - 1] &gt; j) &#123; M[1][j] = M[0][j]; N[1][j] = N[0][j]; &#125;// else&#123;// M[1][j]=max(M[0][j],coins[i-1]+M[0][j-coins[i-1]]);// if(M[1][j]==M[0][j])N[1][j]=N[0][j];// else if(M[1][j]==coins[i-1]+M[0][j-coins[i-1]]) N[1][j]=1+N[0][j-coins[i-1]];// else N[1][j] = N[0][j] &lt; N[0][j - coins[i - 1]] ? N[0][j] : 1+N[0][j - coins[i - 1]];// &#125;// &#125;// for (int j = 0; j &lt;= m; j++) &#123;// M[0][j] = M[1][j];// N[0][j] = N[1][j];// cout &lt;&lt; "(" &lt;&lt; M[0][j] &lt;&lt; "," &lt;&lt; N[0][j] &lt;&lt; ")";// &#125;// cout &lt;&lt;i&lt;&lt;" , "&lt;&lt;coins[i-1]&lt;&lt; endl;// resu[i - 1] = M[0][m];// resunum[i - 1] = N[0][m];//// &#125;// int min=-1;//// for (int i = 0; i &lt; n; i++) &#123;//// cout &lt;&lt; "(" &lt;&lt; resu[i] &lt;&lt; "," &lt;&lt; resunum[i] &lt;&lt; ")";// if (resu[i] == m) &#123;// if (min == -1)min = resunum[i];// if (resunum[i] &lt; min)min = resunum[i];// &#125;// &#125;// return min;// //&#125;int main() &#123; int n; cin &gt;&gt; n; Coins*coins = new Coins[n]; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; coins[i].value &gt;&gt; coins[i].num; &#125; int m; cin &gt;&gt; m; //如果要找的钱数是0，最少需要0个硬币 if (m == 0) &#123; cout &lt;&lt; 0; return 0; &#125; // qsort(coins,n,sizeof(coins[0]),comp); // int sum=0; // for(int i=0;i&lt;n;i++) // sum+=coins[i].num; // int*Mycoin=new int[sum]; // int soum=sum; // sum=coins[0].num; ///* for(int i=0,j=0;i&lt;soum;i++)&#123; // if(i==sum)&#123;sum+=coins[j+1].num;j++;&#125; // Mycoin[i]=coins[j].value; // cout &lt;&lt; Mycoin[i] &lt;&lt; " "; // &#125;*/ // int k = 0; // for (int i = 0; i&lt;n; i++) &#123; // for (int j = 0; j &lt; coins[i].num;j++) &#123; // Mycoin[k] = coins[i].value; // cout &lt;&lt; Mycoin[k] &lt;&lt; " "; // k++; // &#125; // &#125; // cout &lt;&lt; "totally" &lt;&lt; soum &lt;&lt; endl; // int**M=new int*[2]; // for(int i=0;i&lt;2;i++)M[i]=new int[m+1]; // int**N=new int*[2]; // for(int i=0;i&lt;2;i++)N[i]=new int[m+1]; // pp=Getcoin(Mycoin,m,soum,M,N); //cout &lt;&lt; pp &lt;&lt; endl; int pp; pp = GetCoin(coins, n, m); //若最终返回0即为不可能，输出-1。 if (pp != 0)cout &lt;&lt; pp; else cout &lt;&lt; -1;&#125;]]></content>
      <tags>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在MFC中创建控制台]]></title>
    <url>%2F2017%2F10%2F31%2FMFC%E5%9F%BA%E7%A1%80%2F%E5%9C%A8MFC%E4%B8%AD%E5%88%9B%E5%BB%BA%E6%8E%A7%E5%88%B6%E5%8F%B0%2F</url>
    <content type="text"><![CDATA[距离上次写已经一周了。浑浑噩噩的愚人节，浑浑噩噩的一周。但是依然要加油啊~要明确自己想要的是什么！开开心心地、充实地活着才最重要！加油！ 我用的VS是2015版，之前找了一些在MFC中同时显示窗口与命令行的方法，我可以用的只记住了一个，先记录如下： 在×.cpp的InitInstance()中的CWinAPPEx::InitInstance()前加上以下： 123#ifdef _DEBUG AllocConsole()#endif 以后可以使用_cprintf()打印字符串，需要在使用该函数的文件添加头文件： 1#include&lt;conio.h&gt; 切记！这个头文件必须要在#include”stdafx.h”语句之后写，否则会报错！ 使用步骤如下： 1234CString str="";USES_CONVERSION;LPSTR lp=T2A(str);_cprintf(lp); 这段代码完成了将CString类型的str输出的任务。]]></content>
      <tags>
        <tag>MFC</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派解析域名失败导致apt-get update不可用]]></title>
    <url>%2F2017%2F10%2F31%2F%E5%BE%80%E4%BA%8B%E4%B8%8D%E5%A0%AA%E5%9B%9E%E9%A6%96%E7%83%9F%E9%9B%A8%E4%B8%AD%2F%E6%A0%91%E8%8E%93%E6%B4%BE%E8%A7%A3%E6%9E%90%E5%9F%9F%E5%90%8D%E5%A4%B1%E8%B4%A5%E5%AF%BC%E8%87%B4apt-get%20update%E4%B8%8D%E5%8F%AF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[捣鼓了一下午，查了n多网站。从删除文件到修改源，终于发现一直提示解析域名失败的原因是树莓派没有连上网orz…没有HDMI，我是通过树莓派的WiFi和电脑连上，电脑插了网线。后来把网线给了树莓派，电脑连树莓派的WiFi，电脑直接跳出了学校网络的登录界面，在电脑上面登录之后，这次开始更新软件源。 除了这个，我还按照网上各路大神的说法，改了好几个地方，这里一一记下来，以便以后查找。 删除某个目录的内容，只记得是/ect/apt/…/partial什么的 修改/etc/apt/resolv.conf的内容，数字改成8.8.8.8 修改源。据说给的源是国外源，速度慢。国内有很多源可用，网址如下：http://shumeipai.nxez.com/2013/08/31/raspbian-chinese-software-source.html 除此之外，倒是了解了一些些关于远程与vnc。实现这两者需要安装东西，并不是装了系统就可以连远程的。这个百度一下很多教程。 另外是在Linux命令行下的vi(vim)与nano编辑器。相较而言当然是nano好用。用nano编辑/etc/apt/s文件命令：sudo nano /etc/apt/s用vi编辑只需将nano改为vinano内有提示，只需按照提示来就好，而vi就比较复杂。http://shumeipai.nxez.com/2013/12/26/linux-on-vim-editor-tutorials.html该网址内容详尽。注意的是，vi命令模式不是命令行界面，按下esc并不会有界面上的变化，并不是教程错了。 Linux下的文件相关命令]]></content>
      <tags>
        <tag>OS</tag>
        <tag>物联网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OS Lab1]]></title>
    <url>%2F2017%2F10%2F31%2FOS%2FOS-Lab12%2F</url>
    <content type="text"><![CDATA[OSLab1：MIT的Lab1这个作业真的非常令人心烦，现在到了检查作业的紧要关头啦！]]></content>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[first try]]></title>
    <url>%2F2017%2F10%2F29%2Ffirst-try%2F</url>
    <content type="text"><![CDATA[yayi’s new blogwhat !你为什么这么多事啊！？]]></content>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F10%2F29%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[区间划分：贪心算法]]></title>
    <url>%2F2017%2F07%2F21%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%9A%E5%8C%BA%E9%97%B4%E5%88%92%E5%88%86%2F</url>
    <content type="text"><![CDATA[希望自己把这部分和区间调度问题能够结合起来好好考虑下。就酱！ 下面考虑区间划分问题 问题描述如下： 申请i开始时间为Si，结束时间是Fi。 我们有足够多资源，但希望能使用最少的资源接受所有申请。 定义一个申请（区间）集合的深度为通过时间线上任何一点的最大申请（区间）数。 提出：在任何区间划分的实例中，所需的资源数最少是区间集合的深度。这个命题很容易被证明是正确的。再提出另一个问题：使用等于区间深度的资源数一定能够满足接受所有申请的需求吗？ ——哈？这个是没有解决吗？先留着，等我翻一翻资料再说——- 设计算法，把申请按照开始时间排序，按照这个顺序安排申请，把它们安排到不冲突的资源里面。 12345678910将所有申请按开始时间排序，起始时资源数是0;for 申请j=1 to n : while 有未遍历的资源k: if 申请i可以塞进资源k: 把i塞进k; break; if 申请i没分配出去: 申请一个新资源n+1; 把申请i塞进新资源n+1; 资源总数加一个; 这种方法保证了同一个资源分配的申请不会有冲突，而且所需的总资源数不会超过区间深度。而区间深度即为所需资源的最少数量。 实现优化： 对于每一个资源，记录最后一个需求的结束时间。 把资源按照结束时间的先后放入一个优先队列。（优先队列！） 考虑这个算法的时间复杂度。 排序部分有O(nlogn)的时间复杂度 下面部分是线性时间 它应该等同于排序的时间复杂度：O(nlogn)]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计数逆序]]></title>
    <url>%2F2017%2F07%2F21%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E5%88%86%E6%B2%BB%E7%AE%97%E6%B3%95%EF%BC%9A%E8%AE%A1%E6%95%B0%E9%80%86%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[逆序是在排序算法里面常提到的一个词，它是指在与递增序列进行比较时一个序列里i &lt; j且ai &gt; aj时，它们就构成一个逆序对。 计数逆序问题提出的背景是：WEB试图比较用户之间的喜好，当他确定你与某人兴趣相似，便推荐给你那个人浏览的事物。这是一种叫做协同过滤的技术。 找逆序对的一个直观的方式是：进行连线，有交点的两条线段对应两点形成一个逆序，如下： 这样可以清楚地看到逆序对：(1,3),(3,2),(1,5),(2,5),(5,4) 即使不使用分治算法，计数逆序也可以使用遍历的方式进行实现，这时时间复杂度是O(n*n)。这时就想到，排序的工作就是找到所有的逆序对并将它们变成正序，而排序算法最好的时间代价是O(nlogn)。 利用归并排序的思路，对一个序列求其逆序数： 1 5 4 8 10 2 – 6 9 12 11 3 7 可以先求前一部分的逆序数，再求后一部分的逆序数，我们需要考虑的只是如何将两者的逆序数利用起来求出整体的逆序数。 这时求出前一部分逆序数是5，后一部分逆序数是8。 由于每一部分自己内部的逆序数已经被考虑，现在只需考虑两部分之间的逆序数，将每一部分都排序：|3|7|10|14|18|19||-| 2 11 16 17 23 25 这时，以其中一个序列为基准，假设以第一个序列为基准，第二个序列中的每一个元素都从第一个序列的第一个元素开始与之比较，直到找到第一个比这个元素大的元素，之后就可以不用比较了。因为这时已尽可以确定后面的元素都比这个元素大，这个元素的逆序数就可以确定了。 这样，整个序列的逆序数就是这三部分逆序数之和。 经过上述讨论，确定了计数逆序更有效的一种算法： 将序列分成两部分 分别递归求出左右两部分的逆序数 计算两部分之间的逆序数，将他们相加 ，返回总的逆序数并将其排序。 这个方法可达O(nlogn)级别。容易看出，完成计数逆序的过程也就是完成归并排序的过程。 伪代码如下： 1234567891011//Merge and Count伪代码现有两个序列A、Bint count=0;int cura=0,curb=0;while (A、B都不是空): 把A[cura]与B[curb]之间更小的添加到输出表; if(B[curb]更小): count+=A中算A[cura]剩余元素个数; 把较小元素表指针往前移;把另一个非空表中元素添到输出表（不用改变count）;return count与输出表; 12345678910//Sort and Count代码初始一个序列L;if(L.length==1)没有逆序，返回0以及L;else: 把表分两半; A含前n/2个元素，B含剩下的元素; (rA,A)=sort and count(A); (rB,B)=sort and count(B); (r,L)=merge and count(A,B);返回r=rA+rB+r以及排好序的表L;]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分段的最小二乘问题]]></title>
    <url>%2F2017%2F07%2F21%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%9A%E5%9B%BE%E7%9A%84%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[寻找源点到任一个点的最短路径的一个有效算法是Dijkstra算法，下面先简述Dijkstra算法： 给定一个有向图，这个有向图的每条边都有一个非负的权值，现有源点S，则可使用Dijkstra求这个源点S到达这个图中每个点的最短路径。新建一个集合S，如果源点s到一顶点u的最短路径已经被确定，则把u加入到S之中。最初S={s}，d(u)表示已经加入S的一点u的从s到u的最短距离。算法的过程就是遍历图寻找S中任一顶点u与S外任一顶点v使得d(u)+D(u,v)取得最小值，这时将v添加到S中，并使d(v)=d(u)+D(u,v)。循环直到图中的所有顶点都被添加到S之中。可以想到，用这种方法产生出的路径应该是最短路径，利用这件事，在寻找下一个顶点时，可以做一些优化：如上图所示：黑色顶点代表已经添加到S中的点，橙色是这次新加入的点，v是任意一个尚未添加到S中的点。对于一条确定的路径，添加新顶点时只需判断d(原)+l与d(u2)+l6之间的大小关系，取小即可。每添加一个v，都对尚未加入S的每一顶点的d(原)进行更新，取原值或者使用新的值，使其一直保值最短路径状态。 下面给出上图的解答过程：由表可知，只需在上次寻找时将更短的路径存储起来，再下一次寻找时就不需要在此寻找之前的顶点到未添加点的距离，大大节省了计算量。每次被选出的那个顶点所在行的最后一个路径就是由s到达这个顶点的最短路径，数值便是长度。 由这种思想，给出算法的伪代码： 12345678初始时S=&#123;s&#125;，全部顶点集合V;while S!=V: for v in V-S: if(以新节点做中间点更好): update; 选择最小的距离所对应的v; 将v加入S;endwhile; 分析该算法的时间复杂度：若不做优化，时间复杂度是O(mn)级别，若采用优先队列以d+l排序，则可达到O(mlogn)级别。（关于时间复杂度，上网搜了一下，很多说法都不一样，有个看起来挺靠谱的这样讲：邻接矩阵：O(n*n)；邻接表：O(n*n)；邻接表+binary heap O((n+m)logn)；邻接表+fibonacci heap O(m+nlogn) ）]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分段的最小二乘问题]]></title>
    <url>%2F2017%2F07%2F21%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E5%88%86%E6%AE%B5%E7%9A%84%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[终于不是在网上发表，可以直接用截图了！哈！ 在平面上有n个点，他们是$(x_1,y_1),…(x_n,yn)$且x1&lt;…&lt;xn。现用一条直线L:y=ax+b来对他们进行拟合。对误差这样定义：$SSE=\sum{i=1}^n\ (y_i-ax_i-b)^2$ SSE是关于a、b的函数，分别对a、b求偏导，可得出当SSE最小时：123a=\frac&#123;n\sum_i\ x_iy_i-(\sum_i\ x_i)(\sum_i\ y_i)&#125;&#123;n\sum_i\ x_i^2-(\sum_i\ x_i)^2&#125;b=\frac&#123;\sum_i\ y_i-a\sum_i\ x_i&#125;n 实际上，对于一批点，可以以很多条线段进行拟合，通常使用罚分度量函数 $E+cL(c&gt;0)$ 来在所有直线上的平方误差之和E与直线数目L之间找到一个平衡。]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区间调度：贪心算法与动态规划]]></title>
    <url>%2F2017%2F07%2F21%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2F%E5%8C%BA%E9%97%B4%E8%B0%83%E5%BA%A6%EF%BC%9A%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E4%B8%8E%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92%2F</url>
    <content type="text"><![CDATA[在介绍区间调度问题之前，首先要对贪心算法做一个简单的介绍。贪心算法产生的解每前进一步，都做得至少与其他其他解一样好。如果某一个问题可以用贪心算法得到解决，那么这个问题中一定存在一个局部判断规则可以用来构造问题的最优解。 无权区间调度问题： 问题描述如下：给定一个时间段，在这个时间段上有很多申请，但是每个时间只允许至多一个申请生效。 申请i的开始时间是Si，结束时间是Fi。 如果两个申请的时间区间不相交，那么称这两个申请相容。 我们需要尽可能多的接受申请。 针对这种要求，我们提出如下方案： 使Si更小的申请尽可能通过 使时间需求更小的申请尽可能通过 使具有不相容申请更小的申请尽可能通过 使Fi更小的申请尽可能通过 下面对着四种方案进行一一讨论： 第一种方案：假如我们尽可能地接受更早开始的申请，我们可以更早的开始使用我们的资源，但是这种方式显然不能得到最大相容类，任举一反例如下： 从这张图我们可以清楚地看到，即使黄色申请开始时间比蓝色申请更早，但我们更倾向于接受三个蓝色的申请，它们构成了一个最大相容类。故：不可以以开始时间更早作为接受或拒绝申请的标准，这种方案是不行的。 第二种方案：假如我们要尽可能接受时间需求更小的申请，我们可以缩减每个申请需要的时间，似乎可以增加容纳申请的个数。但是，这种方案仍然易于给出反例： 显而易见的，蓝色申请占据时间更小，但是我们仍然希望接受两个粉色的申请，它们构成了最大相容类。即：这种方案被否定。 第三种方案：如果我们尽可能接受拥有更小不相容申请的申请，可能可以塞下更多的申请，但是真的是如此吗？一个反例如下： 即使黄色申请更符合该方案的条件，但我们并不想选择黄色申请。在这个反例里面我们可以看到：正确结果里被选中的申请可能会与大量彼此重叠的申请重叠，从而使不相容申请的个数增加，但是这些重叠的数目对问题的求解并没有什么贡献。故：这种方案被否定。 第四种方案：在这种方案的设定下，最先结束的申请被优先通过，可以使资源更早地被释放，更好的安排后面的需求。这其实是一种贪心算法，它的具体步骤可以描述为： 1234567初始时R时所有申请的集合，A是一个空集合;while(R非空): 选择一个最早结束的申请i属于R; 把i添加到A里; 删除R里所有与i不相容的申请;endwhile;return A; 在未能举出反例的情况下，我们尝试证明这种方案的正确性：令B是一个最优的选择的申请的集合，下面将证明|A|=|B|。贪心算法保证：A中的每个区间结束得至少与B中对应区间一样早。对A中的申请i，在B中对应申请j，它们同处于区间r，则有：F(ir)&lt;=F(jr)。归纳法：当r=1时，显然论断是真；假设r-1的时候论断为真而r时论断为假，即：F(ir-1)&lt;=F(jr-1)且F(ir)&gt;F(jr)。情况即如下图： 从上图可以看出，假如r-1时满足条件，则贪心算法将会把jr选入集合A而不是把ir选入，产生矛盾！经过简单的证明，我们相信：选择最早结束的申请可以令我们得到一个申请的最大相容类。 下面我们考虑这个算法的时间代价： 构造一个n长度的数组S[n]，在S[i]中存储Si。 对所有n个申请按结束时间进行排序，这部分耗时O(nlogn)。 每一次选择出新的申请，按结束时间排序查找S[n]选出第一个S[i]&gt;F(j)的申请，加入再重复寻找。由于最终遍历了整个S[n]，故这部分代价是O(n)。 故这个算法可达到O(nlogn)级。 这是最简单的区间调度问题，在实际情况中可能出现更复杂的情况。比如申请可能随时在增减、每个申请占据了不同的权值等。 与区间调度问题近似的有区间划分问题。区间调度问题在有限资源的情况下接受最多申请，而区间划分问题希望在接受所有申请的情况下使用最少的资源。 (如果，比如，给了两间教室，有一堆申请，在这两个教室分配申请，申请可以取舍。这种问题是可以连续使用两次区间调度问题的算法的嘛？) 带权的区间调度 很显然，在区间调度带权之后，上述的贪心算法就不能一直产生正确的结果，一个显然的反例如下： 定义p(j)，它的值是i，i是使得i与j不相交的i&lt;j的最大区间编号。如果j左边没有相容区间，p(j)=0。 对一个区间集合的最优解O的求解变成： 如果区间$n\in O$,那么O一定包含对区间集{1,..p(n)}求出的的最优解。 如果区间$n\notin O$，那么O就包含对区间集{1,…n-1}求解最优解。]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[miniumtree]]></title>
    <url>%2F2017%2F07%2F21%2F%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%2Fminiumtree%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118#include&lt;iostream&gt;using namespace std;//定义了一个类，包含起点与终点以及权值class Edge &#123;public: int startnode; int endnode; int weightvalue; void GetValue(int a, int b, int c);&#125;;void Edge::GetValue(int a,int b,int c) &#123; startnode = a; endnode = b; weightvalue = c;&#125;//交换函数，交换两个Edge值bool swap(Edge &amp;a, Edge &amp;b) &#123; Edge tmp = a; a = b; b = tmp; return true;&#125;//快排函数，完成按weightvalue对Edge数组由小到大排序的功能。s时开始点的坐标，e是结束点的坐标void quickSort(Edge*origin,int s,int e) &#123; if (s &gt;= e)return ;//如果起始&gt;=结束，return //选择中间点作为枢轴 swap(origin[(s + e) / 2], origin[e]); //lastlittle记录了上次那个比枢轴更小的数的位置的下一个位置 int lastlittle = s-1 ; //遍历，如果遇到比枢轴大的不予理睬，否则与上次记录的位置（一定比枢轴更大）上的数交换 //完成后将在主轴两侧分别是比枢轴大和比枢轴小的数 for (int i = s; i &lt;= e; i++) if (origin[i].weightvalue &lt;= origin[e].weightvalue) &#123; swap(origin[i], origin[++lastlittle]); &#125; //递归继续进行排序 quickSort(origin, s, lastlittle - 1); quickSort(origin, lastlittle+1, e);&#125;//使用DFS思想判断一个图中是否有环void isCircle(int**rect, int s,int n,int &amp;lastflag,int times) &#123; rect[s][n] = times;//node结点设置为已经被遍历 int now = s; //从s结点开始进行深度优先的遍历 while(now&lt;n) &#123; if (lastflag == 1)return;//已经找到了环，不必继续遍历下去 int flag = 0; for (int i = 0; i &lt; n; i++) if ((rect[s][i] &lt;=times) &amp;&amp; (rect[i][s] &gt;0)) &#123; rect[s][i] = rect[i][s] = times+1;//为防止对称的影响，总是将两个一同变化 now = i; flag = 1; break; &#125; //如果没有找到后续未遍历节点，就退出对这个该节点的寻找 if (flag==0)break; if (rect[now][n] == times) &#123; lastflag = 1;//若找到了环，就把标志位置为1,退出。 return; &#125; isCircle(rect, now, n, lastflag,times);//否则接着遍历 &#125;&#125;int main() &#123; int totalweight = 0;//总的weight值 int n, m; cin &gt;&gt; n &gt;&gt; m; //开一个二维数组用于存图并对之进行初始化 int**isin = new int*[n]; for (int i = 0; i &lt; n; i++) isin[i] = new int[n+1]; for (int i = 0; i &lt; n; i++) for (int j = 0; j &lt;= n; j++) isin[i][j] = 0; //Edge类用来存图并方便地完成weightvalue由小到大的排序 Edge*alledges = new Edge[m]; int startn, endn, weightn; for (int i = 0; i &lt; m; i++) &#123; cin &gt;&gt; startn &gt;&gt; endn &gt;&gt; weightn; startn--; endn--; alledges[i].GetValue(startn, endn, weightn); &#125; //完成数据的初始化 //快排完成排序 quickSort(alledges, 0, m - 1); //从最小的weightvalue的边开始往最小生成树里面添加 int whichedge = 0; //当节点还没全添加进去而且边的个数没有越界 while (whichedge &lt; m) &#123; //现在要考虑的边的起始与结束点 int s = alledges[whichedge].startnode; int e = alledges[whichedge].endnode; isin[s][e] = 1; isin[e][s] = 1; //先将它们添加到图上 //调用isCircle函数，判断添加了该边之后会不会构成圈 int iscircle = 0; isCircle(isin, s, n, iscircle,whichedge+1); //若未构成圈 if (!iscircle) &#123; //增加权值总数 totalweight += alledges[whichedge].weightvalue; &#125; //否则这个边不被需要，从图上删去 else &#123; isin[s][e] = 0; isin[e][s] = 0; &#125; //考虑下一条边 whichedge++; &#125; //输出总权值 cout &lt;&lt; totalweight;&#125;]]></content>
      <categories>
        <category>算法与数据结构</category>
      </categories>
      <tags>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[绘图（4]]></title>
    <url>%2F2017%2F05%2F27%2FMFC%E5%9F%BA%E7%A1%80%2FMFC%EF%BC%9A%E7%BB%98%E5%9B%BE%EF%BC%884%2F</url>
    <content type="text"><![CDATA[第四章啦~今天多少有点愧疚呢。 一、设备环境类设备文本用来实现程序的可视化输出，它提供一张画布。图形既可以通过屏幕显示，也可以通过打印机等设备输出。 这里不太清楚，回去需要看书 以下是一些设备环境类：CDC：MFC的设备文本基类CClientDC：客户区（不包括边框、标题栏、菜单栏）的设备文本类CWindowsDC：程序窗口的设备文本类CPaintDC：OnPaint函数使用的设备文本类 为了说明上述各个类得到的区域，下面举一个具体例子： 在C×View的类里面写一个鼠标左键的点击消息，当点击时，画一条线。 首先是最常用的：CDC1234CDC*pDC=GetDC();pDC-&gt;MoveTo(0,0);pDC-&gt;LineTo(point);ReleaseDC(pDC); 最终运行得到的结果是： 1234void C×View::OnLButtonDown(UINT nFlags,CPoint point)&#123; CClientDC dc(this); dc.MoveTo(0,0); dc.LineTo(point); 注意CClientDC对象的声明方法：CClientDC dc(this)，获得客户区的dc，也就是视图的dc。MoveTo , LineTo函数的参数既可以是CPoint也可以是两个int型变量。注意一定是int而不可以是double。 最终的结果： 可以看出，CClientDC得到的是客户区。 如果在上述代码中这样创建CClientDC：CClientDC dc(GetParent());得到的dc就应该是视图的父窗口（即边框窗口），最终结果是： 这里是MFC标准视图，对边框窗口就在那里，如果不清楚，可以看这个图：这是VS2008视图：（编辑视图怎么回事，连截屏不都能，一刷新视图区的东西就都没了(创建延迟截图吧亲爱的）。另：继承于哪个视图基类可不是把例CEditView都改成CView就好了，它们的初始化过程狮虎是不一样的！！！） 123CWindowDC dc(this);dc.MoveTo(0,0);dc.LineTo(point); 注意CWindowDC的对象创建：CWindowDC dc(this) this为参数得到的结果与ClientDC以this为参数得到的结果相同。 以GetParent()为参数时，得到的结果是： 可以看到，这里的(0,0)似乎并不正确，其实，这里得到的dc是整个程序窗口的dc，即这里的(0,0)是你的主边框左上角： 即使这样，也应该说明：这里的dc绘图将会把传递进来的point当作为整个程序窗口的point坐标。但是OnLButtonDown传递进来的point是视图区的坐标。故这时线的另一端并不是在鼠标点击的位置。 如果参数是：GetDesktopWindow()，得到的应该是整个电脑屏幕，这时的结果是： 同理，这时线的另一端也不会是鼠标点击的位置。 二、绘图基本方法首先应该使用上述方法取得设备环境类对象或者对象指针。 1. 几个必要的类： CPoint：封装了POINT结构，定义点的坐标。其中x,y都是int型的数据。CRect：封装了RECT结构，定义一个矩形区域，其中有四个int成员：left , right , top , bottom .CSize：封装了SIZE结构，定义了矩形区域的大小，成员有两个int型数据cx , cy . 这三个类除了对应结构中仅有的成员变量以外，还有其他成员函数。 2. 绘图工具：CDC提供了绘图的工具，比如CPen , CBrush , CFont 等，它们的基类是CGDIObject。默认的画笔是宽度为一个像素的黑色画笔，画刷是白色不透明全填充画刷。 颜色值可由两种方式指定： 是用RGB(Red,Green,Blue)，对应颜色的位置可以填上0-255包括两端的任一整数值用于指定颜色。其中0是最浅，255是最深。 直接使用八位十六进制整数值：0x00FFFFFF。前两个0是固定值，紧接着两个F指蓝色的深度，之后是绿色，最低为两个指红色。其顺序与第一种方法正好相反。 系统内置下表列出一些预定义的画刷与画笔： 类型 说明 BLACK_BRISH 黑色画刷 DKGRAY_BRUSH 深灰色画刷 GRAY_BRUSH 灰色画刷 LTGRAY_BRUSH 浅灰色画刷 WHITE_BRUSH 白色画刷 HOLLOW_BRUSH 透明画刷 NULL_BRUSH 空画刷 BLACK_PEN 黑画笔 WHITE_PEN 白画笔 NULL_PEN 空画笔 可以使用SelectStockObject(TYPE)来选择画刷与画笔，注意一定在画图之前选择，一旦选择该画刷将起作用直到下一个选择画刷语句。 目前认为：空画刷与透明画刷是一样的，都是不会填充，只画边框。 自定义除了系统给的，还提供了函数允许用户自定义自己的画刷与画笔。 画笔创建一个新的CPen对象：123456789CPen newpen(PS_SOLID,5,RGB(255,0,0));//或是CPen newpen1;newpen1.CreatePen(PS_SOLID,5,RGB(225,0,0));//或是CPen*newpen2=new Cpen();//一定要初始化！！！newpen2-&gt;CreatePen(PS_SOLID,5,RGB(255,0,0));//或是CPen*newpen3=new CPen(PS_SOLID,5,RGB(255,0,0)); CPen的构造函数有三个参数：画笔风格、画笔宽度、画笔颜色。 自定义画笔选择不同于内置画笔，这里使用另一个函数:SelectObject()，具体参数应是：pDC-&gt;SelectObject(&amp;newpen)或pDC-&gt;SelectObject(&amp;newpen1)或pDC-&gt;SelectObject(newpen2)或pDC-&gt;SelectObject(newpen3)。 上述的三种选择方式返回值是以前的画笔类型的指针。例如，当第二次选择时，返回的是第一次选择的画笔类型指针。 一些画笔风格： 风格 说明 PS_SOLID 实线 PS_DASH 虚线 PS_DASHDOT 点划线 PS_DASHDOTDOT 双点划线 PS_DOT 点线 PS_NULL 空画笔 下面给出一个具体例子：123456789//在OnDraw中CPen *NewPen = new CPen();CPen *pOldPen;NewPen-&gt;CreatePen(PS_SOLID,1,RGB(255,0,0));pOldPen=pDC-&gt;SelectObject(NewPen);pDC-&gt;Ellipse(150,100,250,200);pDC-&gt;SelectObject(pOldPen); pDC-&gt;MoveTo(150,100);pDC-&gt;LineTo(250,200); 最终还是将宽度改成了1.因为发现宽度较大的时候有的风格体现不出来。 要说明的是返回值的问题，第一次选择的返回值是上一次的选择即默认画笔。由于一旦选择了画笔/画刷，就会一直起作用，故一般会设置一个pOldPen的指针，用来保存默认画笔信息，在函数内容结束的最后一句话将画笔重新设置为默认画笔。 换一个类型，使用PS_DOT，并且去掉二次选择画笔的过程。 PS_DASH： PS_DASHDOT： PS_DASHDOTDOT： 到了这里已经可以确定，DASH与DOT都是虚线，但是DASH较DOT每条联通线都更宽一点。DASHDOT是二者一比一的结合，DASHDOTDOT是一比二的结合。空画笔就是….什么都没有。 ####画刷 与画笔直接简单地确定风格不同，画笔的不同风格需要调用不同的函数： 实心SOLID：CreateSolidBrush(COLORREF crColor);网格HATCHED：CreateHatchBrush(int nIndex,COLORREF crColor);模式PATTERNED：CreatePatternBrush(CBitmap*pBitmap); 这也意味着不能直接在声明CBrush对象的时候就创建一个自定义画刷。 其中对于网格的第一个参数，nIndex是指填充的样式，内置的填充样式如下： 样式 说明 HS_CROSS 十字线 HS_HORIZONTAL 水平线 HS_VERTICAL 垂直线 HS_FDIAGONAL 斜线 HS_BDIAGONAL 反斜线 HS_DIAGCROSS 斜十字线 下面以一个具体例子来了解网格的不同风格： 1234CBrush brush;brush.CreateHatchBrush(HS_CROSS,RGB(255,0,0));pDC-&gt;SelectObject(&amp;newBrush);pDC-&gt;Rectangle(100,100,200,200); 在这里同样应在函数最后将画刷信息重置为默认。 HS_CROSS当改变了画笔的宽度之后： 内部网格线的宽度并没有变。也就是说：内部的填充样式是内置好的，不会随着画笔的变化而变化。 HS_FDIAGONAL HS_BDIAGONAL HS_DIAGCROSS 对于SOLID填充，就是纯色填充，不再赘述。 PATTERNED填充是位图填充：1234CBitmap *bitmap=new CBitmap();//一定初始化！！！bitmap-&gt;LoadBitmapW(IDB_RIDDLE);CBrush newbrush;newbrush.CreatePatternBrush(bitmap); 或者可以声明CBitmap bitmap，并在CreatePatternBrush函数中用参数&amp;bitmap。 （我改变了Bitmap，怎么在运行的时候就是没办法载入新的bitmap呢！） 结果：（最后那句是酷狗的桌面歌词啦） xiuzheng3. 绘图函数常用的绘图函数 设置像素：SetPixel改变当前位置：MoveTo画直线：LineTo画弧线：Arc画矩形：Rectangle圆角矩形：RoundRect画椭圆：Ellipse画饼图：Pie画多边形：Polygon不绘制边框，只用画刷填充矩形： FillRect不填充内部，只用画刷绘制边框：FrameRect 绘图函数中涉及到的坐标都是逻辑单位，默认左上角(0,0)，往右x++，往下y++。逻辑单位是像素。 下面举例子具体说明函数参数与功能。 矩形与圆角矩形123//矩形与圆角矩形pDC-&gt;Rectangle(100,100,300,200);//左上角点(100,100)，右下角点(300,200)pDC-&gt;RoundRect(100,100,300,200,100,40);//对应矩形的参数，往x方向延伸的长度，往y方向延伸的长度。 这两个函数分别有另一种参数形式：Rectangle(LPCRECT lpRect)以及RoundRect(LPCRECT lpRect,POINT point)。CRect封装了LPCRECT，第一个参数可以用CRect。CPoint封装了POINT，第二个参数也可以用CPoint。 结果： 线段与弧线与矩形123456pDC-&gt;Rectangle(100,100,300,200);pDC-&gt;MoveTo(200,150);//确定矩形的中心点pDC-&gt;LineTo(300,175);//截止直线所在线段终点pDC-&gt;MoveTo(200,150);pDC-&gt;LineTo(125,125);//另一截止直线所在线段终点（不一定非在矩形边上）pDC-&gt;Arc(100,100,300,200,300,175,125,125);//外接矩形参数，两条截断线的终点 它们分别有另一种参数形式：MoveTo(POINT point); , LineTo(POINT point); , Arc(LPCRECT lpRect,POINT ptstart,POINT ptend);同理，可以使用CRect与CPoint。 结果： 饼图与矩形12pDC-&gt;Rectangle(100,100,300,200);pDC-&gt;Pie(100,100,300,200,300,100,100,100);//对应外接矩形参数，两个截断直线所在线段终点。（类似弧线） Pie也有另一种参数形式：Pie(LPCRECT lpRect,POINT ptStart,POINT ptEnd); 结果： 多边形12345678910CPoint point[4];//4个顶点的对应坐标point[0].x=100;point[0].y=100;point[1].x=200;point[1].y=200;point[2].x=200;point[2].y=100;point[3].x=100;point[3].y=200;pDC-&gt;Polygon(point,4);//顶点，个数。按顺序连接。 Polygon没有其他参数列表。但有必要说明一下，上述参数列表是：const POINT *point,int nCount 结果： FillRect123CBrush newbrush;newbrush.CreateHatchBrush(HS_FDIAGONAL,RGB(255,0,0));pDC-&gt;FillRect(CRect(100,100,300,200),&amp;newbrush); FillRect上述参数列表是：LPCRECT lpRect,CBrush*pBrush，它只有这一个参数列表。 结果： FrameRect123CBrush NewBrush;NewBrush.CreateSolidBrush(RGB(255,0,0));pDC-&gt;FrameRect(CRect(100,100,300,200), &amp;NewBrush); FrameRect只有这一个参数列表。它是：LPCRECT lpRect,CBrush*pBrush 结果： 4. 绘图模式绘图模式指定绘图工具的颜色和显示颜色的处理方式。SetROP2(int nDrawMode); 常用绘图模式： 模式 说明 R2_COPYPEN 绘图工具颜色 R2_NOT 背景颜色取反 R2_XORPEN 背景与绘图工具颜色异或 R2_COPYPEN不理会背景颜色，Pen/Brush是什么颜色就画成什么颜色R2_NOT不理会Pen/Brush本身的颜色，背景是什么颜色，就将颜色对应的二进制数按位取反，用这个新颜色。R2_XORPEN将Pen/Brush的颜色与背景颜色对应的二进制数按位异或，得到的新颜色。例如：黑色(0,0,0)取反是白色(255,255,255)，白色与蓝色(0,0,255)异或是黄色(255,255,0)。 CRgn与区域CRgn类封装区域即绘图的范围，有： CreateRectRgn CreateEllipseRgn CreatePolygonRgn CombineRgn：将新的区域合并 CDC中的函数： FillClipRgn PaintRgn这两者填充区域（yong是什么鬼） SelectClipRgn：设置剪裁区域 SelectObject： 将区域选入设备文本 下面以一个例子来具体说明某些函数的作用： 12345678pDC-&gt;DrawFocusRect(CRect(10,10,200,200));CRgn NewRgn;NewRgn.CreateRectRgn(10,10,200,200);pDC-&gt;SelectObject(&amp;NewRgn);pDC-&gt;MoveTo(0,100);pDC-&gt;LineTo(300,100);pDC-&gt;MoveTo(100,0);pDC-&gt;LineTo(100,300); 这段代码得出： 外面的虚线是DrawFocusRect画出的线，SelectObject使得画布外面的线全部都消失不见了。SelectClipRect与SelectObject的效果一样。 映射模式绘图函数中的坐标是逻辑坐标而鼠标消息处理函数中的坐标是设备坐标，它们不同的时候就会使绘图的位置发生偏差。 映射模式定义了逻辑坐标与设备坐标之间的单位关系，共有两种模式：比例因子固定的约束映射模式和比例因子以及轴向不固定的非约束映射模式。 函数：SetMapMode：用来设置映射模式。 MM_TEXT：默认映射模式，每个单位映射成一个像素。X向右，Y向下。 MM_HIENGLISH：每个单位映射成0.001英寸，X向右，Y向上。 LPtoDP：逻辑坐标转化为设备坐标 DPtoLP：设备坐标转化为逻辑坐标 举一个例子说明MM_HIENGLISH：12345678910CRect rect;GetClientRect(&amp;rect);pDC-&gt;SetMapMode(MM_HIENGLISH);pDC-&gt;SetViewportOrg(rect.right/2,rect.bottom/2); //设置坐标原点pDC-&gt;MoveTo(-20,0);pDC-&gt;LineTo(100,0); pDC-&gt;MoveTo(0,-20);pDC-&gt;LineTo(0,100); CPoint pt(100,100); pDC-&gt;Ellipse(pt.x-50,pt.y-50,pt.x+50,pt.y+50); 最终运行结果： 如果以默认的绘图模式，结果是： 则可以看到MM_HIENGLISH的绘图模式缩小了一个单位的距离，并且改变了Y轴的方向。 三、文本的绘图文本处理函数文本输出函数： TextOutW：标准的文本输出DrawTextW：格式化文本输出ExtTextOutW：扩展的文本输出TabbedTextOutW：带制表符的文本输出 文本属性设置函数： SetBkMode：背景模式SetBkColor： 背景颜色SetTextColor：文本颜色SetTextAlign：文本对齐方式SetTextCharacterExtra：字符间隔值 这里介绍的参数列表与作用都是在pDC-&gt;下。 TextOutW:两种参数列表： int x,int y,const CString &amp;str int x,int y,LPCTSTR lpszString,int nCount 通常在MessageBox中写字符串的时候，总是在前面加上L，这个L就相当于是整个是LPCTSTR型变量。nCount是指一共有nCount个空位置。如果给的串位数不够就补上（其实我不知道补的是什么），如果串多了就截取前nCount个字符显示。 例如：TextOutW(100,100,L&quot;hello world!&quot;); DrawTextW:两种参数列表： const CString &amp;str,LPRECT lpRect,UINT nFormat LPCTSTR lpszString,int nCount,LPRECT lpRect,UINT nFormat lpRect指向rect结构体，指定了文本格式化的矩形区域。同样地，这里可以使用CRect的uFormat是格式化标记。以下是一些格式化标记：DT_CALCRECT：使DrawText函数计算出输出文本的尺寸。如果输出文本有多行，DrawText函数使用lpRect定义的矩形的宽度，扩展矩形的底部以容纳输出文本的最后一行。如果输出文本只有一行，矩形的右边界改变，以容纳下正文行的最后一个字符。出现上述任何一种情况，返回格式化文本的高度，而不是绘制文本。DT_CENTER：使文本水平居中显示。DT_VCENTER：使文本垂直居中显示。该标记只在单行文本输出时有效，所以它必须与DT_SINGLELINE结合使用：DT_VCENTER|DT_SINGLELINEDT_SINGLELINE：单行显示文本，回车和换行符都不换行。 使用格式化标记的时候一定要小心，不然你都找不出来到底是哪里错了。比如我，应该是一直将字符输出到了视图之外，一直以为输不出… example: pDC-&gt;DrawTextW(L&quot;shen&quot;, rect, DT_SINGLELINE | DT_CENTER|DT_VCENTER); SetBkMode:只有一种参数列表：int nBkMode nBkMode有两种取值：OPAQUE和TRANSPARENT。OPAQUE的方式是用当前背景的画刷的颜色输出显示文字的背景TRANSPARENT是使用透明的输出，也就是文字的背景不改变 SetBkColor:一种参数列表：COLORREF crColor SetTextColor:COLORREF crColor SetTextAlign:UINT nFlags 以下是一些标志位：TA_BASELINE：参考点将在文本的基础线。TA_BOTTOM：参考点将在边界矩形的底部边缘。TA_TOP：参考点将在边界矩形的顶边。TA_CENTER：参考点将水平地的边界矩形的中心对齐。TA_LEFT：参考点将在边界矩形的左边缘。TA_RIGHT：参考点将在边界矩形的右边缘。TA_NOUPDATECP：当前位置每个文本输出调用后没有更新。参考点被传递到文本输出功能。TA_UPDATECP当前位置每个文本输出通话后更新。当前位置被用作参考点。当当前字体具有垂直默认基线，与汉字，下面的值必须被用来代替TA_BASELINE和TA_CENTER。VTA_BASELINE：参考点将在文本的基础线。VTA_CENTER：参考点将垂直的边界矩形的中心对齐。 默认值是TA_LEFT，TA_TOP和TA_NOUPDATECP 这部分部分摘自微软msdn文档 SetTextCharacterExtra:int nCharExtra 上述的文本属性设置函数需要在文本输出函数之前进行调用，类似于笔刷画图。 字符属性字符属性(TEXTMETRIC)指字符大小与字符间距。其声明：1234567typedef struct tagTEXTMETRIC&#123; LONG tmHeight;//字符高度 LONG tmAscent;//字符上升高度（英文 LONG tmDescent;//字符下降高度（英文 LONG tmExternalLeading;//行间距 ...&#125;TEXTMETRIC; 可使用GetTextMetric来获得TEXTMETRIC的指针值。pDC-&gt;GetTextMetric(&amp;tm); 可使用GetTextExtent(const CString &amp;str)获得str的Size，Size中封装了str的宽度(cx)与高度(cy)。CSize size=pDC-&gt;GetTextExtent(L&quot;halo&quot;); 字体内置字体：在MFC库中存有一些内置字体：|字体类型|说明||:–:|:–:||SYSTEM_FONT|系统字体||SYSTEM_FIXED_FONT|固定宽度系统字体||ANSI_FIXED_FONT|ANSI固定宽度系统字体||ANSI_VAR_FONT|ANSI可变宽度系统字体||DEVICE_DEFAULT_FONT|设备缺省字体||OEM_FIXED_FONT|OEM固定宽度字体| 内置字体对象的选择同样使用函数SelectStockObject()，其参数是字体类型。例：pDC-&gt;SelectStockObject(SYSTEM_FONT); 自定义字体：自定义字体有两种方式： CreateFont函数 CreateFontIndirect函数 第一种方法是先自定义一个结构变量LOGFONT，使用它决定字体的参数，随后调用函数：CreateFont(LOGFONT*lf);12345678910111213141516typedef struct tagLOGFONT&#123;LONG lfHeight;//字体高度LONG lfWidth;//字体宽度LONG lfEscapement;//字体逆时针旋转角LONG lfOrientation;LONG lfWeight;//字体粗细BYTE lfItalic;//斜体BYTE lfUnderline;//下划线BYTE lfStrikeOut;//删除线BYTE lfCharSet;//字符集，如：GB2313_CHARSETBYTE lfOutPrecision;BYTE lfClipPrecision;BYTE lfQuality;BYTE lfPitchAndFamily;//字符间距TCHAR lfFaceName[LF_FACESIZE];//所用字体名&#125;LOGFONT; 对于该结构体其他参数更为详尽的介绍，参照百度百科：LOGFONT。 第二种方式是直接调用函数CreateFontIndirect，这个函数的参数共有14个，正好按顺序对应LOGFONT结构体中的变量。 选择自定义字体使用函数SelectObject(CFont font); 四、位图的处理BMP是与硬件无关的图像格式，采用位映射存储方式，除了图像深度可选以外，不使用其他压缩。图像深度包括：1位（单色），4位（16色），8位（256），24位（16M）。BMP图像结构包括文件头（文件类型、文件大小、起始位置等），信息头（图像大小、压缩方法等）以及颜色表与位图数据。 1. 位图填充：使用位图首先应该使用函数LoadBitmap(ID)从资源装载位图。 CDC提供了用于传递图像数据的函数 PatBlt：用选定画刷填充一个矩形 BitBlt：将图像输出到指定位置 StretchBlt：可改变图像大小的BitBlt不能在OnDraw中写LoadBitmapW，会崩溃的。 对画刷填充矩形，有一些内置的模式：|填充参数|说明||:–:|:-:||BLACKNESS|黑色填充目标区域||WHITENESS|白色填充目标区域||PATCOPY|画刷复制到目标区域||PATINVERT|画刷异或到目标区域||DSTINVERT|目标区域取反| 下面是一个PalBlt的例子： 123456789CBitmap bm;bm.LoadBitmap(IDB_MYBITMAP);//与对应位图相关联CBrush brush;brush.CreatePatternBrush(&amp;bm);pDC-&gt;SelectObject(brush);//创建模式画刷并选择CRect rect;GetClientRect(&amp;rect);//获得客户区pDC-&gt;PalBlt(0,0,rect.right,rect.bottom,PATCOPY);bm.DeleteObject(); 代码运行后，将整个位图无变化地复制粘贴过来。如果触到边界，就截断，当把边界往后拉的时候，以后的图又会显现出来。再往后拉，是另一张图的复制粘贴。 PalBlt(int x,int y,int nWidth,int nHeight,DWORD dwRop);x,y是填充矩形的起始坐标，nWidth是矩形向右延伸长度，nHeight是矩形向下延伸长度，这四个参数完成对矩形的选取。dwRop是填充参数，是两字节的整型。 如果填充参数取BLACKNESS，就是满屏黑色，WHITENESS满屏白色。PATINVERT与DSTINVERT类似，将位图异或背景色/取反背景色再填充。 BitBlt与ScretchBlt的填充模式： 填充参数 说明 SRCCOPY 源区域直接填充目标区域 SRCAND 源区域与目标区域与 SRCPAINT 源区域与目标区域或 SRCINVERT 异或 下面是BitBlt的例子： 123456789CBitmap bm;bm.LoadBitmap(IDB_MYBITMAP);//Load位图CDC MemDC;MemDC.CreateCompatibleDC(pDC);//一个具有指定设备兼容的存储器设备上下文MemDC.SelectObject(&amp;bm);BITMAP info;//包含了位图数据的结构体bm.GetBitmap(&amp;info);pDC-&gt;BitBlt(0,0,info.bmWidth,info.bmHeight,&amp;MemDC,0,0,SRCCOPY);bm.DeleteObject(); 更多关于CreateCompatibleDC的信息，访问Windows开发人员中心.aspx)。 最后的执行结果是将对应位图输出到指定位置。没有其他位图再出现。 BitBlt(int x,int y,int nWidth,int nHeight,CDC*pSrcDC,int xSrc,int ySrc,DWORD dwRop);(为什么我的位图没办法编辑了？)与PalBit一样的参数意义也相同，xSrc,ySrc选择了位图的起始坐标，以此坐标作为新的位图的左上角坐标，pSrcDC指的就是与位图相关联的设备环境。 下面是ScretchBlt例子： 将上述代码中BitBlt句改为：pDC-&gt;StretchBlt(0,0,info.bmWidth/2,info.bmHeight/2,&amp;MemDC,0,0,info.bmWidth,info.bmHeight,SRCCOPY); 它比BitBlt多了两个参数。同样的，矩形选择、设备环境选择、左上角坐标选择，接下来多出的两个参数可以完成对位图的截取。 这个例子输出来之后应该是在矩形(0,0,info.bmWidth/2,info.bmHeight/2)中输出完整的位图。 六、图标的处理图标Icon是一种特殊的位图，与位图不同的是，图标的大小是固定的。CWinApp提供LoadStandardIcon加载系统预定义的图标，也提供LoadIcon加载用户自定义图标。 系统预定义图标： 预定义图标宏 说明 IDI_APPLICATION 默认图标 IDI_ASTERISK 信息图标 IDI_EXCLAMATION 惊叹号图标 IDI_HAND 严重警告图标 IDI_QUESTION 问号 一个显示图标的例子： 123456HICON icon1,icon2;icon1=AfxGetApp()-&gt;LoadStandardIcon(IDI_QUESTION);icon2=AfxGetApp()-&gt;LoadIcon(IDI_MYICON);CRect rect;GetClientRect(&amp;rect);pDC-&gt;DrawIcon(rect.right/2,rect.bottom/2,icon);//画图标，比位图简单多了！ 七、光标操作光标cursor用于显示鼠标操作时鼠标的位置与显示形状，CWinapp提供了函数LoadStandardCursor用于加载系统预定义光标，也提供了LoadCursor用于加载用户自定义光标，SetCursor用于设置光标形状。 系统预定义的光标： 光标类型 说明 IDC_ARROW 箭头 IDC_CROSS 十字光标 IDC_WAIT 沙漏光标 IDC_IBEAM 输入光标 IDC_SIZE 装入方框 IDC_ICON 空肖像 IDC_UPARROW 垂至箭头 IDC_SIZEALL 四向箭头 IDC_SIZENWSE 左上右下角双箭头 IDC_SIZENESW 右上左下角双箭头 IDC_SIZEWE 水平双箭头 IDC_SIZENS 垂直双箭头 下面是一个光标操作的例子： 12345678910//在OnButtonDown消息函数中SetCapture();//设置鼠标捕捉到属于当前线程指定的窗口。当鼠标被捕获，菜单热键和其他键盘快捷键不起作用。 HCURSOR cursor;cursor=AfxGetApp()-&gt;LoadStandardCursor(IDC_CROSS);//cursor=AfxGetApp()-&gt;LoadCursor(IDC_MYCURSOR);SetCursor(cursor);//设置光标CRect rect;GetClientDC(&amp;rect);ClientToScreen(&amp;rect);//将客户区坐标转化为屏幕坐标。ClipCursor(&amp;rect);//限制所述光标在屏幕上的矩形区域。 更多关于SetCapture的信息，访问Windows开发人员中心SetCapture功能.aspx)。 更多关于ClipCursor的信息，访问Windows开发人员中心ClipCursor功能.aspx)。 123//在OnLButtonUp中ReleaseCapture();//恢复鼠标的形状ClipCursor(NULL);//放开抓捕，否则怎么也出不去客户区了 由于设置了新的鼠标样式，如果没有SetCapture，在移动后鼠标样式就会发生改变。ClipCursor决定了是不是要把鼠标限制的某一个区域SetCapture与ReleaseCapture决定是不是把鼠标改编成设定好的样式。 八、Examples1. 鼠标画线这个例子允许用户从起点开始，画一条跟随鼠标移动直到其松开为终点的线段。 12345//在C×View类定义中private: int draw; HCURSOR cursor; CPoint old,origin; 1234//在C×View构造函数中draw=0;cursor=AfxGetApp()-&gt;LoadStandardCursor(IDC_CROSS);old=origin=CPoint(0,0); 123456789//OnLButtonDown中old=origin=point;//保存按下鼠标的位置draw=1;SetCapture();SetCursor(cursor);CRect rect;GetClientDC(&amp;rect);ClientToScreen(&amp;rect);ClipCursor(&amp;rect); 1234//在OnLButtonUp中draw=0;ReleaseCapture();ClipCursor(NULL); 12345678//在OnMouseMove中。--需要一直重绘CClientDC dc(this);dc.SetROP2(R2_NOT);if(draw==1)&#123; dc.MoveTo(origin);dc.LineTo(old); dc.MoveTo(origin);dc.LineTo(point); old=point;&#125; 如果想看更详细的，点此链接.aspx#drawing_lines)。 2. 背景与贴图贴图的例子与位图的例子很相似，不过耍了一点小手段。这个具体见例子4-17。 3. 扇面效果扇面效果就是1的降级版。 4. 鼠标拖动圆]]></content>
      <tags>
        <tag>MFC</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MFC something（2]]></title>
    <url>%2F2017%2F05%2F26%2FMFC%E5%9F%BA%E7%A1%80%2F%E7%AC%AC%E4%BA%8C%E7%AB%A0MFCsomething%2F</url>
    <content type="text"><![CDATA[一、MFC类的组织结构1.根类（CObject）CObject类是MFC的抽象基类，是其中多数类与用户自定义类的根类，提供了编程所需的公共操作，如：对象建立与删除，串行化支持，运行时信息支持等操作。 2.应用程序体系结构类(1.CCmdTarget类它是命令相关类，是MFC的消息映射基类 (2.CWinThraed类它是线程相关类，是MFC线程处理的基类 (3.CWinApp类应用程序基类，每个程序只有一个对象，提供相关操作，例如初始化、运行、终止 上述类的继承关系是： 1234graph LRCObject--&gt;CCmdTargetCCmdTarget--&gt;CWinThreadCWinThread--&gt;CWinApp CWinApp类有一些公有成员函数： 函数名 功能 InitInstance 初始化应用程序 Run 启动默认的消息循环 ExitInstance 终止应用程序 LoadCursor 向应用程序加载光标 LoadIcon 向应用程序加载图标 (4.CDocument类文档类文档对象由文档模板创建，管理应用程序的数据，包括文档创建、打开、保存。 文档模板类如下： CDocTemplate:文档模板基类 CSingleDocTemplate：SDI文档模板 CMultiDocTemplate：MDI文档模板 CDocumnet：专用文档基类 (5.视图类CViewMFC视图基类，实现框架窗口中的客户区。其类继承关系如下： 1234graph LRCObject--&gt;CCmdTargetCCmdTarget--&gt;CWndCWnd--&gt;CView CView有一些派生类，大致如下：|派生类名|功能||:-:|:-:||CScrollView|带滚动条的视图||CCtrlView|带树状列表空间的视图||CEditView|带文本编辑器的视图||CFormView|基于表单模板的视图|CListView|带列表框控件的视图CRecordView|可显示数据库记录的视图CRichEditView|带格式文本编辑器的视图CPreviewView|支持打印预览的视图 3.可视对象类(1.窗口类CWndMFC窗口基类，实现不同类型的窗口 MFC派生类有下： CFrameWnd：单文档框架窗口类 CMIDFrameWnd：多文档主框架窗口类 CMIDChildWnd：多文档子框架窗口类 (2.上述的CView派生类属于可视对象类 (3.菜单类CMenuMFC菜单类，实现菜单界面 (4.对话框类CDialog对话框类第五章挺详细的 (5.控件类 控件类名 功能 类名 功能 CStatic 文本 CHotKeyCtrl 热键 CEdit|编辑框|CRichEditCtrl|格式编辑框CScrollBar|滚动条|CProgressCtrl|进度条CSlideCtrl|游标|CSpinButtonCtrl|双向箭头CComboBox|组合框|CBitmapButton|位图按钮CListBox|列表框|CAnimateCtrl|动画显示CButton|按钮|CToolTipCtrl|弹出式窗口 (6.控件条类CControlBarCControlBar是控件栏基类，实现工具条，状态条，浮动对话框。 CControlBar派生类： CStatusBar：状态条 CToolBar：带位图按钮的工具条 CDialogBar：控件条形式的浮动对话框 (7.绘图对象类CGridObjectMFC绘图对象基类，实现各种绘图对象 CGridObject派生类： CBitmap：位图操作接口 CBrush：画刷 CFont：字体 CPalette：调色板 CPen：画笔 CRgn：椭圆或多边形域 (8.设备描述表类CDCCDC派生类： CPaintDC：绘图设备描述表 CClientDC：客户区的设备描述表 CWindowDC：窗口的设备描述表 CMetaFileDC：Windows元文件的设备描述表 4.通用类(1.文件类CFile文件访问基类，实现文件输入与输出操作 其派生类： CMemFile：驻内存文件访问接口 CStudioFile：缓存流式文件访问接口 (2.CArchive类与CFile通过串行化实现文件的永久存储 (3.异常类CException CNotSupportException：不支持异常 CMemoryException：内存异常 CFileException：文件异常 CResourceException：资源异常 COleException：OLE异常 CODBException：数据库异常 CUserException：用户操作异常 (4.模板收集类CArray与CTypedPtrArray类：将数据存储到数组中 CList与CTypedPtrList类：将数据存储到链表中 CMap与CTypedPtrMap类：将键映射到数值 (5.OLE类OLE是对象链接与嵌入，对象服务体系结构 普通类：COleDocument、COleItem客户类：COleClientDoc、COleClientItem服务类：COleServer、COleTemplate可视编辑容器类：COleLinkingDoc数据传输类：COleDropSource、COleTarget、COleDataSource、COleDataObject对话类：COleInsertDialog (6.数据库类ODBC类是MFC数据库访问类，可访问支持ODBC的数据库系统，完成查询、更新等操作12345CDatabase//：连接数据源CRecordset//：数据源的一组记录CRecordView//：记录的表单视图CFieldExchange//：支持记录字段交换CLongBinary//：存储二进制对象句柄 (7.Internet与网络工作类Win32 Internet类：CInternetSession类、CInternetFile类、CInternetConnection类、CFileFind类、CGopherLocator类 Windows Socket类：CSocket类、CAsyncSocket类 ISAPI类 二、MFC全局函数以Afx为前缀的函数：|函数名|功能||:-:|:-:|AfxAbort|终止一个应用程序AfxBeginThread|创建并执行一个线程AfxEndThraed|终止正在执行的线程AfxMessageBox|弹出一个消息框AfxGetApp|返回当前应用程序对象的指针AfxGetInstanceHandle|返回当前应用程序对象的句柄AfxRegisterWndClass|注册一个窗口类 三、MFC程序框架分析Windows程序核心是CWinApp 每次启动新的应用程序，WinMain函数都调用InitInstance() 创建并注册文档模板： ```CSingleDocTemplate*pDocTemplate;pDocTemplate=new CSingleDocTemplate]]></content>
      <tags>
        <tag>MFC</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MFC基础（1]]></title>
    <url>%2F2017%2F05%2F26%2FMFC%E5%9F%BA%E7%A1%80%2FMFC%E5%9F%BA%E7%A1%80%EF%BC%881%2F</url>
    <content type="text"><![CDATA[愚人节快乐呀！ 可视化的笔记一直不知道怎么系统地整理一下，正好前一段搜索stable marriage的时候发现有人写博客写了学习记录，我就想着，嗯，我也可以弄一个这样的学习记录呀，方便以后查找！于是这个系列就诞生啦！应该主要以梳理ppt为主，其间加入教材部分内容以及我自己编程中遇到问题的解决方法。就酱！好了，废话不多说，进入正题！ 窗口：窗口指程序的用户界面，它是Windows应用程序基本的操作单元，也是系统管理应用程序的基本单位。窗口可以分为客户区与非客户区。例如一个文档程序，可编辑区称为客户区，菜单及窗口边缘是非客户区。编写一个Windows应用程序首先应该创建至少一个窗口，应用程序的运行其实就是窗口内部、窗口与窗口之间、窗口与系统之间进行数据处理和数据交换的过程。 事件驱动：Windows程序围绕事件或消息生成进而引发相应处理函数执行，这叫做事件驱动。程序的执行顺序取决于消息的产生顺序。 句柄：句柄是Windows系统标识对象或实例的整数值（PVOID）。对于不同的对象，句柄有不同的类型： 消息Windows中消息有三部分组成：消息号、字参数、长字参数。Windows中消息往往用结构体表示，对一个消息，其定义如下： 12345678typedef struct tagMSG&#123; HWDN hwdn;//窗口句柄 UINT message;//消息的值 WPARAM wParam;//消息附加信息 LPARAM lParam;//消息附加信息 DWORD time;//消息送至消息队列的时间 POINT pt;//发送消息时鼠标光标位置&#125;MSG; 系统定义了很多消息，这些消息有一定的命名规律，比如按消息产生的地方进行分类，不同的地方产生的消息一般会有以下前缀： 再回到消息结构体的定义，发现其中的message即为定义的消息名标识，这个标志在×××.h由宏定义与一个消息号联系起来，即消息组成的第一部分。 1#define WM_MYMSG WMUSER+1 wParam与lParam分别代表了字参数和长字参数。 下面简要介绍Windows用用程序常用的消息： WM_LBUTTONDOWN：单击鼠标左键时产生此消息。wParam标识鼠标键的单击状态，lParam低位标识了当前光标的x坐标，高位标识当前光标的y坐标。类似有：WM_LBUTTONDBLCLK在双击鼠标左键时产生。 WM_KEYDOWN：在按下任意一个非系统键时产生的消息。wParam是按下键的虚拟键码，lParam记录按键重复次数、扫描码、转移代码、先前键的状态等信息。 WM_CHAR：按下任意一个非系统键时产生的消息。wParam是按下键的ASCII码，lParam含义与WM_KEYDOWN相同。 WM_CREATE：由CreateWindow发出的消息，创建窗口。 WM_CLOSE：关闭窗口产生的消息。 WM_DESTORY：销毁窗口时由DestoryWindow发出的消息。 WM_QUIT：退出程序时由PostQuitMessage发出的消息。 WM_PAINT：绘制视图产生该消息。 Windows程序框架：WinMain函数：WinMain函数是Windows程序的入口函数，完成以下功能： 注册窗口类，建立窗口并初始化 进入消息循环，消息队列接收消息，调用相应的处理过程。 接收WM_QUIT消息，终止程序运行 声明：123456int WINAPI WinMain( HINSTANCE hInstance,//当前实例 HINSTANCE hPrevInstance,//前一个实例 LPSTR lpCmdLine,//命令行指针 int nCmdShow//窗口显示方式) 初始化： 123456RegisterClass()//注册窗口CreateWindow()//创建窗口ShowWindow()//显示窗口UpdateWindow()//更新窗口LoadIcon()//加载图标LoadCursor()//加载光标 窗口： 设计窗口类： 123456789101112typedef struct _WNDCLASS &#123; UINT style;//窗口样式 WNDPROC lpfnWndProc;//窗口处理函数 int cbClsExtra;//类附加内存 int cbWndExtra;//窗口附加内存 HANDLE hInstance;//程序实例句柄 HICON hIcon;//图标句柄 HCURSOR hCursor;//光标句柄 HBRUSH hbrBackground;//背景画刷句柄 LPCTSTR lpszMenuName;//菜单资源名 LPCTSTR lpszClassName;//窗口类名 &#125; WNDCLASS; 在窗口类WNDCLASS中，lpfnWndProc成员指定窗口处理函数，又称回调函数，当程序收到传给窗口的消息，它调用某个函数处理该消息。调用过程由Windows系统完成，函数代码由应用程序提供。 CreateWindow函数声明： 12345678910HWND CreateWindow ( LPCTSTR lpszClassName,//窗口类名 LPCTSTR lpszTitle,//窗口标题 DWORD dwStyle,//窗口样式 int X,int Y,//窗口左上角坐标 int nWidth,int nHeight,//窗口宽度高度 HWND hwndParent,//父窗口句柄 HMENU hMenu,//主菜单句柄 HINSTANCE hInstance,//当前程序实例 LPVOID lpParam)//传递参数指针 窗口处理函数定义： 12345678910LRESULT CALLBACK WndProc(HWND hwnd,UINT message, WPARAM wParam,LPARAM lParam)&#123; switch(message)//消息循环 &#123; case WM_LBUTTONDOWN://鼠标左键消息 case WM_DESTROY://退出程序消息 default:DefWindowsProc(hwnd,message,wParam,lParam) &#125;&#125; 常用窗口样式： 消息循环 GetMessage()从消息队列取消息 DispatchMessage()向消息队列存消息 12345MSG msg;while(GetMessage(&amp;msg,NULL,0,0)&#123; TranslateMessage(&amp;msg); DispatchMessage(&amp;msg);&#125; 写的我头晕眼花。感觉没有什么收获的样子。毕竟是综述。以后也要加油啊~]]></content>
      <tags>
        <tag>MFC</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java:clone]]></title>
    <url>%2F2017%2F05%2F06%2FJAVA%2Fjava%E4%B8%AD%E7%9A%84clone%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[JAVA中的clone()方法 今天破天荒的准备用整个晚自习的时间学习JAVA。本来是准备写GUI那边的作业的，看了看clone()那边的作业发现还是有很多问题，决定还是花时间整理一下。 首先是我发现问题的地方。代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package toybattery;class Battery implements Cloneable&#123; int batnum; Battery(int p)&#123; batnum=p; &#125; public String toString()&#123;//can not reduce the visibility of the inherited method from Object String s=new String(Integer.toString(batnum)); return s; &#125; /*** * Battery中的克隆函数。 */ public Object clone()&#123; Object o=null; try&#123; o=super.clone(); &#125;catch(CloneNotSupportedException e)&#123; System.err.println(&quot;Battery can not be cloned!&quot;); &#125;// ((Battery)o).batnum=0; return o; &#125;&#125;public class Toy implements Cloneable&#123; Battery[] mybat=new Battery[10]; /*** * 将mybat中所存的所有int转为String并用逗号分隔。 */ public String toString()&#123; int i=0; String s=new String(&quot;&quot;); while((i&lt;10)&amp;&amp;mybat[i]!=null)&#123; s+=mybat[i]; if(i&lt;9)&#123;s+=&quot;,&quot;;&#125; i++; &#125; return s; &#125; /*** * Toy的克隆函数 */ public Object clone()&#123; Toy o=new Toy();//=null;/* try&#123; o=(Toy)super.clone(); &#125;catch(CloneNotSupportedException e)&#123; System.err.println(&quot;Toy can not be cloned!&quot;); &#125;*/ int i=0; while((i&lt;10)&amp;&amp;(mybat[i]!=null))&#123; o.mybat[i]=(Battery)mybat[i].clone(); i++; &#125; return o; &#125; public static void main(String argc[])&#123; Toy mytoy=new Toy(); for(int i=0;i&lt;10;i++)&#123; mytoy.mybat[i]=new Battery(i+1); &#125; System.out.println(mytoy); Toy mytoy2=(Toy)mytoy.clone(); System.out.println(&quot;orignal:&quot;+mytoy); System.out.println(&quot;clone:&quot;+mytoy2); mytoy.mybat[4].batnum=55; mytoy2.mybat[3].batnum=44; System.out.println(&quot;after changed orignal:&quot;+mytoy); System.out.println(&quot;after changed clone:&quot;+mytoy2); &#125;&#125; 在这段代码中，明明在Toy类里面对o的成员mybat对象数组的每一个对象都调用了相应的clone()方法，却还是没能实现深层克隆。于是我测试了Battery类里面的clone()方法，发现这个方法实现的确实是深层克隆，而且在这个方法里仅仅调用了super.clone()，说明对于仅含有基本类型成员变量的类的对象，Object中的clone()方法足以。然后我又尝试在Toy类中增加了成员变量Battery mb;，经测试，发现mb经克隆之后可以实现深层克隆。然后我又在Battery中加了int[]，以同样的方法，无法实现深克隆。直接对int[]克隆，深克隆。直接对int[][]克隆，浅克隆。于是结论就是，JAVA的clone()方法在对对象数组进行克隆时，有我不知道的地方。 也许也以这样理解：（在这里没有查资料，仅仅做个假设）（意外收获啊：println对int[]打印时打印地址） java中的克隆方法会进行一次判断。 若用户给的是基本数据类型，即给定空间直接存储的就是有用值，直接开一个新空间，把这个值写进新空间。 如果是一个引用，这时clone()将追寻到这个引用所示的地址，并据这个引用提供的长度信息新建x个空间，把引用所示地址的这x个空间里面的值写到新建的x各空间里面。 java所谓的浅克隆是由于复合类型都是由引用来表示的，克隆的是他们的地址值。 那么问题来了，如果用户需要克隆的是基本数据类型或是基本数据类型的一位数组，完全没问题。如果用户想要克隆的是二维数组，对象数组呢？ 首先是二维数组，假设: 12345678public class Test&#123; public void main(String[]argc)&#123; int[][]test=new int[2][2]; int[][]test2=test.clone(); test[0][0]=1; System.out.println(test2[0][0]); &#125;&#125; 若运行以上程序，结果必然是1。这样，我们就不得不对每个一位数组再做克隆，得到深克隆。 12test2[0]=test[0].clone();test2[1]=test[1].clone(); 以简单的二维数组为例，对空间使用情况进行分析： clone()方法据test所代表空间存的值找到2个新空间。这两个新空间分别由test[0]与test[1]代表。 创建两个新空间，把值写进去；创建一个新空间，给test2使用，并把test2里面的地址值写为第一个新空间的地址。 至此，系统给的clone()方法功能已经结束。 但我们并不满于浅克隆，于是对test[0]与test[1]再分别调用系统的clone()方法。 以test2[0]为例。对test2[0]调用clone()，找到两个新空间，写入，赋值。 特别地，若中间地址（暂且这么称呼）已经有了空间，系统将会直接修改这个空间中的值，不在创建新空间（整个逻辑都不对了）。 关于对象的问题。只需明确一点，对象所代表的空间里存的是地址。只需将它作为第一个会检查的引用，其他如上。 顺便一提。在我辛辛苦苦改了1.5+h的代码后，发现最上面的长代码问题竟然是没有写o.mybat=(Battery[])mybat.clone()，呵呵！少了一环能对才有鬼。只是使旧空间最后一环一起挪了个地儿而已！傻孩子啊。]]></content>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java:Calculator]]></title>
    <url>%2F2017%2F05%2F06%2FJAVA%2Fjava%EF%BC%9ACalculator%2F</url>
    <content type="text"><![CDATA[关于今天写的小计算机程序。虽然涉及GUI的知识不多，但是仍然有一些些小点。我就在这篇里面都记录下来。 String类常用函数整理 length()–返回字符串的长度。 charSet(int index)–返回值类型为char，取得String在该位置上的char。索引从0开始，至s.length()-1结束。 contentEquals(String ss)–比较s与ss内容是否相同。返回boolean。注意：使用==比较两个字符串时一般会返回false，这不是预期结果。因为==比的是空间内容。对String来说，比较的是引用值。 contains(String ss)–看s中是否包含ss。返回boolean。 indexOf(char a)/indexOf(String ss)–寻找第一个出现的a/ss的索引值。与之相对的，lastindexOf(char a)/lastindexOf(String ss)–从后面寻找第一个出现的a/ss的索引值。 substring(int begin,int end)–返回一个新串，这个串从begin到end。不包括end。例如，想得到原串的一个副本。可ss=s.substring(0,s.length());。若begin==end，则返回空字符串。 isEmpty()–判断一个字符串是否为空串。若为空返回true。注意：字符串判空不可以使用表达式s==null。这是因为s即使是一个空串，也可能有自己的new出的空间。s==null一般为false。这不是预期结果。 replace(String ori,String aft)–使用aft替换掉在s中出现的所有的ori，并返回新串。注意：String的所有方法都不可能改变原串。所以在replace方法中，原串不会变化。若想得到变化后的字符串，需s=s.replace(“1”,”2”)或ss=s.replace(“1”,”2”);。 BigDecimal类 BigDecimal类属于java.math。(Math类属于java.lang.Math）BigDeciaml类主要解决了Math类计算错误的问题。 由于计算机本身的二进制属性，在程序没有bug的情况下也可能出现以下情况： 12345678public class MyClass&#123; public static void main(String[]argc)&#123; System.out.println(0.1*24); System.out.println(9.6/3); System.out.println(0.7+0.1); System.out.println(7-5.6); &#125;&#125; 运行上面的程序，会得到以下结果： 究其原因，是计算机在进行计算时，首先将十进制转换为二进制，使用二进制进行计算，计算完成后，再转回十进制。在这个过程中，不乏出现十进制无法完全精确地转为二进制的情况，则出现偏差。 java提供了BigDecimal类，使用其中的方法可实现较精确的计算。 构造方法 BigDecimal(int v)–以v做参数的BigDecimal对象。 BigDecimal(double v)–以v做参数的BigDecimal对象。 BigDecimal(long v)–以v做参数的BigDecimal对象。 BigDecimal(String v)–v代表一个数值。 加减乘除 BigDecimal add(BigDecimal v)–成员方法。第一运算分量为调用对象。 BigDecimal subtract(BigDecimal v)–调用同add。 BigDecimal multiply(BigDecimal v)–同。 BigDecimal divide(BigDecimal v)–同。 注意：BigDecimal与Math不可以直接转换。上述为Math转BigDecimal，下述为BigDecimal转Math。 double doubleValue()–返回double值。其他类型类似。 但是，BigDecimal也没能精确到哪里去。仍然会出现问题。我修改代码： 123456789101112import java.math.BigDecimal;public class MyClass&#123; public static void main(String[]argc)&#123; BigDecimal a=new BigDecimal(0.1),b=new BigDecimal(24), c=new BigDecimal(9.6),d=new BigDecimal(3),e=new BigDecimal(0.7), f=new BigDecimal(7.0),g=new BigDecimal(5.6); System.out.println(a.multiply(b));//0.1*24); System.out.println(c.divide(d).doubleValue());//9.6/3); System.out.println(e.add(a));//0.7+0.1); System.out.println(f.subtract(g).doubleValue());//7-5.6); &#125;&#125; 但是运行后还是出现了问题。更为严重的是在divide出现了异常。注释掉这行。问题先留着。我们看其他结果。其实还是不能无误，只是增加了位数。 下面的内容不好意思开一个大标题了。只是顺便一提：System.exit(0)将会使运行中的程序退出，若有多个frame，几个frame都会退出。一个解决办法是：在对小frame监听时，只定义无名的内部类。使用新的frame名字fn调用dispose()。源码如下： 123bt.addActionListener(new ActionListener()&#123; public void actionPerformed(ActionEvent e)&#123;fn.dispose();&#125; &#125;); 可以实现只是小窗口退出。（这里是退出按钮）。 ActionEvent有成员方法getActionCommand()，返回String—按钮名。]]></content>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java:Calculator]]></title>
    <url>%2F2017%2F04%2F06%2FJAVA%2F%E4%BD%BF%E7%94%A8%E5%91%BD%E4%BB%A4%E7%AA%97%E5%8F%A3%E8%BF%90%E8%A1%8Cjava%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[先保存成个稿子，以后完善。 带包的：我的电脑上面不知道为什么不能javac。]]></content>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lab5_Document]]></title>
    <url>%2F2017%2F01%2F05%2FOS%2FLab5_Document%2F</url>
    <content type="text"><![CDATA[Lab5-DocumentFile system preliminariesSectors and Blocks大多数磁盘并不是以字节为单位进行读写，而是以512字节为单位的扇区进行。文件系统经常是以块为单位申请使用磁盘。扇区大小是磁盘的性质，块则是os使用磁盘的一个方面。文件系统的块大小必须是扇区大小的整数倍。 在unix的x86系统中，使用的块大小是512字节。现今由于存储介质的日益廉价以及对存储空间大粒度的操作的高效性，多数os都是用了更大的块。jos使用4k的块，正好和页大小一样。 Superblocks文件系统一般会把文件的meta-data保存在一个便于访问的地方，这些data包括块大小、磁盘大小等数据，保存这些meta-data的地方被称为超级块。 这里的文件系统只有一个超级块，他将会在block1。真正的文件系统一般会有很多个超级块，这样当某一个超级块崩溃的时候，其他的超级块还能正常使用。 下面来看一下超级块的数据结构struct Super，它在inc/fs.h中。 File Meta-data一个文件的meta-data在这里是使用struct File进行描述的，下面是File的结构： 更加直观的是这样： 由于我们的文件系统没有inode，因此将metadat存在磁盘的目录入口处。 在这里的文件系统中，File结构将会被用到内存以及磁盘上。从上图中可以看到，File结构中有一个大小是10的数组f_firect以及一个32位数t_indirect。他们分别存储着文件数据的位置信息。其中文件支持direct的40kB文件，如果大小大于40KB，可以利用indirect块的一共1024个其他block来存储文件，一共是4M+4K的文件大小。实际上，文件系统为了支持大文件，可能会支持2或是3个indirect块。 Directories versus Regular Files在文件系统中一共分为两种文件节点，一种是目录节点，另一种是文件节点。上述的File结构的f_type域便是用来区分这两种节点的。这里的文件系统对待文件与目录基本一样，唯一不同的是，文件系统不会对与文件关联的块进行解释，而会对目录——一堆文件结构进行解释。 超级块中包含根目录的File结构。 The File SystemDisk Access我们将会把IDE磁盘驱动作为用户层面文件系统进程的一部分，稍微修改内核代码来使得文件系统进程拥有独自访问磁盘的权限。 只要我们是依赖PIO-based磁盘，不使用磁盘的中断，完成磁盘访问是很容易的。使用中断驱动的设备驱动也很简单，但是由于kernel需要捕获并处理这些中断，就会变得很复杂。 x86处理器在eflags寄存器上提供了IOPL位，他决定了一个进程能不能执行一i额特殊的设备指令。由于我们需要访问的所有IDE磁盘寄存器都位于x86的IO空间中，而不是虚拟地址空间里面，所以给文件系统环境提供IO特权是我们想要的，允许文件系统访问这些寄存器。 实际上，EFLAGS寄存器中的IOPL位为内核提供了一个简单的“全有或全无”方法来控制用户模式代码是否可以访问IO空间。在这里，我们希望只有文件系统进程可以访问IO空间。 Exercise 1 直接给出代码： exe1完成之后，可以通过fs/io.c的测试： Question Do you have to do anything else to ensure that this I/O privilege setting is saved and restored properly when you subsequently switch from one environment to another? Why? 没有。因为它是在eflags中存在的，在进程间切换时对应的寄存器状态会被保存好，随着切换一同被复位。 The Block Cache在我们的文件系统中，将会实现一个简单的cache。我们的文件系统只能处理3GB以及更小的磁盘，在该文件系统进程的虚拟地址空间上留了从DISKMAP到DISKMAP+DISKMAX的3GB大小的空间，以此作为磁盘的内存空间映射。diskaddr函数可以将磁盘的块号翻译成为虚拟地址：其中BLKSIZE是块大小，这里与页大小相同。看到，该函数拒绝翻译块0与块1的虚拟地址。既然我们的文件系统进程已经有了自己的虚拟地址空间，接下来需要做的就只是实现文件访问。由于现代磁盘大于3GB，因此在32位机器上的真正的文件系统实现会很麻烦。 这种缓冲区高速缓存管理方法在64位地址空间的机器上仍然是合理的。（？） 当然，把整个硬盘读进内存是很荒唐的做法，因此我们实现了一个demand paging机制。它只是允许我们在发生缺页中断的时候把缺页对应的硬盘的内容读进内存。 在写exer2之前，首先读读写硬盘的代码：这是读硬盘的代码。参数分别是分区号、读入地址以及分区数。 这是写硬盘的代码。参数分别是分区号、源虚拟地址以及分区数。 Exercise 2根据提示写出代码：bc_pgfault：flush_block： 完成之后，make grade： 这里完成之后，可以去查看fs_init函数，了解块缓存的使用方法： init首先找一个可用的磁盘，函数ide_probe_disk1如下：这个函数查找一个可以处于ready状态的磁盘块，优先选择磁盘块1。首先等待磁盘块0ready，随后检查等待磁盘块1ready。如果时间用尽块1仍未ready，就切回块0，否则使用块1。 随后初始化bc，读入超级块进cache、设置cache中的pgfault处理函数、检查bc可用。 然后设置超级块的结构指针super指向超级块在内存中的位置，并检查超级块部分是否有效： 最后设置bitmap的结构指针指向位图在内存中的位置，并检查bitmap，保证块0，1以及bitmap部分是free的。 The Block Bitmap在fs_init设置了位图指针之后，我们就可以把位图当作bit的一个数组了。每一个bit代表磁盘上的一个block。 Exercise 3在写函数alloc_block之前，首先查看函数free_block： 相似的，结合check_bitmap中的代码，可以写出： 完成之后： File Operations在向下进行之前，首先来看fs/fs.c中已经写好的exe3将会用到的但是尚未提到过的内容： Exercise 4file_block_walk and file_get_block in fs/fs.cfile_block_walk是从一个指定的文件中找到一个指定的块，并将这个块在磁盘中的块号放在ppdiskbno中。如果不成功则返回对应的错误代码。 file_get_block是从一个指定的文件中找到一个指定的块，并在必要的时候申请新的块，将对应块的被映射的虚拟地址放在blk[0]中。如果不成功，则返回对应的错误代码。 完成后： The file system interface现在文件系统已经有了必要的功能，下面需要允许其他进程来使用文件系统。由于其他进程不能直接调用文件系统中的函数，我们需要暴露文件系统进程的远程过程调用（RPC）。下图是调用文件系统服务的过程： read读取文件，然后交给devfile_read读取磁盘上的文件。devfile一类的函数实现了文件系统操作的客户服务。在请求中绑定函数，调用fsipc发送IPC请求，并解包返回结果。fsipc函数处理向server发送请求和接受应答的常见细节。文件系统服务器代码在fs/serv.c中。它在发送函数中循环，无休止地通过IPC接收请求，将该请求分派给相应的处理函数，并通过IPC发回结果。在阅读示例中，serve将调度到serve_read，它将处理特定于读取请求的IPC细节，例如解压缩请求结构，最后调用file_read来实际执行文件读取。JOS的IPC机制让一个环境发送一个单一的32位数字，并可选择共享一个页面。为了从客户端向服务器发送请求，我们使用32位数的请求类型（文件系统服务器的RPC编号，就像syscalls的编号一样），并将参数存储到联合Fsipc中的请求上该页面通过IPC共享。在客户端，我们总是在fsipcbuf共享页面;在服务器端，我们将传入的请求页面映射到fsreq（0x0ffff000）。服务器也通过IPC发送回应。我们使用32位数字作为函数的返回码。对于大多数RPC，这是他们所有的返回。 FSREQ_READ和FSREQ_STAT也会返回数据，他们只是写入客户端发送请求的页面。在响应IPC中不需要发送此页面，因为客户端首先将其与文件系统服务器共享。此外，FSREQ_OPEN在回复中与客户分享了一个新的“Fd页面”。我们很快会返回到文件描述符页面。 在写exe5之前，参考其他的serv类函数： 首先获得对应的OpenFile结构，随后利用OpenFile中的信息获得File信息，调用FS中的函数，完成任务。 OpenFile结构的定义如下： openfile_lookup函数从全局的数组中根据打开file的id获得对应的file，类似于env的获得。 Fd结构记录了某一个打开文件的打开方式与偏移量等数据。每个打开的文件有一个Fd结构，就像是unix中的文件描述符一样。这个结构由自己的内存空间，而且与所有打开该文件的进程分享。 本函数中使用file_read，这个函数：它从指定文件的指定偏移出读取count字节的数据放到给定的buf中。 关于exe中的联合Fsipc，这里需要用到的一部分如下：其中对于read，req_fileid是对应文件的id，req_n是读取文件的偏移量；readRet中的buf则是在进行文件的读操作的时候，file_read放入数据的buf。对于write，也是对应的字段。 Exercise 5 完成后，可以通过serve_open/file_stat/file_close以及file_read： 对应的file_write是：他已经完成了必要时扩展的功能。与read类似，file_write是将buf中的内容放入对应文件的指定偏移位置。类似的，可以写出exe6中的serv_write函数。 在写devfile_write函数之前，首先看devfile_read函数：它使用fspic发送请求，得到回答并将fsipc（serve）做的工作：读出的数据取回。可以看到的是，fsipc（serve）所做的事情正是我们在前面所做的，serve_read中所做的事。 fsipc函数负责发送request与接受request，其函数体如下：正如前面的图中所示，fsipc随后使用IPC与文件系统进程传递数据，文件系统进程在serve中接收数据并进行更上层的调用处理，为了更好地写出write函数，下面来看serve函数的处理方式： 其中的handlers是函数指针：其中决定了各种除了open之外的处理方式。对于write，可以看到，在fsipcbuf中设置的参数将会在之后用于调用serve_erite函数。 Exercise 6 完成之后： Spawning Processes在lib/spawn.c中，已有的代码可以完成创建新进程，加载程序镜像，使子进程开始跑程序等。我们使用spawn而不是用向unix一样的exec，这是因为spawn将可以更加容易地被实现。 在env.c中：特权级设置。 Exercise 7 完成之后： Sharing library state across fork and spawnUinx文件描述符是一个通用的概念，包括管道，控制台的IO等。每种这样的设备都包含一个对应的Dev结构，包含一个指向实现了read、write等函数的指针。lib/fd.c实现了像unix一样的文件描述符接口。每个fd结构代表他的设备类型，fd中的大部分函数都只是将任务分配到对应dev的函数。 lib/fd.c还在每一个应用程序环境的地址空间上维护文件描述符，从FSTABLE开始，这个区域保留了一个page的空间，允许每一个进程同时最多打开（MAXFD）32个文件。只有某一个文件被打开，对应的Fd才会被map到地址空间中去。每一个fd都有一个可选的data page，从FILEDATA开始，设备可以选择使用。 我们希望能够在fork与spawn之间共享file descriptor，但是文件描述符是被保存在用户空间的内存之中，在fork之中，这些内存需要被标记为cow，因此状态就会重复，而不是共享这也就是说，进程无法找到尚未打开的文件，管道也不可能工作在fork中,在spawn中，内存将会被丢到一旁。 我们需要更改fork，让她知道在特定的区间中内存被用于“library operating system”，并且应该总是共享的。在页表中设置一个位，让fork知道这件事，而不是再编写代码。 在inc/lib.h中定义了一个新的位：PTE_SHARE。它是Intel与AMD手册中标记为“可用于软件使用”的三个PTE位之一。我们将建立约定：如果某一个table entry的这一位被置位，就直接从父亲拷贝到儿子，不管是在spawn还是在fork。这与cow是完全不同的。 Exercise 8修改原来的duppage代码，当某一个页面被标记为SHARE的时候时，将同样的映射映射到对应的env上。 copy_share_pages像是在fork函数中实现的复制映射的部分，只是这里无法调用duppage： 完成之后： The keyboard interface为了使得shell可以工作，我们需要输入东西。QEMU已经可以在CGA显示器上显示我们的输入了，但是目前我们只是在内核监视器上进行输入。在qemu中，输入在图形窗口的输入显示为从键盘到JOS的输入，而输入到控制台的输入在串行端口上显示为字符。 kern / console.c已经包含了自实验1以来已被内核监视器使用的键盘和串口驱动程序，但是现在需要将这些驱动程序附加到系统的其他部分。 在写exe9之前，首先看将会被调用的两个函数kern/condole.c： kbd_intr： serial_intr： 具体操作偏向底层，这里不做讨论。 Exercise 9只需要按照描述调用函数： 完成之后： 在lib/console.c中实现了输入输出文件类型， kbd_intr和serial_intr用最近读取的输入填充一个缓冲区，而控制台文件类型则消耗缓冲区（除非用户重定向，否则控制台文件类型默认用于stdin / stdout）。 The Shell运行user/icode。icode执行初始化操作，设置console为文件描述符0与1（标准输入输出），然后会spawn sh。随后可以运行一些命令。 注意，cprintf直接打印到控制台，而不使用文件描述符代码。这对于调试来说很好，但对于其他程序的管道来说并不好。要将输出打印到特定的文件描述符（例如，1，标准输出）需要使用fprintf（1，“…”，…）。 printf（“…”，…）是打印到FD1。 首先查看user/icode.c文件，在启动完成之后，初始化spawn：spawnl函数在lib/spawn.c中被定义，它将会处理输入的执行程序名与命令行参数并调用spawn函数进行执行。在spawn函数中，将遵循以下执行步骤： 打开程序文件 像以前一样读ELF头，然后检查其IMAGE 使用sys_exofork创建一个新的进程 将child_tf设置为孩子的Trapframe 调用init_stack函数来初始化子环境的堆栈 映射所有程序段的p_type ELF_PROG_LOAD进入新环境的地址空间。对每个段使用Proghdr中的p_flags字段确定如何映射段。 调用sys_env_set_trapframe(child，＆child_tf)来设置子进程中的正确的eip和esp值。 用sys_env_set_status()启动子进程。 这个exe可以参考write的写法： 其中的dup函数在fd.c中被定义，其函数体如下：它将一个fd变成另外一个fd的duplicate，对一个操作，也会影响另外一个。 Exercise 10 完成之后： 本实验结束。最后make grade：]]></content>
      <categories>
        <category>OS</category>
        <category>MIT Lab</category>
      </categories>
      <tags>
        <tag>OS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于]]></title>
    <url>%2Fabout%2Findex.html</url>
    <content type="text"><![CDATA[╰(￣ω￣ｏ)！ 就不说什么能认识大家很开心之类的废话了！ 我目前还在大学奔波忙碌，真的完全是小白啦！之前学习专业课的时候受到很多大神博主的帮助，中文文档简直是瑰宝！ 所以~希望我的东西或多或少也能帮助到别人！ 鞠躬~(●’◡’●)]]></content>
  </entry>
  <entry>
    <title><![CDATA[all-archives]]></title>
    <url>%2Fall-archives%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[schedule]]></title>
    <url>%2Fschedule%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[读书]]></title>
    <url>%2Freading%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[all-categories]]></title>
    <url>%2Fall-catagories%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[categories]]></title>
    <url>%2Fcategories%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[sitemap]]></title>
    <url>%2Fsitemap%2Findex.html</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[tags]]></title>
    <url>%2Ftags%2Findex.html</url>
    <content type="text"></content>
  </entry>
</search>
